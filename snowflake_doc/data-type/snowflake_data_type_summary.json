[
  {
    "category": "Numeric data types",
    "url": "https://docs.snowflake.com/en/sql-reference/data-types-numeric",
    "details": [
      {
        "heading": "Numeric data types",
        "description": "\nThis topic describes the numeric data types supported in Snowflake, along with the supported formats for numeric constants/literals."
      },
      {
        "heading": "Data types for fixed-point numbers",
        "description": "\nSnowflake supports the following data types for fixed-point numbers."
      },
      {
        "heading": "NUMBER",
        "description": "\nNumbers up to 38 digits, with an optional precision and scale:\nBy default, precision is 38, and scale is 0 (that is, NUMBER(38, 0)). Precision limits the range\nof values that can be inserted into (or cast to) columns of a given type. For example, the value 999 fits into\nNUMBER(38,0) but not into NUMBER(2,0).\nBecause precision is the total number of digits allowed, you cant load a value into a NUMBER column if the number\nof digits to the left of the decimal point exceeds the precision of the column minus its scale. For example,\nNUMBER(20, 2) allows 18 digits on the left side of the decimal point and two digits on the right side of the decimal\npoint, for a total of 20.\nThe maximum scale (number of digits to the right of the decimal point) is 37. Numbers that have fewer than 38\nsignificant digits, but whose least significant digit is past the 37th decimal place, for example\n0.0000000000000000000000000000000000000012 (1.2e-39), cant be represented without losing some digits of precision.\nNote\nIf data is converted to another data type with lower precision, then back to the higher-precision data type, the data\ncan lose precision. For example, precision is lost if you convert a NUMBER(38,37) value to a DOUBLE value (which has a\nprecision of approximately 15 decimal digits), and then back to NUMBER.\nSnowflake also supports the FLOAT data type, which allows a wider range of values,\nalthough with less precision.",
        "definitions": [
          {
            "term": "Precision:",
            "definition": "Total number of digits allowed."
          },
          {
            "term": "Scale:",
            "definition": "Number of digits allowed to the right of the decimal point."
          }
        ]
      },
      {
        "heading": "DECIMAL , DEC , NUMERIC",
        "description": "\nSynonymous with NUMBER."
      },
      {
        "heading": "INT , INTEGER , BIGINT , SMALLINT , TINYINT , BYTEINT",
        "description": "\nSynonymous with NUMBER, except that precision and scale cant be specified (that is, it always defaults to NUMBER(38, 0)).\nTherefore, for all INTEGER data types, the range of values is all integer values from\n-99999999999999999999999999999999999999 to +99999999999999999999999999999999999999 (inclusive).\nThe various names (TINYINT, BYTEINT, and so on) are to simplify porting from other systems and to suggest the expected\nrange of values for a column of the specified type."
      },
      {
        "heading": "Impact of precision and scale on storage size",
        "description": "\nPrecision (total number of digits) doesnt affect storage. The storage requirements for the same number in columns with\ndifferent precisions, such as NUMBER(2,0) and NUMBER(38,0), are the same. For each micro-partition, Snowflake determines\nthe minimum and maximum values for a given column and uses that information to determine the storage size for all values\nfor that column in the partition. For example:\nIf a column contains only values between -128 and +127, then each of the values consumes 1 byte (uncompressed).\nIf the largest value in the column is 10000000, then each of the values consumes 4 bytes (uncompressed).\nIf a column contains only values between -128 and +127, then each of the values consumes 1 byte (uncompressed).\nIf the largest value in the column is 10000000, then each of the values consumes 4 bytes (uncompressed).\nHowever, scale (the number of digits following the decimal point) affects storage. For example, the same value stored in\na column of type NUMBER(10,5) consumes more space than NUMBER(5,0). Also, processing values with a larger scale might be\nslightly slower and consume more memory.\nTo save space, Snowflake compresses values before writing them to storage. The amount of compression depends on the data\nvalues and other factors."
      },
      {
        "heading": "Examples of fixed-point data types in a table",
        "description": "\nThe following statement creates a table with columns of various fixed-point data types:",
        "syntax": [
          "CREATE OR REPLACE TABLE test_fixed(\n  num0 NUMBER,\n  num10 NUMBER(10,1),\n  dec20 DECIMAL(20,2),\n  numeric30 NUMERIC(30,3),\n  int1 INT,\n  int2 INTEGER);\n\nDESC TABLE test_fixed;",
          "+-----------+--------------+--------+-------+---------+-------------+------------+-------+------------+---------+-------------+----------------+\n| name      | type         | kind   | null? | default | primary key | unique key | check | expression | comment | policy name | privacy domain |\n|-----------+--------------+--------+-------+---------+-------------+------------+-------+------------+---------+-------------+----------------|\n| NUM0      | NUMBER(38,0) | COLUMN | Y     | NULL    | N           | N          | NULL  | NULL       | NULL    | NULL        | NULL           |\n| NUM10     | NUMBER(10,1) | COLUMN | Y     | NULL    | N           | N          | NULL  | NULL       | NULL    | NULL        | NULL           |\n| DEC20     | NUMBER(20,2) | COLUMN | Y     | NULL    | N           | N          | NULL  | NULL       | NULL    | NULL        | NULL           |\n| NUMERIC30 | NUMBER(30,3) | COLUMN | Y     | NULL    | N           | N          | NULL  | NULL       | NULL    | NULL        | NULL           |\n| INT1      | NUMBER(38,0) | COLUMN | Y     | NULL    | N           | N          | NULL  | NULL       | NULL    | NULL        | NULL           |\n| INT2      | NUMBER(38,0) | COLUMN | Y     | NULL    | N           | N          | NULL  | NULL       | NULL    | NULL        | NULL           |\n+-----------+--------------+--------+-------+---------+-------------+------------+-------+------------+---------+-------------+----------------+"
        ]
      },
      {
        "heading": "Data types for floating-point numbers",
        "description": "\nSnowflake supports the following data types for floating-point numbers."
      },
      {
        "heading": "FLOAT , FLOAT4 , FLOAT8",
        "tables": [
          {
            "headers": [
              "Condition",
              "Snowflake",
              "IEEE 754",
              "Comment"
            ],
            "rows": [
              [
                "'NaN' = 'NaN'",
                "TRUE",
                "FALSE",
                "In Snowflake, 'NaN' values are all equal."
              ],
              [
                "'NaN' > X . where X is any FLOAT value, including . infinity (other than NaN itself).",
                "TRUE",
                "FALSE",
                "In Snowflake, 'NaN' is greater . than any other FLOAT value, . including infinity."
              ]
            ]
          }
        ]
      },
      {
        "heading": "DOUBLE , DOUBLE PRECISION , REAL",
        "description": "\nSynonymous with FLOAT."
      },
      {
        "heading": "Examples of floating-point data types in a table",
        "description": "\nThe following statement creates a table with columns of various floating-point data types:\nNote\nThe DESC TABLE commands type column displays the data type FLOAT not only for FLOAT, but also for synonyms\nof FLOAT (for example, DOUBLE, DOUBLE PRECISION, and REAL).",
        "syntax": [
          "CREATE OR REPLACE TABLE test_float(\n  double1 DOUBLE,\n  float1 FLOAT,\n  dp1 DOUBLE PRECISION,\n  real1 REAL);\n\nDESC TABLE test_float;",
          "+---------+-------+--------+-------+---------+-------------+------------+-------+------------+---------+-------------+----------------+\n| name    | type  | kind   | null? | default | primary key | unique key | check | expression | comment | policy name | privacy domain |\n|---------+-------+--------+-------+---------+-------------+------------+-------+------------+---------+-------------+----------------|\n| DOUBLE1 | FLOAT | COLUMN | Y     | NULL    | N           | N          | NULL  | NULL       | NULL    | NULL        | NULL           |\n| FLOAT1  | FLOAT | COLUMN | Y     | NULL    | N           | N          | NULL  | NULL       | NULL    | NULL        | NULL           |\n| DP1     | FLOAT | COLUMN | Y     | NULL    | N           | N          | NULL  | NULL       | NULL    | NULL        | NULL           |\n| REAL1   | FLOAT | COLUMN | Y     | NULL    | N           | N          | NULL  | NULL       | NULL    | NULL        | NULL           |\n+---------+-------+--------+-------+---------+-------------+------------+-------+------------+---------+-------------+----------------+"
        ]
      },
      {
        "heading": "Numeric constants",
        "description": "\nThe term constants (also known as literals) refers to fixed data values. The following formats are\nsupported for numeric constants:\n[+-][digits][.digits][e[+-]digits]\nWhere:\n+ or - indicates a positive or negative value. The default is positive.\ndigits is one or more digits from 0 to 9.\ne (or E) indicates an exponent in scientific notation. At least one digit must follow the exponent marker if present.\n+ or - indicates a positive or negative value. The default is positive.\ndigits is one or more digits from 0 to 9.\ne (or E) indicates an exponent in scientific notation. At least one digit must follow the exponent marker if present.\nThe following numbers are all examples of supported numeric constants:\nOn this page\nData types for fixed-point numbers\nData types for floating-point numbers\nNumeric constants\nRelated content\nArithmetic operators\nComparison operators\nLogical operators\nNumeric functions\nConversion functions\nData type conversion\nWe use cookies to improve your experience on our site. By accepting, you agree to our privacy policy.\nEnglish\nFranais\nDeutsch\n\n\nPortugus\n",
        "syntax": [
          "15\n+1.34\n0.2\n15e-03\n1.234E2\n1.234E+2\n-1"
        ]
      }
    ]
  },
  {
    "category": "String & binary data types",
    "url": "https://docs.snowflake.com/en/sql-reference/data-types-text",
    "details": [
      {
        "heading": "String & binary data types",
        "description": "\nThis topic describes the string/text data types, including binary strings, supported in Snowflake, along with the supported formats for string constants/literals."
      },
      {
        "heading": "Data types for text strings",
        "description": "\nSnowflake supports the following data types for text (that is, character) strings."
      },
      {
        "heading": "VARCHAR",
        "tables": [
          {
            "headers": [
              "Number of bytes per character",
              "Collation specification",
              "Maximum number of characters allowed (approximate)"
            ],
            "rows": [
              [
                "1 byte",
                "en-ci or en-ci-pi-ai",
                "Around 56 million characters"
              ],
              [
                "1 byte",
                "en",
                "Around 32 million characters"
              ],
              [
                "2 byte",
                "en-ci-pi-ai",
                "Around 64 million characters"
              ],
              [
                "2 byte",
                "en-ci or en-ci-pi",
                "Around 21.6 million characters"
              ],
              [
                "2 byte",
                "en",
                "Around 12 million characters"
              ]
            ]
          }
        ]
      },
      {
        "heading": "CHAR, CHARACTER, NCHAR",
        "description": "\nSynonymous with VARCHAR, except that if the length is not specified, CHAR(1) is the default.\nNote\nSnowflake currently deviates from common CHAR semantics in that strings shorter than the maximum length are not space-padded at the end."
      },
      {
        "heading": "STRING, TEXT, NVARCHAR, NVARCHAR2, CHAR VARYING, NCHAR VARYING",
        "description": "\nSynonymous with VARCHAR."
      },
      {
        "heading": "String examples in table columns",
        "syntax": [
          "CREATE OR REPLACE TABLE test_text(\n  vm VARCHAR(134217728),\n  vd VARCHAR,\n  v50 VARCHAR(50),\n  cm CHAR(134217728),\n  cd CHAR,\n  c10 CHAR(10),\n  sm STRING(134217728),\n  sd STRING,\n  s20 STRING(20),\n  tm TEXT(134217728),\n  td TEXT,\n  t30 TEXT(30));\n\nDESC TABLE test_text;",
          "+------+--------------------+--------+-------+---------+-------------+------------+-------+------------+---------+-------------+----------------+\n| name | type               | kind   | null? | default | primary key | unique key | check | expression | comment | policy name | privacy domain |\n|------+--------------------+--------+-------+---------+-------------+------------+-------+------------+---------+-------------+----------------|\n| VM   | VARCHAR(134217728) | COLUMN | Y     | NULL    | N           | N          | NULL  | NULL       | NULL    | NULL        | NULL           |\n| VD   | VARCHAR(16777216)  | COLUMN | Y     | NULL    | N           | N          | NULL  | NULL       | NULL    | NULL        | NULL           |\n| V50  | VARCHAR(50)        | COLUMN | Y     | NULL    | N           | N          | NULL  | NULL       | NULL    | NULL        | NULL           |\n| CM   | VARCHAR(134217728) | COLUMN | Y     | NULL    | N           | N          | NULL  | NULL       | NULL    | NULL        | NULL           |\n| CD   | VARCHAR(1)         | COLUMN | Y     | NULL    | N           | N          | NULL  | NULL       | NULL    | NULL        | NULL           |\n| C10  | VARCHAR(10)        | COLUMN | Y     | NULL    | N           | N          | NULL  | NULL       | NULL    | NULL        | NULL           |\n| SM   | VARCHAR(134217728) | COLUMN | Y     | NULL    | N           | N          | NULL  | NULL       | NULL    | NULL        | NULL           |\n| SD   | VARCHAR(16777216)  | COLUMN | Y     | NULL    | N           | N          | NULL  | NULL       | NULL    | NULL        | NULL           |\n| S20  | VARCHAR(20)        | COLUMN | Y     | NULL    | N           | N          | NULL  | NULL       | NULL    | NULL        | NULL           |\n| TM   | VARCHAR(134217728) | COLUMN | Y     | NULL    | N           | N          | NULL  | NULL       | NULL    | NULL        | NULL           |\n| TD   | VARCHAR(16777216)  | COLUMN | Y     | NULL    | N           | N          | NULL  | NULL       | NULL    | NULL        | NULL           |\n| T30  | VARCHAR(30)        | COLUMN | Y     | NULL    | N           | N          | NULL  | NULL       | NULL    | NULL        | NULL           |\n+------+--------------------+--------+-------+---------+-------------+------------+-------+------------+---------+-------------+----------------+"
        ]
      },
      {
        "heading": "Data types for binary strings",
        "description": "\nSnowflake supports the following data types for binary strings."
      },
      {
        "heading": "BINARY",
        "description": "\nThe maximum length is 64 MB (67,108,864 bytes). Unlike VARCHAR, the BINARY data type has no notion of Unicode characters,\nso the length is always measured in terms of bytes.\nBINARY values are limited to 64 MB so that they fit within 128 MB when converted to hexadecimal strings, for example using\nTO_CHAR(<binary_expression>, 'HEX').\nIf a length isnt specified, the default is the maximum length."
      },
      {
        "heading": "VARBINARY",
        "description": "\nVARBINARY is synonymous with BINARY."
      },
      {
        "heading": "Internal representation",
        "description": "\nThe BINARY data type holds a sequence of 8-bit bytes.\nWhen Snowflake displays BINARY data values, Snowflake often represents each\nbyte as two hexadecimal characters. For example, the word HELP might be\ndisplayed as 48454C50, where 48 is the hexadecimal equivalent of\nthe ASCII (Unicode) letter H, 45 is the hexadecimal representation of\nthe letter E, and so on.\nFor more information about entering and displaying BINARY data, see\nBinary input and output."
      },
      {
        "heading": "Binary examples in table columns",
        "syntax": [
          "CREATE OR REPLACE TABLE test_binary(\n  bd BINARY,\n  b100 BINARY(100),\n  vbd VARBINARY);\n\nDESC TABLE test_binary;",
          "+------+-----------------+--------+-------+---------+-------------+------------+-------+------------+---------+-------------+----------------+\n| name | type            | kind   | null? | default | primary key | unique key | check | expression | comment | policy name | privacy domain |\n|------+-----------------+--------+-------+---------+-------------+------------+-------+------------+---------+-------------+----------------|\n| BD   | BINARY(8388608) | COLUMN | Y     | NULL    | N           | N          | NULL  | NULL       | NULL    | NULL        | NULL           |\n| B100 | BINARY(100)     | COLUMN | Y     | NULL    | N           | N          | NULL  | NULL       | NULL    | NULL        | NULL           |\n| VBD  | BINARY(8388608) | COLUMN | Y     | NULL    | N           | N          | NULL  | NULL       | NULL    | NULL        | NULL           |\n+------+-----------------+--------+-------+---------+-------------+------------+-------+------------+---------+-------------+----------------+"
        ]
      },
      {
        "heading": "String constants",
        "description": "\nConstants (also known as literals) refer to fixed data values. String constants in Snowflake must always be enclosed between\ndelimiter characters. Snowflake supports using either of the following to delimit string constants:\nSingle quotes\nPairs of dollar signs\nSingle quotes\nPairs of dollar signs"
      },
      {
        "heading": "Single-quoted string constants",
        "tables": [
          {
            "headers": [
              "Escape sequence",
              "Character represented"
            ],
            "rows": [
              [
                "Simple escape sequences",
                ""
              ],
              [
                "\\'",
                "A single quote (') character."
              ],
              [
                "\\\"",
                "A double quote (\") character."
              ],
              [
                "\\\\",
                "A backslash (\\) character."
              ],
              [
                "\\b",
                "A backspace character."
              ],
              [
                "\\f",
                "A formfeed character."
              ],
              [
                "\\n",
                "A newline (linefeed) character."
              ],
              [
                "\\r",
                "A carriage return character."
              ],
              [
                "\\t",
                "A tab character."
              ],
              [
                "\\0",
                "An ASCII NUL character."
              ],
              [
                "Octal escape sequences",
                ""
              ],
              [
                "\\ooo",
                "ASCII character in octal notation (that is, where each o represents an octal digit)."
              ],
              [
                "Hexadecimal escape sequences",
                ""
              ],
              [
                "\\xhh",
                "ASCII character in hexadecimal notation (that is, where each h represents a hexadecimal digit)."
              ],
              [
                "Unicode escape sequences",
                ""
              ],
              [
                "\\uhhhh",
                "Unicode character in hexadecimal notation (that is, where each h represents a hexadecimal digit). The number of hexadecimal digits must be exactly four."
              ]
            ]
          }
        ]
      },
      {
        "heading": "Dollar-quoted string constants",
        "tables": [
          {
            "headers": [
              "Example using single quote delimiters",
              "Example using double dollar sign delimiters"
            ],
            "rows": [
              [
                "'string with a \\' character'\n\nCopy",
                "$$string with a ' character$$\n\nCopy"
              ],
              [
                "'regular expression with \\\\ characters: \\\\d{2}-\\\\d{3}-\\\\d{4}'\n\nCopy",
                "$$regular expression with \\ characters: \\d{2}-\\d{3}-\\d{4}$$\n\nCopy"
              ],
              [
                "'string with a newline\\ncharacter'\n\nCopy",
                "$$string with a newline\ncharacter$$\n\nCopy"
              ]
            ]
          }
        ]
      }
    ]
  },
  {
    "category": "Logical data types",
    "url": "https://docs.snowflake.com/en/sql-reference/data-types-logical",
    "details": [
      {
        "heading": "Logical data types",
        "description": "\nThis topic describes the logical data types supported in Snowflake."
      },
      {
        "heading": "Data types",
        "description": "\nSnowflake supports a single logical data type (BOOLEAN)."
      },
      {
        "heading": "BOOLEAN",
        "description": "\nBOOLEAN can have TRUE or FALSE values. BOOLEAN can also have an UNKNOWN value, which is represented by NULL.\nBOOLEAN columns can be used in expressions (for example, a SELECT list),\nas well as predicates (for example, a WHERE clause).\nThe BOOLEAN data type enables support for Ternary logic."
      },
      {
        "heading": "BOOLEAN conversion",
        "description": "\nSnowflake supports conversion to and from BOOLEAN."
      },
      {
        "heading": "Conversion to BOOLEAN",
        "description": "\nNon-BOOLEAN values can be converted to BOOLEAN values explicitly or implicitly.\nYou can explicitly convert specific text string and numeric values\nto BOOLEAN values by using the TO_BOOLEAN or CAST functions:\nSnowflake can implicitly convert specific text string and numeric values to BOOLEAN values:",
        "definitions": [
          {
            "term": "String conversion:",
            "definition": "Strings converted to TRUE: 'true', 't', 'yes', 'y', 'on', '1'. Strings converted to FALSE: 'false', 'f', 'no', 'n', 'off', '0'. Conversion is case-insensitive. Other text strings cant be converted to BOOLEAN values."
          },
          {
            "term": "Numeric conversion:",
            "definition": "Zero (0) is converted to FALSE. Any non-zero value is converted to TRUE."
          },
          {
            "term": "String conversion:",
            "definition": "'true' is converted to TRUE. 'false' is converted to FALSE. Conversion is case-insensitive."
          },
          {
            "term": "Numeric conversion:",
            "definition": "Zero (0) is converted to FALSE. Any non-zero value is converted to TRUE."
          }
        ]
      },
      {
        "heading": "Conversion from BOOLEAN",
        "description": "\nBOOLEAN values can be converted to non-BOOLEAN values explicitly or implicitly.\nYou can explicitly cast BOOLEAN values to text string or numeric values:\nSnowflake can implicitly convert BOOLEAN values to text string values:",
        "definitions": [
          {
            "term": "String conversion:",
            "definition": "TRUE is converted to 'true'. FALSE is converted to 'false'."
          },
          {
            "term": "Numeric conversion:",
            "definition": "TRUE is converted to 1. FALSE is converted to 0."
          },
          {
            "term": "String conversion:",
            "definition": "TRUE is converted to 'true'. FALSE is converted to 'false'."
          }
        ]
      },
      {
        "heading": "Examples",
        "description": "\nCreate a table and insert values:\nThe following query includes a BOOLEAN-typed expression:\nThe following example uses a BOOLEAN column in predicates:\nThe following example casts a text value to a BOOLEAN value. The example uses\nthe SYSTEM$TYPEOF to show the type of the value\nafter the conversion.\nThe following example casts a number value to a BOOLEAN value:\nIn this example, Snowflake implicitly converts a BOOLEAN value to a text value:\nOn this page\nData types\nBOOLEAN conversion\nExamples\nRelated content\nTernary logic\nConversion functions\nData type conversion\nWe use cookies to improve your experience on our site. By accepting, you agree to our privacy policy.\nEnglish\nFranais\nDeutsch\n\n\nPortugus\n",
        "syntax": [
          "CREATE OR REPLACE TABLE test_boolean(\n  b BOOLEAN,\n  n NUMBER,\n  s STRING);\n\nINSERT INTO test_boolean VALUES\n  (true, 1, 'yes'),\n  (false, 0, 'no'),\n  (NULL, NULL, NULL);\n\nSELECT * FROM test_boolean;",
          "+-------+------+------+\n| B     |    N | S    |\n|-------+------+------|\n| True  |    1 | yes  |\n| False |    0 | no   |\n| NULL  | NULL | NULL |\n+-------+------+------+",
          "SELECT b, n, NOT b AND (n < 1) FROM test_boolean;",
          "+-------+------+-------------------+\n| B     |    N | NOT B AND (N < 1) |\n|-------+------+-------------------|\n| True  |    1 | False             |\n| False |    0 | True              |\n| NULL  | NULL | NULL              |\n+-------+------+-------------------+",
          "SELECT * FROM test_boolean WHERE NOT b AND (n < 1);",
          "+-------+---+----+\n| B     | N | S  |\n|-------+---+----|\n| False | 0 | no |\n+-------+---+----+",
          "SELECT s,\n       TO_BOOLEAN(s),\n       SYSTEM$TYPEOF(TO_BOOLEAN(s))\n  FROM test_boolean;",
          "+------+---------------+------------------------------+\n| S    | TO_BOOLEAN(S) | SYSTEM$TYPEOF(TO_BOOLEAN(S)) |\n|------+---------------+------------------------------|\n| yes  | True          | BOOLEAN[SB1]                 |\n| no   | False         | BOOLEAN[SB1]                 |\n| NULL | NULL          | BOOLEAN[SB1]                 |\n+------+---------------+------------------------------+",
          "SELECT n,\n       TO_BOOLEAN(n),\n       SYSTEM$TYPEOF(TO_BOOLEAN(n))\n  FROM test_boolean;",
          "+------+---------------+------------------------------+\n| N    | TO_BOOLEAN(N) | SYSTEM$TYPEOF(TO_BOOLEAN(N)) |\n|------+---------------+------------------------------|\n| 1    | True          | BOOLEAN[SB1]                 |\n| 0    | False         | BOOLEAN[SB1]                 |\n| NULL | NULL          | BOOLEAN[SB1]                 |\n+------+---------------+------------------------------+",
          "SELECT 'Text for ' || s || ' is ' || b AS result,\n       SYSTEM$TYPEOF('Text for ' || s || ' is ' || b) AS type_of_result\n  FROM test_boolean;",
          "+----------------------+-------------------------+\n| RESULT               | TYPE_OF_RESULT          |\n|----------------------+-------------------------|\n| Text for yes is true | VARCHAR(134217728)[LOB] |\n| Text for no is false | VARCHAR(134217728)[LOB] |\n| NULL                 | VARCHAR(134217728)[LOB] |\n+----------------------+-------------------------+"
        ]
      }
    ]
  },
  {
    "category": "Date & time data types",
    "url": "https://docs.snowflake.com/en/sql-reference/data-types-datetime",
    "details": [
      {
        "heading": "Date & time data types",
        "description": "\nSnowflake supports data types for managing dates, times, and timestamps (combined date + time). Snowflake also supports formats for\nstring constants used in manipulating dates, times, and timestamps."
      },
      {
        "heading": "Data types",
        "description": "\nSnowflake supports the following date and time data types:\nDATE\nDATETIME\nTIME\nTIMESTAMP_LTZ , TIMESTAMP_NTZ , TIMESTAMP_TZ\nDATE\nDATETIME\nTIME\nTIMESTAMP_LTZ , TIMESTAMP_NTZ , TIMESTAMP_TZ\nNote\nFor DATE and TIMESTAMP data, Snowflake recommends using years between 1582 and 9999. Snowflake accepts some\nyears outside this range, but years prior to 1582 should be avoided due to\nlimitations on the Gregorian Calendar."
      },
      {
        "heading": "DATE",
        "description": "\nSnowflake supports a single DATE data type for storing dates (with no time elements).\nDATE accepts dates in the most common forms (YYYY-MM-DD, DD-MON-YYYY, and so on).\nIn addition, all accepted TIMESTAMP values are valid inputs for dates, but the TIME information is truncated."
      },
      {
        "heading": "DATETIME",
        "description": "\nDATETIME is an alias for TIMESTAMP_NTZ."
      },
      {
        "heading": "TIME",
        "description": "\nSnowflake supports a single TIME data type for storing times in the form of HH:MI:SS.\nTIME supports an optional precision parameter for fractional seconds (for example, TIME(3)).\nTime precision can range from 0 (seconds) to 9 (nanoseconds). The default precision is 9.\nAll TIME values must be between 00:00:00 and 23:59:59.999999999. TIME internally stores wallclock time, and all operations on TIME values are performed\nwithout taking any time zone into consideration."
      },
      {
        "heading": "TIMESTAMP_LTZ , TIMESTAMP_NTZ , TIMESTAMP_TZ",
        "description": "\nSnowflake supports three variations of timestamp.\nAttention\nTIMESTAMP_TZ currently only stores the offset of a given time zone, not the actual time zone, at the moment of creation for a given value. This is especially\nimportant for daylight saving time, which is not utilized by UTC.\nFor example, with the TIMEZONE parameter set to \"America/Los_Angeles\", converting a value to TIMESTAMP_TZ in January of a given year stores the\ntime zone offset of -0800. If six months are later added to the value, the -0800 offset is retained, even though in July the offset for Los Angeles is\n-0700. This is because, after the value is created, the actual time zone information (\"America/Los_Angeles\") is no longer available. The following code\nsample illustrates this behavior:\nTIMESTAMP in Snowflake is a user-specified alias associated with one of the TIMESTAMP_* variations. In all operations where TIMESTAMP is used, the associated TIMESTAMP_*\nvariation is automatically used. The TIMESTAMP data type is never stored in tables.\nThe TIMESTAMP_* variation associated with TIMESTAMP is specified by the TIMESTAMP_TYPE_MAPPING session parameter. The default is TIMESTAMP_NTZ.\nAll timestamp variations, as well as the TIMESTAMP alias, support an optional precision parameter for fractional\nseconds (for example, TIMESTAMP(3)). Timestamp precision can range from 0 (seconds) to 9 (nanoseconds). The default precision is 9.\nThese examples create a table using different timestamps.\nFirst, create a table with a TIMESTAMP column (mapped to TIMESTAMP_NTZ):\nNext, explicitly use one of the TIMESTAMP variations (TIMESTAMP_LTZ):\nUse TIMESTAMP_LTZ with different time zones:\nThis query shows that the time for January 2nd is 08:00 in Los Angeles (which is 16:00 in UTC):\nNext, note that the times change with a different time zone:\nCreate a table and use TIMESTAMP_NTZ:\nNote that both times from different time zones are converted to the same wallclock time:\nNext, note that changing the session time zone doesnt affect the results:\nCreate a table and use TIMESTAMP_TZ:\nNote that the January 1st record inherited the session time zone,\nand America/Los_Angeles was converted to a numeric time zone offset:\nNext, note that changing the session time zone doesnt affect the results:",
        "syntax": [
          "SELECT '2024-01-01 00:00:00 +0000'::TIMESTAMP_TZ = '2024-01-01 01:00:00 +0100'::TIMESTAMP_TZ;",
          "SELECT '2024-01-01 12:00:00'::TIMESTAMP_TZ;",
          "+-------------------------------------+\n| '2024-01-01 12:00:00'::TIMESTAMP_TZ |\n|-------------------------------------|\n| 2024-01-01 12:00:00.000 -0800       |\n+-------------------------------------+",
          "SELECT DATEADD(MONTH, 6, '2024-01-01 12:00:00'::TIMESTAMP_TZ);",
          "+--------------------------------------------------------+\n| DATEADD(MONTH, 6, '2024-01-01 12:00:00'::TIMESTAMP_TZ) |\n|--------------------------------------------------------|\n| 2024-07-01 12:00:00.000 -0800                          |\n+--------------------------------------------------------+",
          "ALTER SESSION SET TIMESTAMP_TYPE_MAPPING = TIMESTAMP_NTZ;\n\nCREATE OR REPLACE TABLE ts_test(ts TIMESTAMP);\n\nDESC TABLE ts_test;",
          "+------+------------------+--------+-------+---------+-------------+------------+-------+------------+---------+-------------+----------------+\n| name | type             | kind   | null? | default | primary key | unique key | check | expression | comment | policy name | privacy domain |\n|------+------------------+--------+-------+---------+-------------+------------+-------+------------+---------+-------------+----------------|\n| TS   | TIMESTAMP_NTZ(9) | COLUMN | Y     | NULL    | N           | N          | NULL  | NULL       | NULL    | NULL        | NULL           |\n+------+------------------+--------+-------+---------+-------------+------------+-------+------------+---------+-------------+----------------+",
          "CREATE OR REPLACE TABLE ts_test(ts TIMESTAMP_LTZ);\n\nDESC TABLE ts_test;",
          "+------+------------------+--------+-------+---------+-------------+------------+-------+------------+---------+-------------+----------------+\n| name | type             | kind   | null? | default | primary key | unique key | check | expression | comment | policy name | privacy domain |\n|------+------------------+--------+-------+---------+-------------+------------+-------+------------+---------+-------------+----------------|\n| TS   | TIMESTAMP_LTZ(9) | COLUMN | Y     | NULL    | N           | N          | NULL  | NULL       | NULL    | NULL        | NULL           |\n+------+------------------+--------+-------+---------+-------------+------------+-------+------------+---------+-------------+----------------+",
          "CREATE OR REPLACE TABLE ts_test(ts TIMESTAMP_LTZ);\n\nALTER SESSION SET TIMEZONE = 'America/Los_Angeles';\n\nINSERT INTO ts_test VALUES('2024-01-01 16:00:00');\nINSERT INTO ts_test VALUES('2024-01-02 16:00:00 +00:00');",
          "SELECT ts, HOUR(ts) FROM ts_test;",
          "+-------------------------------+----------+\n| TS                            | HOUR(TS) |\n|-------------------------------+----------|\n| 2024-01-01 16:00:00.000 -0800 |       16 |\n| 2024-01-02 08:00:00.000 -0800 |        8 |\n+-------------------------------+----------+",
          "ALTER SESSION SET TIMEZONE = 'America/New_York';\n\nSELECT ts, HOUR(ts) FROM ts_test;",
          "+-------------------------------+----------+\n| TS                            | HOUR(TS) |\n|-------------------------------+----------|\n| 2024-01-01 19:00:00.000 -0500 |       19 |\n| 2024-01-02 11:00:00.000 -0500 |       11 |\n+-------------------------------+----------+",
          "CREATE OR REPLACE TABLE ts_test(ts TIMESTAMP_NTZ);\n\nALTER SESSION SET TIMEZONE = 'America/Los_Angeles';\n\nINSERT INTO ts_test VALUES('2024-01-01 16:00:00');\nINSERT INTO ts_test VALUES('2024-01-02 16:00:00 +00:00');",
          "SELECT ts, HOUR(ts) FROM ts_test;",
          "+-------------------------+----------+\n| TS                      | HOUR(TS) |\n|-------------------------+----------|\n| 2024-01-01 16:00:00.000 |       16 |\n| 2024-01-02 16:00:00.000 |       16 |\n+-------------------------+----------+",
          "ALTER SESSION SET TIMEZONE = 'America/New_York';\n\nSELECT ts, HOUR(ts) FROM ts_test;",
          "+-------------------------+----------+\n| TS                      | HOUR(TS) |\n|-------------------------+----------|\n| 2024-01-01 16:00:00.000 |       16 |\n| 2024-01-02 16:00:00.000 |       16 |\n+-------------------------+----------+",
          "CREATE OR REPLACE TABLE ts_test(ts TIMESTAMP_TZ);\n\nALTER SESSION SET TIMEZONE = 'America/Los_Angeles';\n\nINSERT INTO ts_test VALUES('2024-01-01 16:00:00');\nINSERT INTO ts_test VALUES('2024-01-02 16:00:00 +00:00');",
          "SELECT ts, HOUR(ts) FROM ts_test;",
          "+-------------------------------+----------+\n| TS                            | HOUR(TS) |\n|-------------------------------+----------|\n| 2024-01-01 16:00:00.000 -0800 |       16 |\n| 2024-01-02 16:00:00.000 +0000 |       16 |\n+-------------------------------+----------+",
          "ALTER SESSION SET TIMEZONE = 'America/New_York';\n\nSELECT ts, HOUR(ts) FROM ts_test;",
          "+-------------------------------+----------+\n| TS                            | HOUR(TS) |\n|-------------------------------+----------|\n| 2024-01-01 16:00:00.000 -0800 |       16 |\n| 2024-01-02 16:00:00.000 +0000 |       16 |\n+-------------------------------+----------+"
        ],
        "definitions": [
          {
            "term": "TIMESTAMP_LTZ:",
            "definition": "TIMESTAMP_LTZ internally stores UTC time with a specified precision. However, all operations are performed in the current sessions time zone, controlled by the\nTIMEZONE session parameter. Aliases for TIMESTAMP_LTZ: TIMESTAMPLTZ TIMESTAMP WITH LOCAL TIME ZONE"
          },
          {
            "term": "TIMESTAMP_NTZ:",
            "definition": "TIMESTAMP_NTZ internally stores wallclock time with a specified precision. All operations are performed without taking any time zone into account. If the output format contains a time zone, the UTC indicator (Z) is displayed. TIMESTAMP_NTZ is the default for TIMESTAMP. Aliases for TIMESTAMP_NTZ: TIMESTAMPNTZ TIMESTAMP WITHOUT TIME ZONE DATETIME"
          },
          {
            "term": "TIMESTAMP_TZ:",
            "definition": "TIMESTAMP_TZ internally stores UTC time together with an associated time zone offset. When a time zone isnt provided, the session time zone offset is used. All\noperations are performed with the time zone offset specific to each record. Aliases for TIMESTAMP_TZ: TIMESTAMPTZ TIMESTAMP WITH TIME ZONE TIMESTAMP_TZ values are compared based on their times in UTC. For example, the following comparison between\ndifferent times in different timezones returns TRUE because the two values have equivalent times in UTC."
          }
        ]
      },
      {
        "heading": "Supported calendar",
        "description": "\nSnowflake uses the Gregorian Calendar for all dates and timestamps. The Gregorian Calendar starts in the year 1582, but recognizes prior years, which is important to note\nbecause Snowflake does not adjust dates prior to 1582 (or calculations involving dates prior to 1582) to match the Julian Calendar. The UUUU format element\nsupports negative years."
      },
      {
        "heading": "Date and time formats",
        "tables": [
          {
            "headers": [
              "Format element",
              "Description"
            ],
            "rows": [
              [
                "YYYY",
                "Four-digit year."
              ],
              [
                "YY",
                "Two-digit year, controlled by the TWO_DIGIT_CENTURY_START session parameter. For example, when set to 1980, values of 79 and 80 are parsed as 2079 and 1980 respectively."
              ],
              [
                "MM",
                "Two-digit month (01 = January, and so on)."
              ],
              [
                "MON",
                "Full or abbreviated month name."
              ],
              [
                "MMMM",
                "Full month name."
              ],
              [
                "DD",
                "Two-digit day of month (01 through 31)."
              ],
              [
                "DY",
                "Abbreviated day of week."
              ],
              [
                "HH24",
                "Two digits for hour (00 through 23). You must not specify AM / PM."
              ],
              [
                "HH12",
                "Two digits for hour (01 through 12). You can specify AM / PM."
              ],
              [
                "AM , PM",
                "Ante meridiem (AM) / post meridiem (PM). Use this only with HH12 (not with HH24)."
              ],
              [
                "MI",
                "Two digits for minute (00 through 59)."
              ],
              [
                "SS",
                "Two digits for second (00 through 59)."
              ],
              [
                "FF[0-9]",
                "Fractional seconds with precision 0 (seconds) to 9 (nanoseconds), e.g. FF, FF0, FF3, FF9. Specifying FF is equivalent to FF9 (nanoseconds)."
              ],
              [
                "TZH:TZM , TZHTZM , TZH",
                "Time zone hour and minute, offset from UTC. Can be prefixed by +/- for sign."
              ],
              [
                "UUUU",
                "Four-digit year in ISO format, which are negative for BCE years."
              ]
            ]
          }
        ]
      },
      {
        "heading": "Examples of using date and time formats",
        "description": "\nThe following example uses FF to indicate that the output has 9 digits in the fractional seconds field:",
        "syntax": [
          "CREATE OR REPLACE TABLE timestamp_demo_table(\n  tstmp TIMESTAMP,\n  tstmp_tz TIMESTAMP_TZ,\n  tstmp_ntz TIMESTAMP_NTZ,\n  tstmp_ltz TIMESTAMP_LTZ);\nINSERT INTO timestamp_demo_table (tstmp, tstmp_tz, tstmp_ntz, tstmp_ltz) VALUES (\n  '2024-03-12 01:02:03.123456789',\n  '2024-03-12 01:02:03.123456789',\n  '2024-03-12 01:02:03.123456789',\n  '2024-03-12 01:02:03.123456789');",
          "ALTER SESSION SET TIMESTAMP_OUTPUT_FORMAT = 'YYYY-MM-DD HH24:MI:SS.FF';\nALTER SESSION SET TIMESTAMP_TZ_OUTPUT_FORMAT = 'YYYY-MM-DD HH24:MI:SS.FF';\nALTER SESSION SET TIMESTAMP_NTZ_OUTPUT_FORMAT = 'YYYY-MM-DD HH24:MI:SS.FF';\nALTER SESSION SET TIMESTAMP_LTZ_OUTPUT_FORMAT = 'YYYY-MM-DD HH24:MI:SS.FF';",
          "SELECT tstmp, tstmp_tz, tstmp_ntz, tstmp_ltz\n  FROM timestamp_demo_table;",
          "+-------------------------------+-------------------------------+-------------------------------+-------------------------------+\n| TSTMP                         | TSTMP_TZ                      | TSTMP_NTZ                     | TSTMP_LTZ                     |\n|-------------------------------+-------------------------------+-------------------------------+-------------------------------|\n| 2024-03-12 01:02:03.123456789 | 2024-03-12 01:02:03.123456789 | 2024-03-12 01:02:03.123456789 | 2024-03-12 01:02:03.123456789 |\n+-------------------------------+-------------------------------+-------------------------------+-------------------------------+"
        ]
      },
      {
        "heading": "Date and time constants",
        "description": "\nConstants (also known as literals) are fixed data values. Snowflake supports using string constants to specify fixed date, time, or timestamp values. String\nconstants must always be enclosed between delimiter characters. Snowflake supports using single quotes to delimit string constants.\nFor example:\nThe string is parsed as a DATE, TIME, or TIMESTAMP value based on the input format for the data type, as set through the following parameters:\nFor example, to insert a specific date into a column in a table:",
        "syntax": [
          "DATE '2024-08-14'\nTIME '10:03:56'\nTIMESTAMP '2024-08-15 10:59:43'",
          "CREATE TABLE t1 (d1 DATE);\n\nINSERT INTO t1 (d1) VALUES (DATE '2024-08-15');"
        ],
        "definitions": [
          {
            "term": "DATE:",
            "definition": "DATE_INPUT_FORMAT"
          },
          {
            "term": "TIME:",
            "definition": "TIME_INPUT_FORMAT"
          },
          {
            "term": "TIMESTAMP:",
            "definition": "TIMESTAMP_INPUT_FORMAT"
          }
        ]
      },
      {
        "heading": "Interval constants",
        "description": "\nYou can use interval constants to add or subtract a period of time to or from a date, time, or timestamp. Interval constants are implemented\nusing the INTERVAL keyword, which has the following syntax:\nAs with all string constants, Snowflake requires single quotes to delimit interval constants.\nThe INTERVAL keyword supports one more integers and, optionally, one or more date or time parts. For example:\nINTERVAL '1 year' represents one year.\nINTERVAL '4 years, 5 months, 3 hours' represents four years, five months, and three hours.\nINTERVAL '1 year' represents one year.\nINTERVAL '4 years, 5 months, 3 hours' represents four years, five months, and three hours.\nIf a date or time part isnt specified, the interval represents seconds (for example, INTERVAL '2' is the same\nas INTERVAL '2 seconds'). Note that this is different from the default unit of time for performing date arithmetic.\nFor more details, see Simple arithmetic for dates.\nFor the list of supported date and time parts, see Supported Date and Time Parts for Intervals.\nNote\nThe order of interval increments is important. The increments are added or subtracted in the order listed. For example:\n\n\nINTERVAL '1 year, 1 day' first adds or subtracts a year and then a day.\nINTERVAL '1 day, 1 year' first adds or subtracts a day and then a year.\n\nOrdering differences can affect calculations influenced by calendar events, such as leap years:\nSELECT TO_DATE ('2019-02-28') + INTERVAL '1 day, 1 year';\n\nCopy\n+---------------------------------------------------+\n| TO_DATE ('2019-02-28') + INTERVAL '1 DAY, 1 YEAR' |\n|---------------------------------------------------|\n| 2020-03-01                                        |\n+---------------------------------------------------+\n\n\nSELECT TO_DATE ('2019-02-28') + INTERVAL '1 year, 1 day';\n\nCopy\n+---------------------------------------------------+\n| TO_DATE ('2019-02-28') + INTERVAL '1 YEAR, 1 DAY' |\n|---------------------------------------------------|\n| 2020-02-29                                        |\n+---------------------------------------------------+\nINTERVAL '1 year, 1 day' first adds or subtracts a year and then a day.\nINTERVAL '1 day, 1 year' first adds or subtracts a day and then a year.\nINTERVAL is not a data type (that is, you cant define a table column to be of data type INTERVAL). Intervals can only be used in date, time, and timestamp arithmetic.\nYou cant use an interval with a SQL variable. For example, the following query returns an error:\nSET v1 = '1 year';\n\nSELECT TO_DATE('2023-04-15') + INTERVAL $v1;\n\nCopy\nThe order of interval increments is important. The increments are added or subtracted in the order listed. For example:\nINTERVAL '1 year, 1 day' first adds or subtracts a year and then a day.\nINTERVAL '1 day, 1 year' first adds or subtracts a day and then a year.\nINTERVAL '1 year, 1 day' first adds or subtracts a year and then a day.\nINTERVAL '1 day, 1 year' first adds or subtracts a day and then a year.\nOrdering differences can affect calculations influenced by calendar events, such as leap years:\nINTERVAL is not a data type (that is, you cant define a table column to be of data type INTERVAL). Intervals can only be used in date, time, and timestamp arithmetic.\nYou cant use an interval with a SQL variable. For example, the following query returns an error:",
        "syntax": [
          "{ + | - } INTERVAL '<integer> [ <date_time_part> ] [ , <integer> [ <date_time_part> ] ... ]'",
          "SELECT TO_DATE ('2019-02-28') + INTERVAL '1 day, 1 year';",
          "+---------------------------------------------------+\n| TO_DATE ('2019-02-28') + INTERVAL '1 DAY, 1 YEAR' |\n|---------------------------------------------------|\n| 2020-03-01                                        |\n+---------------------------------------------------+",
          "SELECT TO_DATE ('2019-02-28') + INTERVAL '1 year, 1 day';",
          "+---------------------------------------------------+\n| TO_DATE ('2019-02-28') + INTERVAL '1 YEAR, 1 DAY' |\n|---------------------------------------------------|\n| 2020-02-29                                        |\n+---------------------------------------------------+",
          "SET v1 = '1 year';\n\nSELECT TO_DATE('2023-04-15') + INTERVAL $v1;"
        ]
      },
      {
        "heading": "Supported date and time parts for intervals",
        "tables": [
          {
            "headers": [
              "Date or Time Part",
              "Abbreviations / Variations"
            ],
            "rows": [
              [
                "year",
                "y , yy , yyy , yyyy , yr , years , yrs"
              ],
              [
                "quarter",
                "q , qtr , qtrs , quarters"
              ],
              [
                "month",
                "mm , mon , mons , months"
              ],
              [
                "week",
                "w , wk , weekofyear , woy , wy , weeks"
              ],
              [
                "day",
                "d , dd , days, dayofmonth"
              ],
              [
                "hour",
                "h , hh , hr , hours , hrs"
              ],
              [
                "minute",
                "m , mi , min , minutes , mins"
              ],
              [
                "second",
                "s , sec , seconds , secs"
              ],
              [
                "millisecond",
                "ms , msec , milliseconds"
              ],
              [
                "microsecond",
                "us , usec , microseconds"
              ],
              [
                "nanosecond",
                "ns , nsec , nanosec , nsecond , nanoseconds , nanosecs , nseconds"
              ]
            ]
          }
        ]
      },
      {
        "heading": "Interval examples",
        "description": "\nAdd a year interval to a specific date:\nAdd an interval of 3 hours and 18 minutes to a specific time:\nAdd a complex interval to the output of the CURRENT_TIMESTAMP function:\nThe following is sample output. The output is different when the current timestamp is different.\nAdd a complex interval with abbreviated date/time part notation to a specific date:\nQuery a table of employee information and return the names of employees who were hired within the past two years and three months:\nFilter a TIMESTAMP column named ts from a table named t1 and add four seconds to each returned value:",
        "syntax": [
          "SELECT TO_DATE('2023-04-15') + INTERVAL '1 year';",
          "+-------------------------------------------+\n| TO_DATE('2023-04-15') + INTERVAL '1 YEAR' |\n|-------------------------------------------|\n| 2024-04-15                                |\n+-------------------------------------------+",
          "SELECT TO_TIME('04:15:29') + INTERVAL '3 hours, 18 minutes';",
          "+------------------------------------------------------+\n| TO_TIME('04:15:29') + INTERVAL '3 HOURS, 18 MINUTES' |\n|------------------------------------------------------|\n| 07:33:29                                             |\n+------------------------------------------------------+",
          "SELECT CURRENT_TIMESTAMP + INTERVAL\n    '1 year, 3 quarters, 4 months, 5 weeks, 6 days, 7 minutes, 8 seconds,\n    1000 milliseconds, 4000000 microseconds, 5000000001 nanoseconds'\n  AS complex_interval1;",
          "+-------------------------------+\n| COMPLEX_INTERVAL1             |\n|-------------------------------|\n| 2026-11-07 18:07:19.875000001 |\n+-------------------------------+",
          "SELECT TO_DATE('2025-01-17') + INTERVAL\n    '1 y, 3 q, 4 mm, 5 w, 6 d, 7 h, 9 m, 8 s,\n    1000 ms, 445343232 us, 898498273498 ns'\n  AS complex_interval2;",
          "+-------------------------------+\n| COMPLEX_INTERVAL2             |\n|-------------------------------|\n| 2027-03-30 07:31:32.841505498 |\n+-------------------------------+",
          "SELECT name, hire_date\n  FROM employees\n  WHERE hire_date > CURRENT_DATE - INTERVAL '2 y, 3 month';",
          "SELECT ts + INTERVAL '4 seconds'\n  FROM t1\n  WHERE ts > TO_TIMESTAMP('2024-04-05 01:02:03');"
        ]
      },
      {
        "heading": "Simple arithmetic for dates",
        "description": "\nIn addition to using interval constants to add to and subtract from dates, times, and timestamps, you can also\nadd and subtract days to and from DATE values, in the form of { + | - } integer, where integer\nspecifies the number of days to add or subtract.\nNote\nTIME and TIMESTAMP values dont yet support simple arithmetic."
      },
      {
        "heading": "Date arithmetic examples",
        "description": "\nAdd one day to a specific date:\nSubtract four days from a specific date:\nQuery a table named employees and return the names of people who left the company, but were employed more than 365 days:\nOn this page\nData types\nSupported calendar\nDate and time formats\nDate and time constants\nInterval constants\nSimple arithmetic for dates\nRelated content\nDate & time functions\nData type conversion\nWe use cookies to improve your experience on our site. By accepting, you agree to our privacy policy.\nEnglish\nFranais\nDeutsch\n\n\nPortugus\n",
        "syntax": [
          "SELECT TO_DATE('2024-04-15') + 1;",
          "+---------------------------+\n| TO_DATE('2024-04-15') + 1 |\n|---------------------------|\n| 2024-04-16                |\n+---------------------------+",
          "SELECT TO_DATE('2024-04-15') - 4;",
          "+---------------------------+\n| TO_DATE('2024-04-15') - 4 |\n|---------------------------|\n| 2024-04-11                |\n+---------------------------+",
          "SELECT name\n  FROM employees\n  WHERE end_date > start_date + 365;"
        ]
      }
    ]
  },
  {
    "category": "Semi-structured data types",
    "url": "https://docs.snowflake.com/en/sql-reference/data-types-semistructured",
    "details": [
      {
        "heading": "Semi-structured data types",
        "description": "\nThe following Snowflake data types can contain other data types:\nVARIANT (can contain a value of any other data type).\nOBJECT (can directly contain a VARIANT value, and thus indirectly contain a value of any\nother data type, including itself).\nARRAY (can directly contain a VARIANT value, and thus indirectly contain a value of any\nother data type, including itself).\nVARIANT (can contain a value of any other data type).\nOBJECT (can directly contain a VARIANT value, and thus indirectly contain a value of any\nother data type, including itself).\nARRAY (can directly contain a VARIANT value, and thus indirectly contain a value of any\nother data type, including itself).\nWe often refer to these data types as semi-structured data types. Strictly speaking, OBJECT is the only one of these\ndata types that, by itself, has all of the characteristics of a true\nsemi-structured data type. However, combining these data types allows you to\nexplicitly represent arbitrary hierarchical data structures,\nwhich can be used to load and operate on data in semi-structured formats (such as JSON,\nAvro, ORC, Parquet, or\nXML).\nNote\nFor information about structured data types (for example, ARRAY(INTEGER), OBJECT(city VARCHAR), or MAP(VARCHAR, VARCHAR),\nsee Structured data types."
      },
      {
        "heading": "VARIANT",
        "description": "\nA VARIANT value can store a value of any other type, including OBJECT and ARRAY values."
      },
      {
        "heading": "Characteristics of a VARIANT value",
        "description": "\nA VARIANT value can have a maximum size of up to 128 MB of uncompressed data. However, in practice,\nthe maximum size is usually smaller because of internal overhead. The maximum size is also dependent\non the object being stored.\nNote\nIf the 2025_03 behavior change bundle is disabled, the maximum size for a VARIANT value is 16 MB. This behavior change\nbundle is enabled by default. For more information, see Size limits for database objects."
      },
      {
        "heading": "Inserting VARIANT data",
        "description": "\nTo insert VARIANT data directly, use INSERT INTO ... SELECT. The following example shows how to insert JSON-formatted\ndata into a VARIANT value:",
        "syntax": [
          "CREATE OR REPLACE TABLE variant_insert (v VARIANT);\nINSERT INTO variant_insert (v)\n  SELECT PARSE_JSON('{\"key3\": \"value3\", \"key4\": \"value4\"}');\nSELECT * FROM variant_insert;",
          "+---------------------+\n| V                   |\n|---------------------|\n| {                   |\n|   \"key3\": \"value3\", |\n|   \"key4\": \"value4\"  |\n| }                   |\n+---------------------+"
        ]
      },
      {
        "heading": "Using VARIANT values",
        "description": "\nTo convert a value to or from the VARIANT data type, you can explicitly cast using the CAST\nfunction, the TO_VARIANT function, or the :: operator (for example, expression::VARIANT).\nIn some situations, a value can be implicitly cast to a VARIANT value. For details, see Data type conversion.\nThe following example shows how to use a VARIANT value, including how to convert from a VARIANT value and to a VARIANT value.\nCreate a table and insert a value:\nThe first UPDATE converts a FLOAT value to a VARIANT value. The second UPDATE converts a VARIANT\nvalue to a FLOAT value.\nSELECT all the values:\nAs shown in the previous example, to convert a value from the VARIANT data type, cast the VARIANT value to the\ntarget data type. For example, the following statement uses the :: operator to convert the VARIANT\nto a FLOAT:\nVARIANT data stores both the value and the data type of the value. Therefore, you can use VARIANT values in expressions where the\nvalues data type is valid without first casting the VARIANT. For example, if VARIANT column my_variant_column contains a\nnumeric value, then you can directly multiply my_variant_column by another numeric value:\nYou can retrieve the values native data type by using the TYPEOF function.\nBy default, when VARCHAR, DATE, TIME, and TIMESTAMP values are retrieved from a VARIANT column, the values are surrounded by double\nquotes. You can eliminate the double quotes by explicitly casting the values to the underlying data types (for example, from VARIANT to\nVARCHAR). For example:\nA VARIANT value can be missing (contain SQL NULL), which is different from a VARIANT null value, which is a real value used to\nrepresent a null value in semi-structured data. VARIANT null is a true value that compares as equal to itself.\nFor more information, see NULL values.\nIf data was loaded from JSON format and stored in a VARIANT column, then the following considerations apply:\nFor data that is mostly regular and uses only native JSON types (such as strings and numbers), the performance is very similar for\nstorage and query operations on relational data and data in a VARIANT column.\nFor non-native data (such as dates and timestamps), the values are stored as strings when loaded into a VARIANT column. Therefore,\noperations on these values might be slower and also consume more space than when stored in a relational column with the corresponding\ndata type.\nFor data that is mostly regular and uses only native JSON types (such as strings and numbers), the performance is very similar for\nstorage and query operations on relational data and data in a VARIANT column.\nFor non-native data (such as dates and timestamps), the values are stored as strings when loaded into a VARIANT column. Therefore,\noperations on these values might be slower and also consume more space than when stored in a relational column with the corresponding\ndata type.\nFor more information about using the VARIANT data type, see Considerations for semi-structured data stored in VARIANT.\nFor more information about querying semi-structured data stored in a VARIANT column, see Querying Semi-structured Data.",
        "syntax": [
          "CREATE OR REPLACE TABLE varia (float1 FLOAT, v VARIANT, float2 FLOAT);\nINSERT INTO varia (float1, v, float2) VALUES (1.23, NULL, NULL);",
          "UPDATE varia SET v = TO_VARIANT(float1);  -- converts from a FLOAT value to a VARIANT value.\nUPDATE varia SET float2 = v::FLOAT;       -- converts from a VARIANT value to a FLOAT value.",
          "SELECT * FROM varia;",
          "+--------+-----------------------+--------+\n| FLOAT1 | V                     | FLOAT2 |\n|--------+-----------------------+--------|\n|   1.23 | 1.230000000000000e+00 |   1.23 |\n+--------+-----------------------+--------+",
          "SELECT my_variant_column::FLOAT * 3.14 FROM ...;",
          "SELECT my_variant_column * 3.14 FROM ...;",
          "SELECT 'Sample', 'Sample'::VARIANT, 'Sample'::VARIANT::VARCHAR;",
          "+----------+-------------------+----------------------------+\n| 'SAMPLE' | 'SAMPLE'::VARIANT | 'SAMPLE'::VARIANT::VARCHAR |\n|----------+-------------------+----------------------------|\n| Sample   | \"Sample\"          | Sample                     |\n+----------+-------------------+----------------------------+"
        ]
      },
      {
        "heading": "Common uses for VARIANT data",
        "description": "\nVARIANT data is typically used when:\nYou want to create hierarchical data by explicitly defining a hierarchy that contains two or\nmore ARRAY values or OBJECT values.\nYou want to load JSON, Avro, ORC, or Parquet data directly, without explicitly describing the hierarchical structure of the data.\nSnowflake can convert data from JSON, Avro, ORC, or Parquet format to an internal hierarchy of\nARRAY, OBJECT, and VARIANT data and store that hierarchical data directly in a VARIANT value. Although you can manually construct\nthe data hierarchy yourself, it is usually easier to let Snowflake do it for you.\nFor more information about loading and converting semi-structured data, see Loading Semi-structured Data.\nYou want to create hierarchical data by explicitly defining a hierarchy that contains two or\nmore ARRAY values or OBJECT values.\nYou want to load JSON, Avro, ORC, or Parquet data directly, without explicitly describing the hierarchical structure of the data.\nSnowflake can convert data from JSON, Avro, ORC, or Parquet format to an internal hierarchy of\nARRAY, OBJECT, and VARIANT data and store that hierarchical data directly in a VARIANT value. Although you can manually construct\nthe data hierarchy yourself, it is usually easier to let Snowflake do it for you.\nFor more information about loading and converting semi-structured data, see Loading Semi-structured Data."
      },
      {
        "heading": "OBJECT",
        "description": "\nA Snowflake OBJECT value is analogous to a JSON object. In other programming\nlanguages, the corresponding data type is often called a dictionary, hash, or map.\nAn OBJECT value contains key-value pairs."
      },
      {
        "heading": "Characteristics of an OBJECT value",
        "description": "\nIn Snowflake semi-structured OBJECT data, each key is a VARCHAR value, and each\nvalue is a VARIANT value.\nBecause a VARIANT value can store a value of any other data type, different VARIANT values (in different key-value pairs) can have\ndifferent underlying data types. For example, an OBJECT value can hold a persons name as a VARCHAR value and a persons age as an INTEGER\nvalue. In the following example, both the name and the age are cast to VARIANT values.\nThe following considerations apply to OBJECT data:\nCurrently, Snowflake doesnt support explicitly-typed objects.\nIn a key-value pair, the key shouldnt be an empty string, and neither the key nor the value should be NULL.\nThe maximum length of an OBJECT value is 128 MB.\nIf the 2025_03 behavior change bundle is disabled, the maximum size for an OBJECT value is 16 MB. This behavior change\nbundle is enabled by default. For more information, see Size limits for database objects.\nAn OBJECT value can contain semi-structured data.\nAn OBJECT value can be used to create hierarchical data structures.\nCurrently, Snowflake doesnt support explicitly-typed objects.\nIn a key-value pair, the key shouldnt be an empty string, and neither the key nor the value should be NULL.\nThe maximum length of an OBJECT value is 128 MB.\nIf the 2025_03 behavior change bundle is disabled, the maximum size for an OBJECT value is 16 MB. This behavior change\nbundle is enabled by default. For more information, see Size limits for database objects.\nAn OBJECT value can contain semi-structured data.\nAn OBJECT value can be used to create hierarchical data structures.\nNote\nSnowflake also supports the structured OBJECT data type, which allows for values other than VARIANT values. A structured OBJECT type also defines\nthe keys that must be present in an OBJECT value of that type. For more information, see Structured data types.",
        "syntax": [
          "SELECT OBJECT_CONSTRUCT(\n  'name', 'Jones'::VARIANT,\n  'age',  42::VARIANT);"
        ]
      },
      {
        "heading": "Inserting OBJECT data",
        "description": "\nTo insert OBJECT data directly, use INSERT INTO ... SELECT.\nThe following example uses the OBJECT_CONSTRUCT function to construct the OBJECT value that it inserts.\nIn each key-value pair, the value was explicitly cast to VARIANT. Explicit casting wasnt required in these cases.\nSnowflake can implicitly cast to VARIANT. For information about implicit casting, see\nData type conversion.\nYou can also use an OBJECT constant to specify the OBJECT value to insert. For more information, see\nOBJECT constants.",
        "syntax": [
          "CREATE OR REPLACE TABLE object_example (object_column OBJECT);\nINSERT INTO object_example (object_column)\n  SELECT OBJECT_CONSTRUCT('thirteen', 13::VARIANT, 'zero', 0::VARIANT);\nSELECT * FROM object_example;",
          "+-------------------+\n| OBJECT_COLUMN     |\n|-------------------|\n| {                 |\n|   \"thirteen\": 13, |\n|   \"zero\": 0       |\n| }                 |\n+-------------------+"
        ]
      },
      {
        "heading": "OBJECT constants",
        "description": "\nA constant (also known as a literal) refers to a fixed data value. Snowflake supports using constants to specify OBJECT values.\nOBJECT constants are delimited with curly braces ({ and }).\nOBJECT constants have the following syntax:\nWhere:\nThe following are examples that specify OBJECT constants:\n{} is an empty OBJECT value.\n{ 'key1': 'value1' , 'key2': 'value2' } contains the specified key-value pairs for the OBJECT value using\nliterals for the values.\n{ 'key1': c1+1 , 'key2': c1+2 } contains the specified key-value pairs for the OBJECT value using\nexpressions for the values.\n{} is an empty OBJECT value.\n{ 'key1': 'value1' , 'key2': 'value2' } contains the specified key-value pairs for the OBJECT value using\nliterals for the values.\n{ 'key1': c1+1 , 'key2': c1+2 } contains the specified key-value pairs for the OBJECT value using\nexpressions for the values.\n{*} is a wildcard that constructs the OBJECT value from the specified data using the attribute names\nas keys and the associated values as values.\nWhen it is specified in an object constant, the wildcard can be unqualified or qualified with a table name or alias.\nFor example, both of these wildcard specifications are valid:\nSELECT {*} FROM my_table;\n\nSELECT {my_table1.*}\n  FROM my_table1 INNER JOIN my_table2\n    ON my_table2.col1 = my_table1.col1;\n\nCopy\nYou can use the ILIKE and EXCLUDE keywords in an object constant. To select specific columns, use the\nILIKE keyword. For example, the following query selects columns that match the pattern col1% in\nthe table my_table:\nSELECT {* ILIKE 'col1%'} FROM my_table;\n\nCopy\nTo exclude specific columns, use the EXCLUDE keyword. For example, the following query excludes col1 in\nthe table my_table:\nSELECT {* EXCLUDE col1} FROM my_table;\n\nCopy\nThe following query excludes col1 and col2 in the table my_table:\nSELECT {* EXCLUDE (col1, col2)} FROM my_table;\n\nCopy\nWildcards cant be mixed with key-value pairs. For example, the following wildcard specification isnt allowed:\nSELECT {*, 'k': 'v'} FROM my_table;\n\nCopy\nMore than one wildcard cant be used in one object constant. For example, the following\nwildcard specification isnt allowed:\nSELECT {t1.*, t2.*} FROM t1, t2;\n\nCopy\n{*} is a wildcard that constructs the OBJECT value from the specified data using the attribute names\nas keys and the associated values as values.\nWhen it is specified in an object constant, the wildcard can be unqualified or qualified with a table name or alias.\nFor example, both of these wildcard specifications are valid:\nYou can use the ILIKE and EXCLUDE keywords in an object constant. To select specific columns, use the\nILIKE keyword. For example, the following query selects columns that match the pattern col1% in\nthe table my_table:\nTo exclude specific columns, use the EXCLUDE keyword. For example, the following query excludes col1 in\nthe table my_table:\nThe following query excludes col1 and col2 in the table my_table:\nWildcards cant be mixed with key-value pairs. For example, the following wildcard specification isnt allowed:\nMore than one wildcard cant be used in one object constant. For example, the following\nwildcard specification isnt allowed:\nThe following statements use an OBJECT constant and the OBJECT_CONSTRUCT function to perform\nan insert of OBJECT data into a table. The OBJECT values contain the names and capital cities of two Canadian\nprovinces.\nThe following example uses a wildcard ({*}) to insert OBJECT data by getting the attribute names and\nvalues from the FROM clause. First, create a table named demo_ca_provinces with VARCHAR\nvalues that contain the province and capital names:\nInsert object data into the my_object_table using the data in the demo_ca_provinces\ntable:\nThe following example uses expressions for the values in an OBJECT constant:\nSQL statements specify string literals inside an OBJECT value with single quotes (as elsewhere in Snowflake SQL), but string\nliterals inside an OBJECT value are displayed with double quotes:",
        "syntax": [
          "{ [<key>: <value> [, <key>: <value> , ...]] }",
          "SELECT {*} FROM my_table;\n\nSELECT {my_table1.*}\n  FROM my_table1 INNER JOIN my_table2\n    ON my_table2.col1 = my_table1.col1;",
          "SELECT {* ILIKE 'col1%'} FROM my_table;",
          "SELECT {* EXCLUDE col1} FROM my_table;",
          "SELECT {* EXCLUDE (col1, col2)} FROM my_table;",
          "SELECT {*, 'k': 'v'} FROM my_table;",
          "SELECT {t1.*, t2.*} FROM t1, t2;",
          "CREATE OR REPLACE TABLE my_object_table (my_object OBJECT);\n\nINSERT INTO my_object_table (my_object)\n  SELECT { 'PROVINCE': 'Alberta'::VARIANT , 'CAPITAL': 'Edmonton'::VARIANT };\n\nINSERT INTO my_object_table (my_object)\n  SELECT OBJECT_CONSTRUCT('PROVINCE', 'Manitoba'::VARIANT , 'CAPITAL', 'Winnipeg'::VARIANT );\n\nSELECT * FROM my_object_table;",
          "+--------------------------+\n| MY_OBJECT                |\n|--------------------------|\n| {                        |\n|   \"CAPITAL\": \"Edmonton\", |\n|   \"PROVINCE\": \"Alberta\"  |\n| }                        |\n| {                        |\n|   \"CAPITAL\": \"Winnipeg\", |\n|   \"PROVINCE\": \"Manitoba\" |\n| }                        |\n+--------------------------+",
          "CREATE OR REPLACE TABLE demo_ca_provinces (province VARCHAR, capital VARCHAR);\nINSERT INTO demo_ca_provinces (province, capital) VALUES\n  ('Ontario', 'Toronto'),\n  ('British Columbia', 'Victoria');\n\nSELECT province, capital\n  FROM demo_ca_provinces\n  ORDER BY province;",
          "+------------------+----------+\n| PROVINCE         | CAPITAL  |\n|------------------+----------|\n| British Columbia | Victoria |\n| Ontario          | Toronto  |\n+------------------+----------+",
          "INSERT INTO my_object_table (my_object)\n  SELECT {*} FROM demo_ca_provinces;\n\nSELECT * FROM my_object_table;",
          "+----------------------------------+\n| MY_OBJECT                        |\n|----------------------------------|\n| {                                |\n|   \"CAPITAL\": \"Edmonton\",         |\n|   \"PROVINCE\": \"Alberta\"          |\n| }                                |\n| {                                |\n|   \"CAPITAL\": \"Winnipeg\",         |\n|   \"PROVINCE\": \"Manitoba\"         |\n| }                                |\n| {                                |\n|   \"CAPITAL\": \"Toronto\",          |\n|   \"PROVINCE\": \"Ontario\"          |\n| }                                |\n| {                                |\n|   \"CAPITAL\": \"Victoria\",         |\n|   \"PROVINCE\": \"British Columbia\" |\n| }                                |\n+----------------------------------+",
          "SET my_variable = 10;\nSELECT {'key1': $my_variable+1, 'key2': $my_variable+2};",
          "+--------------------------------------------------+\n| {'KEY1': $MY_VARIABLE+1, 'KEY2': $MY_VARIABLE+2} |\n|--------------------------------------------------|\n| {                                                |\n|   \"key1\": 11,                                    |\n|   \"key2\": 12                                     |\n| }                                                |\n+--------------------------------------------------+",
          "SELECT { 'Manitoba': 'Winnipeg' } AS province_capital;",
          "+--------------------------+\n| PROVINCE_CAPITAL         |\n|--------------------------|\n| {                        |\n|   \"Manitoba\": \"Winnipeg\" |\n| }                        |\n+--------------------------+"
        ],
        "definitions": [
          {
            "term": "key",
            "definition": "The key in a key-value pair. The key must be a string literal."
          },
          {
            "term": "value",
            "definition": "The value that is associated with the key. The value can be a literal or an expression.\nThe value can be any data type."
          }
        ]
      },
      {
        "heading": "Accessing elements of an OBJECT value by key",
        "description": "\nTo retrieve the value in an OBJECT value, specify the key in\nsquare brackets, as shown below:\nYou can also use the colon operator. The following command shows that the results are the same whether you use\nthe square brackets or the colon:\nFor more information about the colon operator, see Dot Notation, which describes\nthe use of the : and . operators to access nested data.",
        "syntax": [
          "SELECT object_column['thirteen'] FROM object_example;",
          "SELECT object_column['thirteen'],\n       object_column:thirteen\n  FROM object_example;",
          "+---------------------------+------------------------+\n| OBJECT_COLUMN['THIRTEEN'] | OBJECT_COLUMN:THIRTEEN |\n|---------------------------+------------------------|\n| 13                        | 13                     |\n+---------------------------+------------------------+"
        ]
      },
      {
        "heading": "Common uses for OBJECT data",
        "description": "\nOBJECT data is typically used when one or more of the following are true:\nYou have multiple pieces of data that are identified by strings. For example, if\nyou want to look up information by province name, you might want to use an OBJECT value.\nYou want to store information about the data with the data. The names (keys) arent merely distinct identifiers, but are\nmeaningful.\nThe information has no natural order, or the order can be inferred solely from the keys.\nThe structure of the data varies, or the data can be incomplete. For example, if you want to create a catalog of books that\nusually contains the title, author name, and publication date, but in some cases the publication date is unknown, then you might\nwant to use an OBJECT value.\nYou have multiple pieces of data that are identified by strings. For example, if\nyou want to look up information by province name, you might want to use an OBJECT value.\nYou want to store information about the data with the data. The names (keys) arent merely distinct identifiers, but are\nmeaningful.\nThe information has no natural order, or the order can be inferred solely from the keys.\nThe structure of the data varies, or the data can be incomplete. For example, if you want to create a catalog of books that\nusually contains the title, author name, and publication date, but in some cases the publication date is unknown, then you might\nwant to use an OBJECT value."
      },
      {
        "heading": "ARRAY",
        "description": "\nA Snowflake array is similar to an array in many other programming languages. An array contains 0 or more pieces of data.\nEach element is accessed by specifying its position in the array."
      },
      {
        "heading": "Characteristics of an array",
        "description": "\nEach value in a semi-structured array is of type VARIANT. A VARIANT value can contain a value of any\nother data type.\nValues of other data types can be cast to VARIANT values and then stored in an array. Some functions for arrays, including\nARRAY_CONSTRUCT, can implicitly cast values to VARIANT\nvalues.\nBecause arrays store VARIANT values, and because VARIANT values can store other data types within them, the underlying data types\nof the values in an array can be different. However, in most cases, the data elements are of the same or compatible\ntypes, so they can all be processed the same way.\nThe following considerations apply to arrays:\nSnowflake doesnt support arrays of elements of a specific non-VARIANT type.\nA Snowflake array is declared without specifying the number of elements. An array can grow dynamically based on operations such\nas ARRAY_APPEND. Snowflake doesnt currently support fixed-size arrays.\nAn array can contain both SQL NULL values and JSON null values. For more information, see NULL values.\nThe theoretical maximum combined size of all values in an array is 128 MB. However, arrays have internal overhead.\nThe practical maximum data size is usually smaller, depending upon the number and values of the elements.\nIf the 2025_03 behavior change bundle is disabled, the maximum size for an array is 16 MB. This behavior change\nbundle is enabled by default. For more information, see Size limits for database objects.\nSnowflake doesnt support arrays of elements of a specific non-VARIANT type.\nA Snowflake array is declared without specifying the number of elements. An array can grow dynamically based on operations such\nas ARRAY_APPEND. Snowflake doesnt currently support fixed-size arrays.\nAn array can contain both SQL NULL values and JSON null values. For more information, see NULL values.\nThe theoretical maximum combined size of all values in an array is 128 MB. However, arrays have internal overhead.\nThe practical maximum data size is usually smaller, depending upon the number and values of the elements.\nIf the 2025_03 behavior change bundle is disabled, the maximum size for an array is 16 MB. This behavior change\nbundle is enabled by default. For more information, see Size limits for database objects.\nNote\nSnowflake also supports structured arrays, which allow for elements of types other than VARIANT.\nFor more information, see Structured data types."
      },
      {
        "heading": "Inserting ARRAY data",
        "description": "\nTo insert ARRAY data directly, use INSERT INTO ... SELECT.\nThe following code uses the ARRAY_CONSTRUCT function to construct the array that it inserts.\nYou can also use an ARRAY constant to specify the array to insert. For more information, see\nARRAY constants.",
        "syntax": [
          "CREATE OR REPLACE TABLE array_example (array_column ARRAY);\nINSERT INTO array_example (array_column)\n  SELECT ARRAY_CONSTRUCT(12, 'twelve', NULL);"
        ]
      },
      {
        "heading": "ARRAY constants",
        "description": "\nA constant (also known as a literal) refers to a fixed data value. Snowflake supports using constants to specify ARRAY values.\nARRAY constants are delimited with square brackets ([ and ]).\nARRAY constants have the following syntax:\nWhere:\nThe following are examples that specify ARRAY constants:\n[] is an empty ARRAY value.\n[ 1 , 'value1' ] contains the specified values for the ARRAY constant using\nliterals for the values.\n[ c1+1 , c1+2 ] contains the specified values for the ARRAY constant using\nexpressions for the values.\n[] is an empty ARRAY value.\n[ 1 , 'value1' ] contains the specified values for the ARRAY constant using\nliterals for the values.\n[ c1+1 , c1+2 ] contains the specified values for the ARRAY constant using\nexpressions for the values.\nThe following example uses an ARRAY constant to specify the array to insert.\nThe following statements use an ARRAY constant and the ARRAY_CONSTRUCT function to perform the same task:\nThe following example uses expressions for the values in an ARRAY constant:\nSQL statements specify string literals inside an array with single quotes (as elsewhere in Snowflake SQL), but string\nliterals inside an array are displayed with double quotes:",
        "syntax": [
          "[<value> [, <value> , ...]]",
          "INSERT INTO array_example (array_column)\n  SELECT [ 12, 'twelve', NULL ];",
          "UPDATE my_table SET my_array = [ 1, 2 ];\n\nUPDATE my_table SET my_array = ARRAY_CONSTRUCT(1, 2);",
          "SET my_variable = 10;\nSELECT [$my_variable+1, $my_variable+2];",
          "+----------------------------------+\n| [$MY_VARIABLE+1, $MY_VARIABLE+2] |\n|----------------------------------|\n| [                                |\n|   11,                            |\n|   12                             |\n| ]                                |\n+----------------------------------+",
          "SELECT [ 'Alberta', 'Manitoba' ] AS province;",
          "+--------------+\n| PROVINCE     |\n|--------------|\n| [            |\n|   \"Alberta\", |\n|   \"Manitoba\" |\n| ]            |\n+--------------+"
        ],
        "definitions": [
          {
            "term": "value",
            "definition": "The value that is associated with an array element. The value can be a literal or an expression.\nThe value can be any data type."
          }
        ]
      },
      {
        "heading": "Accessing elements of an array by index or by slice",
        "description": "\nArray indexes are 0-based, so the first element in an array is element 0.\nValues in an array are accessed by specifying an array elements index number in square brackets. For example, the following query\nreads the value at index position 2 in the array stored in my_array_column.\nArrays can be nested. The following query reads the zeroth element of the zeroth element of a nested array:\nAttempting to access an element beyond the end of an array returns NULL.\nA slice of an array is a sequence of adjacent elements (that is, a contiguous subset of the array).\nYou can access a slice of an array by calling the ARRAY_SLICE function. For example:\nThe ARRAY_SLICE function returns elements from the specified starting element (5 in the example above) up to\nbut not including the specified ending element (10 in the example above).\nAn empty array or an empty slice is often denoted by a pair of square braces with nothing between them ([]).",
        "syntax": [
          "SELECT my_array_column[2] FROM my_table;",
          "SELECT my_array_column[0][0] FROM my_table;",
          "SELECT ARRAY_SLICE(my_array_column, 5, 10) FROM my_table;"
        ]
      },
      {
        "heading": "Dense and sparse arrays",
        "description": "\nAn array can be dense or sparse.\nIn a dense array, the index values of the elements start at zero and are sequential (0, 1, 2, and so on). However,\nin a sparse array, the index values can be non-sequential (for example, 0, 2, 5). The values dont need to start at 0.\nIf an index has no corresponding element, then the value corresponding to that index is said to be undefined. For example, if a\nsparse array has three elements, and those elements are at indexes 0, 2, and 5, then the elements at indexes 1, 3, and 4 are\nundefined.\nAn undefined element is treated as an element. For example, consider the earlier example of a sparse array that contains elements\nat indexes 0, 2, and 5 (and doesnt have any elements after index 5). If you read the slice containing elements at indexes 3 and 4,\nthen the output is similar to the following:\nAttempting to access a slice beyond the end of an array results in an empty array, not an array of undefined values.\nThe following SELECT statement attempts to read beyond the last element in the sample sparse array:\nThe output is an empty array:\nundefined is different from NULL. A NULL value in an array is a defined element.\nIn a dense array, each element consumes storage space, even if the value of the element is NULL.\nIn a sparse array, undefined elements dont directly consume storage space.\nIn a dense array, the theoretical range of index values is from 0 to 134217727. (The maximum theoretical number of elements\nis 134217728 because the upper limit on size is 128 MB, or 134217728 bytes, and the smallest possible value is one byte.)\nIn a sparse array, the theoretical range of index values is from 0 to 231 - 1. However, because of the 128 MB limitation, a\nsparse array cant hold 231 values. The maximum theoretical number of values is still limited to 134217728.\nBecause of internal overhead, the practical size limit in both dense and sparse arrays is at least slightly less than\nthe theoretical maximum of 128 MB.\nNote\nIf the 2025_03 behavior change bundle is disabled, the maximum size for an array is 16 MB. This behavior change\nbundle is enabled by default. For more information, see Size limits for database objects.\nYou can create a sparse array by using the ARRAY_INSERT function to insert values at specific\nindex points in an array (leaving other array elements undefined). Because ARRAY_INSERT pushes elements to the right, which\nchanges the index values required to access them, it is normally best to fill a sparse array from left to right\n(that is, from 0 up, increasing the index value for each new value inserted).",
        "syntax": [
          "[ undefined, undefined ]",
          "SELECT ARRAY_SLICE(array_column, 6, 8) FROM table_1;",
          "+---------------------------------+\n| array_slice(array_column, 6, 8) |\n+---------------------------------+\n| [ ]                             |\n+---------------------------------+"
        ]
      },
      {
        "heading": "Common uses for ARRAY data",
        "description": "\nARRAY data is typically used when one or more of the following are true:\nThere is a collection of data, and each piece in the collection is structured the same or similarly.\nEach piece of data is processed similarly. For example, you might loop through the data, processing each piece the same way.\nThe data has a natural order, for example, chronological.\nThere is a collection of data, and each piece in the collection is structured the same or similarly.\nEach piece of data is processed similarly. For example, you might loop through the data, processing each piece the same way.\nThe data has a natural order, for example, chronological."
      },
      {
        "heading": "Examples",
        "description": "\nThe following example shows the output of a DESC TABLE command on a table with VARIANT, ARRAY, and OBJECT data.\nThis example shows how to load simple values into a table, and what those values look like when you query the table.\nCreate a table and load the data:\nNow show the data in the table.\nFor additional examples, see Querying Semi-structured Data.\nOn this page\nVARIANT\nOBJECT\nARRAY\nExamples\nRelated content\nIntroduction to Loading Semi-structured Data\nSupported formats for semi-structured data\nConsiderations for semi-structured data stored in VARIANT\nQuerying Semi-structured Data\nSemi-structured and structured data functions\nConversion functions\nData type conversion\nWe use cookies to improve your experience on our site. By accepting, you agree to our privacy policy.\nEnglish\nFranais\nDeutsch\n\n\nPortugus\n",
        "syntax": [
          "CREATE OR REPLACE TABLE test_semi_structured(\n  var VARIANT,\n  arr ARRAY,\n  obj OBJECT);\n\nDESC TABLE test_semi_structured;",
          "+------+---------+--------+-------+---------+-------------+------------+-------+------------+---------+-------------+----------------+\n| name | type    | kind   | null? | default | primary key | unique key | check | expression | comment | policy name | privacy domain |\n|------+---------+--------+-------+---------+-------------+------------+-------+------------+---------+-------------+----------------|\n| VAR  | VARIANT | COLUMN | Y     | NULL    | N           | N          | NULL  | NULL       | NULL    | NULL        | NULL           |\n| ARR  | ARRAY   | COLUMN | Y     | NULL    | N           | N          | NULL  | NULL       | NULL    | NULL        | NULL           |\n| OBJ  | OBJECT  | COLUMN | Y     | NULL    | N           | N          | NULL  | NULL       | NULL    | NULL        | NULL           |\n+------+---------+--------+-------+---------+-------------+------------+-------+------------+---------+-------------+----------------+",
          "CREATE OR REPLACE TABLE demonstration1 (\n  ID INTEGER,\n  array1 ARRAY,\n  variant1 VARIANT,\n  object1 OBJECT);\n\nINSERT INTO demonstration1 (id, array1, variant1, object1)\n  SELECT\n    1,\n    ARRAY_CONSTRUCT(1, 2, 3),\n    PARSE_JSON(' { \"key1\": \"value1\", \"key2\": \"value2\" } '),\n    PARSE_JSON(' { \"outer_key1\": { \"inner_key1A\": \"1a\", \"inner_key1B\": \"1b\" }, '\n              ||\n               '   \"outer_key2\": { \"inner_key2\": 2 } } ');\n\nINSERT INTO demonstration1 (id, array1, variant1, object1)\n  SELECT\n    2,\n    ARRAY_CONSTRUCT(1, 2, 3, NULL),\n    PARSE_JSON(' { \"key1\": \"value1\", \"key2\": NULL } '),\n    PARSE_JSON(' { \"outer_key1\": { \"inner_key1A\": \"1a\", \"inner_key1B\": NULL }, '\n              ||\n                '   \"outer_key2\": { \"inner_key2\": 2 } '\n              ||\n               ' } ');",
          "SELECT *\n  FROM demonstration1\n  ORDER BY id;",
          "+----+-------------+---------------------+--------------------------+\n| ID | ARRAY1      | VARIANT1            | OBJECT1                  |\n|----+-------------+---------------------+--------------------------|\n|  1 | [           | {                   | {                        |\n|    |   1,        |   \"key1\": \"value1\", |   \"outer_key1\": {        |\n|    |   2,        |   \"key2\": \"value2\"  |     \"inner_key1A\": \"1a\", |\n|    |   3         | }                   |     \"inner_key1B\": \"1b\"  |\n|    | ]           |                     |   },                     |\n|    |             |                     |   \"outer_key2\": {        |\n|    |             |                     |     \"inner_key2\": 2      |\n|    |             |                     |   }                      |\n|    |             |                     | }                        |\n|  2 | [           | {                   | {                        |\n|    |   1,        |   \"key1\": \"value1\", |   \"outer_key1\": {        |\n|    |   2,        |   \"key2\": null      |     \"inner_key1A\": \"1a\", |\n|    |   3,        | }                   |     \"inner_key1B\": null  |\n|    |   undefined |                     |   },                     |\n|    | ]           |                     |   \"outer_key2\": {        |\n|    |             |                     |     \"inner_key2\": 2      |\n|    |             |                     |   }                      |\n|    |             |                     | }                        |\n+----+-------------+---------------------+--------------------------+"
        ]
      }
    ]
  },
  {
    "category": "Structured data types",
    "url": "https://docs.snowflake.com/en/sql-reference/data-types-structured",
    "details": [
      {
        "heading": "Structured data types",
        "description": "\nFeature  Generally Available\nStructured types are generally available for Apache Iceberg tables.\nPreview Feature  Open\nEnabled for all accounts.\nStructured types are in preview for standard Snowflake tables (non-Iceberg), views, and materialized views.\nStructured types arent supported for dynamic, hybrid, or external tables.\nThe Snowflake structured types are ARRAY, OBJECT, and MAP. Structured types contain elements or key-value pairs with specific\nSnowflake data types. The following are examples of structured types:\nAn ARRAY of INTEGER elements.\nAn OBJECT with VARCHAR and NUMBER key-value pairs.\nA MAP that associates a VARCHAR key with a DOUBLE value.\nAn ARRAY of INTEGER elements.\nAn OBJECT with VARCHAR and NUMBER key-value pairs.\nA MAP that associates a VARCHAR key with a DOUBLE value.\nYou can use structured types in the following ways:\nYou can define a structured type column in a table.\nA structured type column supports a maximum of 1000 sub-columns.\nIn an Apache Iceberg table, the\nApache Iceberg data types list, struct, and map correspond\nto the structured ARRAY, structured OBJECT, and MAP types in Snowflake.\nYou use structured types when accessing data from a structured type column in a table.\nYou can cast a semi-structured ARRAY, OBJECT, or VARIANT\nvalue to a corresponding structured type (for example, an ARRAY value to an ARRAY value of INTEGER elements). You can also cast a\nstructured type of a semi-structured type.\nYou can define a structured type column in a table.\nA structured type column supports a maximum of 1000 sub-columns.\nIn an Apache Iceberg table, the\nApache Iceberg data types list, struct, and map correspond\nto the structured ARRAY, structured OBJECT, and MAP types in Snowflake.\nYou use structured types when accessing data from a structured type column in a table.\nYou can cast a semi-structured ARRAY, OBJECT, or VARIANT\nvalue to a corresponding structured type (for example, an ARRAY value to an ARRAY value of INTEGER elements). You can also cast a\nstructured type of a semi-structured type.\nThis topic explains how to use structured types in Snowflake."
      },
      {
        "heading": "Specifying a structured type",
        "description": "\nWhen defining a structured type column or casting a value to a structured type, use the syntax described in the following\nsections:\nSpecifying a structured ARRAY type\nSpecifying a structured OBJECT type\nSpecifying a MAP type\nSpecifying a structured ARRAY type\nSpecifying a structured OBJECT type\nSpecifying a MAP type"
      },
      {
        "heading": "Specifying a structured ARRAY type",
        "description": "\nTo specify a structured ARRAY type, use the following syntax:\nWhere:\nelement_type is the Snowflake data type of the elements in this ARRAY.\nYou can also specify a structured ARRAY, a structured OBJECT, or a MAP as the type of the element.\n\nNote\nIn the definition of a standard Snowflake table (non-Iceberg) column, you cant specify GEOGRAPHY as the type of the ARRAY element.\nIn the definition of an Iceberg table column, you cant specify VARIANT, semi-structured ARRAY, or semi-structured OBJECT\nas the type of the ARRAY element.\nNOT NULL specifies that the ARRAY cant contain any elements that are NULL.\nelement_type is the Snowflake data type of the elements in this ARRAY.\nYou can also specify a structured ARRAY, a structured OBJECT, or a MAP as the type of the element.\nNote\nIn the definition of a standard Snowflake table (non-Iceberg) column, you cant specify GEOGRAPHY as the type of the ARRAY element.\nIn the definition of an Iceberg table column, you cant specify VARIANT, semi-structured ARRAY, or semi-structured OBJECT\nas the type of the ARRAY element.\nNOT NULL specifies that the ARRAY cant contain any elements that are NULL.\nFor example, compare the types returned by the SYSTEM$TYPEOF function in the following statement:\nThe first column expression casts a semi-structured ARRAY value to a structured ARRAY value (an ARRAY of NUMBER elements).\nThe second column expression specifies a semi-structured ARRAY value.\nThe first column expression casts a semi-structured ARRAY value to a structured ARRAY value (an ARRAY of NUMBER elements).\nThe second column expression specifies a semi-structured ARRAY value.",
        "syntax": [
          "ARRAY( <element_type> [ NOT NULL ] )",
          "SELECT\n  SYSTEM$TYPEOF(\n    [1, 2, 3]::ARRAY(NUMBER)\n  ) AS structured_array,\n  SYSTEM$TYPEOF(\n    [1, 2, 3]\n  ) AS semi_structured_array;",
          "+-------------------------------+-----------------------+\n| STRUCTURED_ARRAY              | SEMI_STRUCTURED_ARRAY |\n|-------------------------------+-----------------------|\n| ARRAY(NUMBER(38,0))[LOB]      | ARRAY[LOB]            |\n+-------------------------------+-----------------------+"
        ]
      },
      {
        "heading": "Specifying a structured OBJECT type",
        "description": "\nTo specify a structured OBJECT type, use the following syntax:\nWhere:\nkey specifies a key for the OBJECT type.\n\nEach key in an OBJECT definition must be unique.\nThe order of the keys is part of the OBJECT definition. Comparing two OBJECT values that have the same keys in a different order\nisnt allowed. (A compile time error occurs.)\nIf you dont specify any key but specify the parentheses (that is, if you use OBJECT()), the resulting type is a structured\nOBJECT that contains no keys. A structured OBJECT with no keys is different from a semi-structured OBJECT.\nEach key in an OBJECT definition must be unique.\nThe order of the keys is part of the OBJECT definition. Comparing two OBJECT values that have the same keys in a different order\nisnt allowed. (A compile time error occurs.)\nIf you dont specify any key but specify the parentheses (that is, if you use OBJECT()), the resulting type is a structured\nOBJECT that contains no keys. A structured OBJECT with no keys is different from a semi-structured OBJECT.\nvalue_type is the Snowflake data type of the value corresponding to the key.\nYou can also specify a structured ARRAY, a structured OBJECT, or a MAP as the type of the value.\n\nNote\nIn the definition of a standard Snowflake table (non-Iceberg) column, you cant specify GEOGRAPHY as the type of the\nvalue corresponding to the OBJECT key.\nIn the definition of an Iceberg table column, you cant specify VARIANT, semi-structured ARRAY, or semi-structured OBJECT\nas the type of the value corresponding to the OBJECT key.\nNOT NULL specifies that the value corresponding to the key cant be NULL.\nkey specifies a key for the OBJECT type.\nEach key in an OBJECT definition must be unique.\nThe order of the keys is part of the OBJECT definition. Comparing two OBJECT values that have the same keys in a different order\nisnt allowed. (A compile time error occurs.)\nIf you dont specify any key but specify the parentheses (that is, if you use OBJECT()), the resulting type is a structured\nOBJECT that contains no keys. A structured OBJECT with no keys is different from a semi-structured OBJECT.\nEach key in an OBJECT definition must be unique.\nThe order of the keys is part of the OBJECT definition. Comparing two OBJECT values that have the same keys in a different order\nisnt allowed. (A compile time error occurs.)\nIf you dont specify any key but specify the parentheses (that is, if you use OBJECT()), the resulting type is a structured\nOBJECT that contains no keys. A structured OBJECT with no keys is different from a semi-structured OBJECT.\nvalue_type is the Snowflake data type of the value corresponding to the key.\nYou can also specify a structured ARRAY, a structured OBJECT, or a MAP as the type of the value.\nNote\nIn the definition of a standard Snowflake table (non-Iceberg) column, you cant specify GEOGRAPHY as the type of the\nvalue corresponding to the OBJECT key.\nIn the definition of an Iceberg table column, you cant specify VARIANT, semi-structured ARRAY, or semi-structured OBJECT\nas the type of the value corresponding to the OBJECT key.\nNOT NULL specifies that the value corresponding to the key cant be NULL.\nFor example, compare the types returned by the SYSTEM$TYPEOF function in the following statement:\nThe first column expression casts a semi-structured OBJECT value to a structured OBJECT value that contains the following keys and values:\n\nA key named str with a VARCHAR value that is not NULL.\nA key named num with a NUMBER value.\nA key named str with a VARCHAR value that is not NULL.\nA key named num with a NUMBER value.\nThe second column expression specifies a semi-structured OBJECT value.\nThe first column expression casts a semi-structured OBJECT value to a structured OBJECT value that contains the following keys and values:\nA key named str with a VARCHAR value that is not NULL.\nA key named num with a NUMBER value.\nA key named str with a VARCHAR value that is not NULL.\nA key named num with a NUMBER value.\nThe second column expression specifies a semi-structured OBJECT value.",
        "syntax": [
          "OBJECT(\n  [\n    <key> <value_type> [ NOT NULL ]\n    [ , <key> <value_type> [ NOT NULL ] ]\n    [ , ... ]\n  ]\n)",
          "SELECT\n  SYSTEM$TYPEOF(\n    {\n      'str': 'test',\n      'num': 1\n    }::OBJECT(\n      str VARCHAR NOT NULL,\n      num NUMBER\n    )\n  ) AS structured_object,\n  SYSTEM$TYPEOF(\n    {\n      'str': 'test',\n      'num': 1\n    }\n  ) AS semi_structured_object;",
          "+-----------------------------------------------------+------------------------+\n| STRUCTURED_OBJECT                                   | SEMI_STRUCTURED_OBJECT |\n|-----------------------------------------------------+------------------------|\n| OBJECT(str VARCHAR NOT NULL, num NUMBER(38,0))[LOB] | OBJECT[LOB]            |\n+-----------------------------------------------------+------------------------+"
        ]
      },
      {
        "heading": "Specifying a MAP type",
        "description": "\nTo specify a MAP type, use the following syntax:\nWhere:\nkey_type is the Snowflake data type of the key for the map. You must use one of\nthe following types for keys:\n\nVARCHAR\nNUMBER with the scale 0\n\nYou cant use a floating point data type as the type for the key.\nMap keys cant be NULL.\nVARCHAR\nNUMBER with the scale 0\nvalue_type is the Snowflake data type of the values in the map.\nYou can also specify a structured ARRAY, a structured OBJECT, or a MAP as the type of the values.\n\nNote\nIn the definition of a standard Snowflake table (non-Iceberg) column, you cant specify GEOGRAPHY as the type of the\nvalue in the MAP.\nIn the definition of an Iceberg table column, you cant specify VARIANT, semi-structured ARRAY, or semi-structured OBJECT\nas the type of the value in the MAP.\nNOT NULL specifies that the value corresponding to the key cant be NULL.\nkey_type is the Snowflake data type of the key for the map. You must use one of\nthe following types for keys:\nVARCHAR\nNUMBER with the scale 0\nVARCHAR\nNUMBER with the scale 0\nYou cant use a floating point data type as the type for the key.\nMap keys cant be NULL.\nvalue_type is the Snowflake data type of the values in the map.\nYou can also specify a structured ARRAY, a structured OBJECT, or a MAP as the type of the values.\nNote\nIn the definition of a standard Snowflake table (non-Iceberg) column, you cant specify GEOGRAPHY as the type of the\nvalue in the MAP.\nIn the definition of an Iceberg table column, you cant specify VARIANT, semi-structured ARRAY, or semi-structured OBJECT\nas the type of the value in the MAP.\nNOT NULL specifies that the value corresponding to the key cant be NULL.\nThe following example casts a semi-structured OBJECT value to a MAP value and uses the SYSTEM$TYPEOF\nfunction to print the resulting type of the value. The MAP associates VARCHAR keys with VARCHAR values.",
        "syntax": [
          "MAP( <key_type> , <value_type> [ NOT NULL ] )",
          "SELECT\n  SYSTEM$TYPEOF(\n    {\n      'a_key': 'a_val',\n      'b_key': 'b_val'\n    }::MAP(VARCHAR, VARCHAR)\n  ) AS map_example;",
          "+----------------------------+\n| MAP_EXAMPLE                |\n|----------------------------|\n| MAP(VARCHAR, VARCHAR)[LOB] |\n+----------------------------+"
        ]
      },
      {
        "heading": "Creating a table with a structured type column",
        "description": "\nWhen you use the CREATE TABLE command to create a table, you can use the syntax described in\nSpecifying a structured type to define a column that contains a structured type.\nThe following examples demonstrate how to specify a structured type column:\nExample of creating a table with a structured ARRAY column\nExample of creating a table with a structured OBJECT column\nExample of creating a table with a MAP column\nExample of creating a table with a structured ARRAY column\nExample of creating a table with a structured OBJECT column\nExample of creating a table with a MAP column"
      },
      {
        "heading": "Example of creating a table with a structured ARRAY column",
        "description": "\nThe following statement creates a table with a column for a structured ARRAY:\nThe following statement inserts a row into the table:\nNote the following:\nBecause the example uses an ARRAY constant for the value to insert, the example uses a query\n(SELECT) rather than the VALUES clause.\nThe VALUES clause does not support OBJECT constants, ARRAY constants, and some\nfunctions like OBJECT_CONSTRUCT and ARRAY_CONSTRUCT.\nBecause\nan ARRAY constant specifies a semi-structured ARRAY (not a structured ARRAY),\nyou must cast the resulting semi-structured ARRAY to a structured ARRAY.\nBecause the example uses an ARRAY constant for the value to insert, the example uses a query\n(SELECT) rather than the VALUES clause.\nThe VALUES clause does not support OBJECT constants, ARRAY constants, and some\nfunctions like OBJECT_CONSTRUCT and ARRAY_CONSTRUCT.\nBecause\nan ARRAY constant specifies a semi-structured ARRAY (not a structured ARRAY),\nyou must cast the resulting semi-structured ARRAY to a structured ARRAY.",
        "syntax": [
          "CREATE TABLE my_table_with_structured_array_column (\n  numeric_array ARRAY(NUMBER)\n);",
          "INSERT INTO my_table_with_structured_array_column SELECT\n  [10, 20, 30]::ARRAY(NUMBER);"
        ]
      },
      {
        "heading": "Example of creating a table with a structured OBJECT column",
        "description": "\nThe following statement creates a table with a column for a structured OBJECT:\nThe following statement inserts a row into the table:\nNote the following:\nBecause the example uses an OBJECT constant for the value to insert, the example uses a query\n(SELECT) rather than the VALUES clause.\nThe VALUES clause does not support OBJECT constants, ARRAY constants, and some\nfunctions like OBJECT_CONSTRUCT and ARRAY_CONSTRUCT.\nBecause\nan OBJECT constant specifies a semi-structured OBJECT (not a structured OBJECT),\nyou must cast the resulting semi-structured OBJECT to a structured OBJECT.\nBecause the example uses an OBJECT constant for the value to insert, the example uses a query\n(SELECT) rather than the VALUES clause.\nThe VALUES clause does not support OBJECT constants, ARRAY constants, and some\nfunctions like OBJECT_CONSTRUCT and ARRAY_CONSTRUCT.\nBecause\nan OBJECT constant specifies a semi-structured OBJECT (not a structured OBJECT),\nyou must cast the resulting semi-structured OBJECT to a structured OBJECT.",
        "syntax": [
          "CREATE TABLE customer (\n  c_id VARCHAR,\n  c_name VARCHAR,\n  c_address OBJECT(\n    state VARCHAR,\n    city VARCHAR,\n    street VARCHAR,\n    zip_code NUMBER\n  )\n);",
          "INSERT INTO customer SELECT\n  '1',\n  'customer_name',\n  {\n    'state': 'CA',\n    'city': 'San Mateo',\n    'street': '450 Concar Drive',\n    'zip_code': 94402\n  }::OBJECT(\n    state VARCHAR,\n    city VARCHAR,\n    street VARCHAR,\n    zip_code NUMBER\n  );"
        ]
      },
      {
        "heading": "Example of creating a table with a MAP column",
        "description": "\nThe following statement creates a table with a column for a MAP:\nThe following statement inserts a row into the table:\nNote the following:\nBecause the example uses an OBJECT constant for the value to insert, the example uses a query\n(SELECT) rather than the VALUES clause.\nThe VALUES clause does not support OBJECT constants, ARRAY constants, and some\nfunctions like OBJECT_CONSTRUCT and ARRAY_CONSTRUCT.\nBecause\nan OBJECT constant specifies a semi-structured OBJECT (not a MAP),\nyou must cast the resulting semi-structured OBJECT to a MAP.\nBecause the example uses an OBJECT constant for the value to insert, the example uses a query\n(SELECT) rather than the VALUES clause.\nThe VALUES clause does not support OBJECT constants, ARRAY constants, and some\nfunctions like OBJECT_CONSTRUCT and ARRAY_CONSTRUCT.\nBecause\nan OBJECT constant specifies a semi-structured OBJECT (not a MAP),\nyou must cast the resulting semi-structured OBJECT to a MAP.",
        "syntax": [
          "CREATE OR REPLACE TABLE my_table_with_map_column(my_map MAP(VARCHAR, VARCHAR));",
          "INSERT INTO my_table_with_map_column SELECT\n  {'key123': 'value123'}::MAP(VARCHAR, VARCHAR);"
        ]
      },
      {
        "heading": "Adding a structured type column",
        "description": "\nTo add a column containing a structured type, use ALTER TABLE  ADD COLUMN with the\nsyntax described in Specifying a structured type. For example:",
        "syntax": [
          "ALTER TABLE customer ADD COLUMN phone ARRAY(VARCHAR);"
        ]
      },
      {
        "heading": "Dropping and renaming structured type columns",
        "description": "\nTo drop or rename a structured type column, you can use ALTER TABLE  DROP COLUMN and\nALTER TABLE  RENAME COLUMN (as you would with a column with a semi-structured object)."
      },
      {
        "heading": "Using structured types in semi-structured types",
        "description": "\nYou cant use a MAP, structured OBJECT, or structured ARRAY value in a VARIANT, semi-structured OBJECT, or semi-structured ARRAY value. An\nerror occurs in the following situations:\nYou use a MAP, structured OBJECT, or structured ARRAY value in an OBJECT constant or\nARRAY constant.\nYou pass a MAP, structured OBJECT, or structured ARRAY value to an OBJECT or ARRAY\nconstructor function.\nYou use a MAP, structured OBJECT, or structured ARRAY value in an OBJECT constant or\nARRAY constant.\nYou pass a MAP, structured OBJECT, or structured ARRAY value to an OBJECT or ARRAY\nconstructor function."
      },
      {
        "heading": "Converting structured and semi-structured types",
        "tables": [
          {
            "headers": [
              "Source data type",
              "Target data type",
              "Castable",
              "Coercible"
            ],
            "rows": [
              [
                "Semi-structured ARRAY",
                "Structured ARRAY",
                "",
                ""
              ],
              [
                "Semi-structured OBJECT",
                "Structured OBJECT\nMAP",
                "",
                ""
              ],
              [
                "Semi-structured VARIANT",
                "Structured ARRAY\nStructured OBJECT\nMAP",
                "",
                ""
              ],
              [
                "Structured ARRAY",
                "Semi-structured ARRAY",
                "",
                ""
              ],
              [
                "Structured OBJECT\nMAP",
                "Semi-structured OBJECT",
                "",
                ""
              ],
              [
                "Structured ARRAY\nStructured OBJECT\nMAP",
                "Semi-structured VARIANT",
                "",
                ""
              ]
            ]
          }
        ]
      },
      {
        "heading": "Explicitly casting a semi-structured type to a structured type",
        "tables": [
          {
            "headers": [
              "Semi-structured type",
              "Structured type that you can cast to"
            ],
            "rows": [
              [
                "ARRAY",
                "Structured ARRAY"
              ],
              [
                "OBJECT",
                "MAP or structured OBJECT"
              ],
              [
                "VARIANT",
                "MAP or structured ARRAY or OBJECT"
              ]
            ]
          }
        ]
      },
      {
        "heading": "Explicitly casting a structured type to a semi-structured type",
        "tables": [
          {
            "headers": [
              "Structured type",
              "Semi-structured type that you can cast to"
            ],
            "rows": [
              [
                "Structured ARRAY",
                "ARRAY"
              ],
              [
                "MAP or structured OBJECT",
                "OBJECT"
              ],
              [
                "MAP, structured ARRAY, or structured OBJECT",
                "VARIANT"
              ]
            ]
          }
        ]
      },
      {
        "heading": "Implicit casting a value (coercion)",
        "description": "\nThe following rules apply to implicitly casting (coercion) from a value of one structured type to\na value of another structured type:\nA structured type value can be coerced to another structured type value if the two basic types are the same:\n\nAn ARRAY value of one type can be coerced to an ARRAY value of another type, provided that the first element type is coercible to the\nsecond element type.\nAn element type can be coerced to another element type in either of the following cases:\n\nBoth types are numeric. The following cases are supported:\n\nBoth use the same numeric type but possibly differ in precision and/or scale.\nCoercing NUMBER to FLOAT (and vice versa).\n\n\nBoth types are timestamps. The following cases are supported:\n\nBoth use the same type but possibly differ in precision.\nCoercing TIMESTAMP_LTZ to TIMESTAMP_TZ (and vice versa).\n\n\n\nFor example:\n\nAn ARRAY(NUMBER) value can be coerced to an ARRAY(DOUBLE) value.\nAn ARRAY(DATE) value cant be coerced to an ARRAY(NUMBER) value.\n\n\nAn OBJECT value with one type definition can be coerced to an OBJECT value of with another type definition only if all of the following\nare true:\n\nBoth OBJECT types have the same number of keys.\nBoth OBJECT types use the same names for keys.\nThe keys in both OBJECT types are in the same order.\nThe type of each value in one OBJECT type can be coerced to the type of the corresponding value in the other OBJECT type.\nAs is the case with element types in structured ARRAY values, you can coerce the type of one value to another type only if:\n\nBoth types are numeric. The following cases are supported:\n\nBoth use the same numeric type but possibly differ in precision and/or scale.\nCoercing NUMBER to FLOAT (and vice versa).\n\n\nBoth types are timestamps. The following cases are supported:\n\nBoth use the same type but possibly differ in precision.\nCoercing TIMESTAMP_LTZ to TIMESTAMP_TZ (and vice versa).\n\n\n\n\n\nFor example:\n\nAn OBJECT(city VARCHAR, zipcode NUMBER) value can be coerced to an OBJECT(city VARCHAR, zipcode DOUBLE) value.\nAn OBJECT(city VARCHAR, zipcode NUMBER) value cant be coerced to an OBJECT(city VARCHAR, zipcode DATE) value.\n\n\nA MAP value with one value type can be coerced to a MAP value with a different value type if:\n\nBoth value types are numeric. The following cases are supported:\n\nBoth use the same numeric type but possibly differ in precision and/or scale.\nCoercing NUMBER to FLOAT (and vice versa).\n\n\nBoth value types are timestamps. The following cases are supported:\n\nBoth use the same type but possibly differ in precision.\nCoercing TIMESTAMP_LTZ to TIMESTAMP_TZ (and vice versa).\n\n\n\nFor example, a MAP(VARCHAR, NUMBER) value can be coerced to a MAP(VARCHAR, DOUBLE) value.\n\nA MAP value with one key type can be coerced to a MAP value with a different key type if both key types use the same integer NUMERIC\ntype that differ only in precision.\nFor example, a MAP(VARCHAR, NUMBER) value cant be coerced to a MAP(NUMBER, NUMBER) value.\nAn ARRAY value of one type can be coerced to an ARRAY value of another type, provided that the first element type is coercible to the\nsecond element type.\nAn element type can be coerced to another element type in either of the following cases:\n\nBoth types are numeric. The following cases are supported:\n\nBoth use the same numeric type but possibly differ in precision and/or scale.\nCoercing NUMBER to FLOAT (and vice versa).\n\n\nBoth types are timestamps. The following cases are supported:\n\nBoth use the same type but possibly differ in precision.\nCoercing TIMESTAMP_LTZ to TIMESTAMP_TZ (and vice versa).\n\n\n\nFor example:\n\nAn ARRAY(NUMBER) value can be coerced to an ARRAY(DOUBLE) value.\nAn ARRAY(DATE) value cant be coerced to an ARRAY(NUMBER) value.\nBoth types are numeric. The following cases are supported:\n\nBoth use the same numeric type but possibly differ in precision and/or scale.\nCoercing NUMBER to FLOAT (and vice versa).\nBoth use the same numeric type but possibly differ in precision and/or scale.\nCoercing NUMBER to FLOAT (and vice versa).\nBoth types are timestamps. The following cases are supported:\n\nBoth use the same type but possibly differ in precision.\nCoercing TIMESTAMP_LTZ to TIMESTAMP_TZ (and vice versa).\nBoth use the same type but possibly differ in precision.\nCoercing TIMESTAMP_LTZ to TIMESTAMP_TZ (and vice versa).\nAn ARRAY(NUMBER) value can be coerced to an ARRAY(DOUBLE) value.\nAn ARRAY(DATE) value cant be coerced to an ARRAY(NUMBER) value.\nAn OBJECT value with one type definition can be coerced to an OBJECT value of with another type definition only if all of the following\nare true:\n\nBoth OBJECT types have the same number of keys.\nBoth OBJECT types use the same names for keys.\nThe keys in both OBJECT types are in the same order.\nThe type of each value in one OBJECT type can be coerced to the type of the corresponding value in the other OBJECT type.\nAs is the case with element types in structured ARRAY values, you can coerce the type of one value to another type only if:\n\nBoth types are numeric. The following cases are supported:\n\nBoth use the same numeric type but possibly differ in precision and/or scale.\nCoercing NUMBER to FLOAT (and vice versa).\n\n\nBoth types are timestamps. The following cases are supported:\n\nBoth use the same type but possibly differ in precision.\nCoercing TIMESTAMP_LTZ to TIMESTAMP_TZ (and vice versa).\n\n\n\n\n\nFor example:\n\nAn OBJECT(city VARCHAR, zipcode NUMBER) value can be coerced to an OBJECT(city VARCHAR, zipcode DOUBLE) value.\nAn OBJECT(city VARCHAR, zipcode NUMBER) value cant be coerced to an OBJECT(city VARCHAR, zipcode DATE) value.\nBoth OBJECT types have the same number of keys.\nBoth OBJECT types use the same names for keys.\nThe keys in both OBJECT types are in the same order.\nThe type of each value in one OBJECT type can be coerced to the type of the corresponding value in the other OBJECT type.\nAs is the case with element types in structured ARRAY values, you can coerce the type of one value to another type only if:\n\nBoth types are numeric. The following cases are supported:\n\nBoth use the same numeric type but possibly differ in precision and/or scale.\nCoercing NUMBER to FLOAT (and vice versa).\n\n\nBoth types are timestamps. The following cases are supported:\n\nBoth use the same type but possibly differ in precision.\nCoercing TIMESTAMP_LTZ to TIMESTAMP_TZ (and vice versa).\nBoth types are numeric. The following cases are supported:\n\nBoth use the same numeric type but possibly differ in precision and/or scale.\nCoercing NUMBER to FLOAT (and vice versa).\nBoth use the same numeric type but possibly differ in precision and/or scale.\nCoercing NUMBER to FLOAT (and vice versa).\nBoth types are timestamps. The following cases are supported:\n\nBoth use the same type but possibly differ in precision.\nCoercing TIMESTAMP_LTZ to TIMESTAMP_TZ (and vice versa).\nBoth use the same type but possibly differ in precision.\nCoercing TIMESTAMP_LTZ to TIMESTAMP_TZ (and vice versa).\nAn OBJECT(city VARCHAR, zipcode NUMBER) value can be coerced to an OBJECT(city VARCHAR, zipcode DOUBLE) value.\nAn OBJECT(city VARCHAR, zipcode NUMBER) value cant be coerced to an OBJECT(city VARCHAR, zipcode DATE) value.\nA MAP value with one value type can be coerced to a MAP value with a different value type if:\n\nBoth value types are numeric. The following cases are supported:\n\nBoth use the same numeric type but possibly differ in precision and/or scale.\nCoercing NUMBER to FLOAT (and vice versa).\n\n\nBoth value types are timestamps. The following cases are supported:\n\nBoth use the same type but possibly differ in precision.\nCoercing TIMESTAMP_LTZ to TIMESTAMP_TZ (and vice versa).\n\n\n\nFor example, a MAP(VARCHAR, NUMBER) value can be coerced to a MAP(VARCHAR, DOUBLE) value.\nBoth value types are numeric. The following cases are supported:\n\nBoth use the same numeric type but possibly differ in precision and/or scale.\nCoercing NUMBER to FLOAT (and vice versa).\nBoth use the same numeric type but possibly differ in precision and/or scale.\nCoercing NUMBER to FLOAT (and vice versa).\nBoth value types are timestamps. The following cases are supported:\n\nBoth use the same type but possibly differ in precision.\nCoercing TIMESTAMP_LTZ to TIMESTAMP_TZ (and vice versa).\nBoth use the same type but possibly differ in precision.\nCoercing TIMESTAMP_LTZ to TIMESTAMP_TZ (and vice versa).\nA MAP value with one key type can be coerced to a MAP value with a different key type if both key types use the same integer NUMERIC\ntype that differ only in precision.\nFor example, a MAP(VARCHAR, NUMBER) value cant be coerced to a MAP(NUMBER, NUMBER) value.\nA structured type value cant be coerced to a semi-structured value (and vice versa).\nA VARCHAR value cant be coerced to a structured type value.\nA structured type value can be coerced to another structured type value if the two basic types are the same:\nAn ARRAY value of one type can be coerced to an ARRAY value of another type, provided that the first element type is coercible to the\nsecond element type.\nAn element type can be coerced to another element type in either of the following cases:\n\nBoth types are numeric. The following cases are supported:\n\nBoth use the same numeric type but possibly differ in precision and/or scale.\nCoercing NUMBER to FLOAT (and vice versa).\n\n\nBoth types are timestamps. The following cases are supported:\n\nBoth use the same type but possibly differ in precision.\nCoercing TIMESTAMP_LTZ to TIMESTAMP_TZ (and vice versa).\n\n\n\nFor example:\n\nAn ARRAY(NUMBER) value can be coerced to an ARRAY(DOUBLE) value.\nAn ARRAY(DATE) value cant be coerced to an ARRAY(NUMBER) value.\nBoth types are numeric. The following cases are supported:\n\nBoth use the same numeric type but possibly differ in precision and/or scale.\nCoercing NUMBER to FLOAT (and vice versa).\nBoth use the same numeric type but possibly differ in precision and/or scale.\nCoercing NUMBER to FLOAT (and vice versa).\nBoth types are timestamps. The following cases are supported:\n\nBoth use the same type but possibly differ in precision.\nCoercing TIMESTAMP_LTZ to TIMESTAMP_TZ (and vice versa).\nBoth use the same type but possibly differ in precision.\nCoercing TIMESTAMP_LTZ to TIMESTAMP_TZ (and vice versa).\nAn ARRAY(NUMBER) value can be coerced to an ARRAY(DOUBLE) value.\nAn ARRAY(DATE) value cant be coerced to an ARRAY(NUMBER) value.\nAn OBJECT value with one type definition can be coerced to an OBJECT value of with another type definition only if all of the following\nare true:\n\nBoth OBJECT types have the same number of keys.\nBoth OBJECT types use the same names for keys.\nThe keys in both OBJECT types are in the same order.\nThe type of each value in one OBJECT type can be coerced to the type of the corresponding value in the other OBJECT type.\nAs is the case with element types in structured ARRAY values, you can coerce the type of one value to another type only if:\n\nBoth types are numeric. The following cases are supported:\n\nBoth use the same numeric type but possibly differ in precision and/or scale.\nCoercing NUMBER to FLOAT (and vice versa).\n\n\nBoth types are timestamps. The following cases are supported:\n\nBoth use the same type but possibly differ in precision.\nCoercing TIMESTAMP_LTZ to TIMESTAMP_TZ (and vice versa).\n\n\n\n\n\nFor example:\n\nAn OBJECT(city VARCHAR, zipcode NUMBER) value can be coerced to an OBJECT(city VARCHAR, zipcode DOUBLE) value.\nAn OBJECT(city VARCHAR, zipcode NUMBER) value cant be coerced to an OBJECT(city VARCHAR, zipcode DATE) value.\nBoth OBJECT types have the same number of keys.\nBoth OBJECT types use the same names for keys.\nThe keys in both OBJECT types are in the same order.\nThe type of each value in one OBJECT type can be coerced to the type of the corresponding value in the other OBJECT type.\nAs is the case with element types in structured ARRAY values, you can coerce the type of one value to another type only if:\n\nBoth types are numeric. The following cases are supported:\n\nBoth use the same numeric type but possibly differ in precision and/or scale.\nCoercing NUMBER to FLOAT (and vice versa).\n\n\nBoth types are timestamps. The following cases are supported:\n\nBoth use the same type but possibly differ in precision.\nCoercing TIMESTAMP_LTZ to TIMESTAMP_TZ (and vice versa).\nBoth types are numeric. The following cases are supported:\n\nBoth use the same numeric type but possibly differ in precision and/or scale.\nCoercing NUMBER to FLOAT (and vice versa).\nBoth use the same numeric type but possibly differ in precision and/or scale.\nCoercing NUMBER to FLOAT (and vice versa).\nBoth types are timestamps. The following cases are supported:\n\nBoth use the same type but possibly differ in precision.\nCoercing TIMESTAMP_LTZ to TIMESTAMP_TZ (and vice versa).\nBoth use the same type but possibly differ in precision.\nCoercing TIMESTAMP_LTZ to TIMESTAMP_TZ (and vice versa).\nAn OBJECT(city VARCHAR, zipcode NUMBER) value can be coerced to an OBJECT(city VARCHAR, zipcode DOUBLE) value.\nAn OBJECT(city VARCHAR, zipcode NUMBER) value cant be coerced to an OBJECT(city VARCHAR, zipcode DATE) value.\nA MAP value with one value type can be coerced to a MAP value with a different value type if:\n\nBoth value types are numeric. The following cases are supported:\n\nBoth use the same numeric type but possibly differ in precision and/or scale.\nCoercing NUMBER to FLOAT (and vice versa).\n\n\nBoth value types are timestamps. The following cases are supported:\n\nBoth use the same type but possibly differ in precision.\nCoercing TIMESTAMP_LTZ to TIMESTAMP_TZ (and vice versa).\n\n\n\nFor example, a MAP(VARCHAR, NUMBER) value can be coerced to a MAP(VARCHAR, DOUBLE) value.\nBoth value types are numeric. The following cases are supported:\n\nBoth use the same numeric type but possibly differ in precision and/or scale.\nCoercing NUMBER to FLOAT (and vice versa).\nBoth use the same numeric type but possibly differ in precision and/or scale.\nCoercing NUMBER to FLOAT (and vice versa).\nBoth value types are timestamps. The following cases are supported:\n\nBoth use the same type but possibly differ in precision.\nCoercing TIMESTAMP_LTZ to TIMESTAMP_TZ (and vice versa).\nBoth use the same type but possibly differ in precision.\nCoercing TIMESTAMP_LTZ to TIMESTAMP_TZ (and vice versa).\nA MAP value with one key type can be coerced to a MAP value with a different key type if both key types use the same integer NUMERIC\ntype that differ only in precision.\nFor example, a MAP(VARCHAR, NUMBER) value cant be coerced to a MAP(NUMBER, NUMBER) value.\nAn ARRAY value of one type can be coerced to an ARRAY value of another type, provided that the first element type is coercible to the\nsecond element type.\nAn element type can be coerced to another element type in either of the following cases:\nBoth types are numeric. The following cases are supported:\n\nBoth use the same numeric type but possibly differ in precision and/or scale.\nCoercing NUMBER to FLOAT (and vice versa).\nBoth use the same numeric type but possibly differ in precision and/or scale.\nCoercing NUMBER to FLOAT (and vice versa).\nBoth types are timestamps. The following cases are supported:\n\nBoth use the same type but possibly differ in precision.\nCoercing TIMESTAMP_LTZ to TIMESTAMP_TZ (and vice versa).\nBoth use the same type but possibly differ in precision.\nCoercing TIMESTAMP_LTZ to TIMESTAMP_TZ (and vice versa).\nBoth types are numeric. The following cases are supported:\nBoth use the same numeric type but possibly differ in precision and/or scale.\nCoercing NUMBER to FLOAT (and vice versa).\nBoth use the same numeric type but possibly differ in precision and/or scale.\nCoercing NUMBER to FLOAT (and vice versa).\nBoth types are timestamps. The following cases are supported:\nBoth use the same type but possibly differ in precision.\nCoercing TIMESTAMP_LTZ to TIMESTAMP_TZ (and vice versa).\nBoth use the same type but possibly differ in precision.\nCoercing TIMESTAMP_LTZ to TIMESTAMP_TZ (and vice versa).\nFor example:\nAn ARRAY(NUMBER) value can be coerced to an ARRAY(DOUBLE) value.\nAn ARRAY(DATE) value cant be coerced to an ARRAY(NUMBER) value.\nAn ARRAY(NUMBER) value can be coerced to an ARRAY(DOUBLE) value.\nAn ARRAY(DATE) value cant be coerced to an ARRAY(NUMBER) value.\nAn OBJECT value with one type definition can be coerced to an OBJECT value of with another type definition only if all of the following\nare true:\nBoth OBJECT types have the same number of keys.\nBoth OBJECT types use the same names for keys.\nThe keys in both OBJECT types are in the same order.\nThe type of each value in one OBJECT type can be coerced to the type of the corresponding value in the other OBJECT type.\nAs is the case with element types in structured ARRAY values, you can coerce the type of one value to another type only if:\n\nBoth types are numeric. The following cases are supported:\n\nBoth use the same numeric type but possibly differ in precision and/or scale.\nCoercing NUMBER to FLOAT (and vice versa).\n\n\nBoth types are timestamps. The following cases are supported:\n\nBoth use the same type but possibly differ in precision.\nCoercing TIMESTAMP_LTZ to TIMESTAMP_TZ (and vice versa).\nBoth types are numeric. The following cases are supported:\n\nBoth use the same numeric type but possibly differ in precision and/or scale.\nCoercing NUMBER to FLOAT (and vice versa).\nBoth use the same numeric type but possibly differ in precision and/or scale.\nCoercing NUMBER to FLOAT (and vice versa).\nBoth types are timestamps. The following cases are supported:\n\nBoth use the same type but possibly differ in precision.\nCoercing TIMESTAMP_LTZ to TIMESTAMP_TZ (and vice versa).\nBoth use the same type but possibly differ in precision.\nCoercing TIMESTAMP_LTZ to TIMESTAMP_TZ (and vice versa).\nBoth OBJECT types have the same number of keys.\nBoth OBJECT types use the same names for keys.\nThe keys in both OBJECT types are in the same order.\nThe type of each value in one OBJECT type can be coerced to the type of the corresponding value in the other OBJECT type.\nAs is the case with element types in structured ARRAY values, you can coerce the type of one value to another type only if:\nBoth types are numeric. The following cases are supported:\n\nBoth use the same numeric type but possibly differ in precision and/or scale.\nCoercing NUMBER to FLOAT (and vice versa).\nBoth use the same numeric type but possibly differ in precision and/or scale.\nCoercing NUMBER to FLOAT (and vice versa).\nBoth types are timestamps. The following cases are supported:\n\nBoth use the same type but possibly differ in precision.\nCoercing TIMESTAMP_LTZ to TIMESTAMP_TZ (and vice versa).\nBoth use the same type but possibly differ in precision.\nCoercing TIMESTAMP_LTZ to TIMESTAMP_TZ (and vice versa).\nBoth types are numeric. The following cases are supported:\nBoth use the same numeric type but possibly differ in precision and/or scale.\nCoercing NUMBER to FLOAT (and vice versa).\nBoth use the same numeric type but possibly differ in precision and/or scale.\nCoercing NUMBER to FLOAT (and vice versa).\nBoth types are timestamps. The following cases are supported:\nBoth use the same type but possibly differ in precision.\nCoercing TIMESTAMP_LTZ to TIMESTAMP_TZ (and vice versa).\nBoth use the same type but possibly differ in precision.\nCoercing TIMESTAMP_LTZ to TIMESTAMP_TZ (and vice versa).\nFor example:\nAn OBJECT(city VARCHAR, zipcode NUMBER) value can be coerced to an OBJECT(city VARCHAR, zipcode DOUBLE) value.\nAn OBJECT(city VARCHAR, zipcode NUMBER) value cant be coerced to an OBJECT(city VARCHAR, zipcode DATE) value.\nAn OBJECT(city VARCHAR, zipcode NUMBER) value can be coerced to an OBJECT(city VARCHAR, zipcode DOUBLE) value.\nAn OBJECT(city VARCHAR, zipcode NUMBER) value cant be coerced to an OBJECT(city VARCHAR, zipcode DATE) value.\nA MAP value with one value type can be coerced to a MAP value with a different value type if:\nBoth value types are numeric. The following cases are supported:\n\nBoth use the same numeric type but possibly differ in precision and/or scale.\nCoercing NUMBER to FLOAT (and vice versa).\nBoth use the same numeric type but possibly differ in precision and/or scale.\nCoercing NUMBER to FLOAT (and vice versa).\nBoth value types are timestamps. The following cases are supported:\n\nBoth use the same type but possibly differ in precision.\nCoercing TIMESTAMP_LTZ to TIMESTAMP_TZ (and vice versa).\nBoth use the same type but possibly differ in precision.\nCoercing TIMESTAMP_LTZ to TIMESTAMP_TZ (and vice versa).\nBoth value types are numeric. The following cases are supported:\nBoth use the same numeric type but possibly differ in precision and/or scale.\nCoercing NUMBER to FLOAT (and vice versa).\nBoth use the same numeric type but possibly differ in precision and/or scale.\nCoercing NUMBER to FLOAT (and vice versa).\nBoth value types are timestamps. The following cases are supported:\nBoth use the same type but possibly differ in precision.\nCoercing TIMESTAMP_LTZ to TIMESTAMP_TZ (and vice versa).\nBoth use the same type but possibly differ in precision.\nCoercing TIMESTAMP_LTZ to TIMESTAMP_TZ (and vice versa).\nFor example, a MAP(VARCHAR, NUMBER) value can be coerced to a MAP(VARCHAR, DOUBLE) value.\nA MAP value with one key type can be coerced to a MAP value with a different key type if both key types use the same integer NUMERIC\ntype that differ only in precision.\nFor example, a MAP(VARCHAR, NUMBER) value cant be coerced to a MAP(NUMBER, NUMBER) value.\nA structured type value cant be coerced to a semi-structured value (and vice versa).\nA VARCHAR value cant be coerced to a structured type value."
      },
      {
        "heading": "Casting from one structured type to another",
        "description": "\nYou can call the CAST function or use the :: operator to cast from a value of\none structured type to a value of another structured type. You can cast values from and to the following structured types:\nFor structured ARRAYs:\nYou can cast an ARRAY value of one type to an ARRAY value of another type.\nFor structured OBJECTs:\n\nYou can use a cast to\nchange the order of key-value pairs in an OBJECT value.\nYou can use a cast to\nchange the names of the keys in an OBJECT value.\nYou can use a cast to\nadd keys to an OBJECT value.\nYou can cast a structured OBJECT value to a MAP value.\nYou can use a cast to\nchange the order of key-value pairs in an OBJECT value.\nYou can use a cast to\nchange the names of the keys in an OBJECT value.\nYou can use a cast to\nadd keys to an OBJECT value.\nYou can cast a structured OBJECT value to a MAP value.\nFor MAP values:\n\nYou can cast a MAP value with keys and values of a specific type to a MAP value with keys and values of a different type.\nYou can cast a MAP value to a structured OBJECT value.\nYou can cast a MAP value with keys and values of a specific type to a MAP value with keys and values of a different type.\nYou can cast a MAP value to a structured OBJECT value.\nFor structured ARRAYs:\nYou can cast an ARRAY value of one type to an ARRAY value of another type.\nFor structured OBJECTs:\nYou can use a cast to\nchange the order of key-value pairs in an OBJECT value.\nYou can use a cast to\nchange the names of the keys in an OBJECT value.\nYou can use a cast to\nadd keys to an OBJECT value.\nYou can cast a structured OBJECT value to a MAP value.\nYou can use a cast to\nchange the order of key-value pairs in an OBJECT value.\nYou can use a cast to\nchange the names of the keys in an OBJECT value.\nYou can use a cast to\nadd keys to an OBJECT value.\nYou can cast a structured OBJECT value to a MAP value.\nFor MAP values:\nYou can cast a MAP value with keys and values of a specific type to a MAP value with keys and values of a different type.\nYou can cast a MAP value to a structured OBJECT value.\nYou can cast a MAP value with keys and values of a specific type to a MAP value with keys and values of a different type.\nYou can cast a MAP value to a structured OBJECT value.\nNote\nTRY_CAST isnt supported with structured types.\nIf it isnt possible to cast the values from one type to the other, the cast fails. For example, attempting to cast an\nARRAY(BOOLEAN) value to an ARRAY(DATE) value fails.\nThe following example casts an ARRAY(NUMBER) value to an ARRAY(VARCHAR) value:\nThe following example changes the order of key-value pairs in a structured OBJECT value:\nTo change the key names in a structured OBJECT value, specify the RENAME FIELDS keywords at the end of CAST. For example:\nIf the type that you are casting to has additional key-value pairs that arent present in the original structured OBJECT value,\nspecify the ADD FIELDS keywords at the end of CAST. For example:\nThe values for the newly added keys are set to NULL. If you want to assign a value to these keys, call the\nOBJECT_INSERT function instead.",
        "syntax": [
          "SELECT CAST(\n  CAST([1,2,3] AS ARRAY(NUMBER))\n  AS ARRAY(VARCHAR)) AS cast_array;",
          "+------------+\n| CAST_ARRAY |\n|------------|\n| [          |\n|   \"1\",     |\n|   \"2\",     |\n|   \"3\"      |\n| ]          |\n+------------+",
          "SELECT CAST(\n  {'city': 'San Mateo','state': 'CA'}::OBJECT(city VARCHAR, state VARCHAR)\n  AS OBJECT(state VARCHAR, city VARCHAR)) AS object_value_order;",
          "+-----------------------+\n| OBJECT_VALUE_ORDER    |\n|-----------------------|\n| {                     |\n|   \"state\": \"CA\",      |\n|   \"city\": \"San Mateo\" |\n| }                     |\n+-----------------------+",
          "SELECT CAST({'city':'San Mateo','state': 'CA'}::OBJECT(city VARCHAR, state VARCHAR)\n  AS OBJECT(city_name VARCHAR, state_name VARCHAR) RENAME FIELDS) AS object_value_key_names;",
          "+-----------------------------+\n| OBJECT_VALUE_KEY_NAMES      |\n|-----------------------------|\n| {                           |\n|   \"city_name\": \"San Mateo\", |\n|   \"state_name\": \"CA\"        |\n| }                           |\n+-----------------------------+",
          "SELECT CAST({'city':'San Mateo','state': 'CA'}::OBJECT(city VARCHAR, state VARCHAR)\n  AS OBJECT(city VARCHAR, state VARCHAR, zipcode NUMBER) ADD FIELDS) AS add_fields;",
          "+------------------------+\n| ADD_FIELDS             |\n|------------------------|\n| {                      |\n|   \"city\": \"San Mateo\", |\n|   \"state\": \"CA\",       |\n|   \"zipcode\": null      |\n| }                      |\n+------------------------+"
        ]
      },
      {
        "heading": "Constructing structured ARRAY, structured OBJECT, and MAP values",
        "description": "\nThe following sections explain how to construct structured ARRAY, structured OBJECT, and MAP values.\nUsing SQL functions to construct structured ARRAY and OBJECT values\nUsing ARRAY and OBJECT constants to construct structured ARRAY and OBJECT values\nConstructing a MAP value\nUsing SQL functions to construct structured ARRAY and OBJECT values\nUsing ARRAY and OBJECT constants to construct structured ARRAY and OBJECT values\nConstructing a MAP value"
      },
      {
        "heading": "Using SQL functions to construct structured ARRAY and OBJECT values",
        "description": "\nThe following functions construct semi-structured ARRAY values:\nARRAY_CONSTRUCT\nARRAY_CONSTRUCT_COMPACT\nARRAY_AGG\nTO_ARRAY\nARRAY_CONSTRUCT\nARRAY_CONSTRUCT_COMPACT\nARRAY_AGG\nTO_ARRAY\nThe following functions construct semi-structured OBJECT values:\nOBJECT_CONSTRUCT\nOBJECT_CONSTRUCT_KEEP_NULL\nOBJECT_AGG\nTO_OBJECT\nOBJECT_CONSTRUCT\nOBJECT_CONSTRUCT_KEEP_NULL\nOBJECT_AGG\nTO_OBJECT\nTo construct a structured ARRAY or OBJECT value, use these functions and explicitly cast the return value of the function. For example:\nFor details, refer to Explicitly casting a semi-structured type to a structured type.\nNote\nYou cant pass structured ARRAY, structured OBJECT, or MAP values to these functions. Doing so would result in a structured\ntype being implicitly cast to a semi-structured type, which isnt allowed, as noted in\nImplicit casting a value (coercion).",
        "syntax": [
          "SELECT ARRAY_CONSTRUCT(10, 20, 30)::ARRAY(NUMBER);",
          "SELECT OBJECT_CONSTRUCT(\n  'oname', 'abc',\n  'created_date', '2020-01-18'::DATE\n)::OBJECT(\n  oname VARCHAR,\n  created_date DATE\n);"
        ]
      },
      {
        "heading": "Using ARRAY and OBJECT constants to construct structured ARRAY and OBJECT values",
        "description": "\nWhen you specify an ARRAY constant or an OBJECT constant, you are\nspecifying a semi-structured ARRAY or OBJECT value.\nTo construct a structured ARRAY or OBJECT value, you must explicitly cast the expression. For example:\nFor details, refer to Explicitly casting a semi-structured type to a structured type.",
        "syntax": [
          "SELECT [10, 20, 30]::ARRAY(NUMBER);",
          "SELECT {\n  'oname': 'abc',\n  'created_date': '2020-01-18'::DATE\n}::OBJECT(\n  oname VARCHAR,\n  created_date DATE\n);"
        ]
      },
      {
        "heading": "Constructing a MAP value",
        "description": "\nTo construct a MAP value, construct a semi-structured OBJECT value, and cast the OBJECT value to a MAP value.\nFor example, the following statements both produce the MAP value {'city'->'San Mateo','state'->'CA'}:\nThe following statement produces the MAP value {-10->'CA',-20->'OR'}:\nFor details, refer to Casting semi-structured OBJECT and VARIANT values to MAP values.",
        "syntax": [
          "SELECT OBJECT_CONSTRUCT(\n  'city', 'San Mateo',\n  'state', 'CA'\n)::MAP(\n  VARCHAR,\n  VARCHAR\n);",
          "SELECT {\n  'city': 'San Mateo',\n  'state': 'CA'\n}::MAP(\n  VARCHAR,\n  VARCHAR\n);",
          "SELECT {\n  '-10': 'CA',\n  '-20': 'OR'\n}::MAP(\n  NUMBER,\n  VARCHAR\n);"
        ]
      },
      {
        "heading": "Working with keys, values, and elements in values of structured types",
        "description": "\nThe following sections explain how to use keys, values, and elements in values of structured types.\nGetting the list of keys from a structured OBJECT value\nGetting the list of keys from a MAP value\nAccessing values and elements from values of structured types\nDetermining the size of a structured ARRAY value\nDetermining the size of a MAP value\nLooking up elements in a structured ARRAY value\nDetermining if a MAP value contains a key\nGetting the list of keys from a structured OBJECT value\nGetting the list of keys from a MAP value\nAccessing values and elements from values of structured types\nDetermining the size of a structured ARRAY value\nDetermining the size of a MAP value\nLooking up elements in a structured ARRAY value\nDetermining if a MAP value contains a key"
      },
      {
        "heading": "Getting the list of keys from a structured OBJECT value",
        "description": "\nTo get the list of keys in a structured OBJECT value, call the OBJECT_KEYS function:\nIf the input is a structured OBJECT value, the function returns an ARRAY(VARCHAR) value containing the keys. If the input is a\nsemi-structured OBJECT value, the function returns an ARRAY value.",
        "syntax": [
          "SELECT OBJECT_KEYS({'city':'San Mateo','state':'CA'}::OBJECT(city VARCHAR, state VARCHAR));"
        ]
      },
      {
        "heading": "Getting the list of keys from a MAP value",
        "description": "\nTo get the list of keys in a MAP value, call the MAP_KEYS function:",
        "syntax": [
          "SELECT MAP_KEYS({'my_key':'my_value'}::MAP(VARCHAR,VARCHAR));"
        ]
      },
      {
        "heading": "Accessing values and elements from values of structured types",
        "description": "\nYou can use the following methods to access values and elements from structured ARRAY, structured OBJECT, and MAP\nvalues:\nThe GET function\nThe GET_IGNORE_CASE function\nThe GET_PATH function\nDot Notation\nBracket Notation\nThe GET function\nThe GET_IGNORE_CASE function\nThe GET_PATH function\nDot Notation\nBracket Notation\nThe returned values and elements have the type specified for the structured value, rather than VARIANT.\nThe following example passes the first element of a semi-structured ARRAY value and an ARRAY(VARCHAR) value to the\nSYSTEM$TYPEOF function to return the data type of that element:\nNote the following:\nWhen you pass a structured OBJECT value to the GET or GET_IGNORE_CASE function, you must specify a constant for the key.\nYou dont need to specify a constant if you are passing a MAP or structured ARRAY value to the GET function.\nYou also dont need to specify a constant if you are passing a MAP value to the GET_IGNORE_CASE function.\nWhen you pass a structured OBJECT, structured ARRAY, or MAP value to the GET_PATH function, you must specify a constant for the path\nname.\nFor a structured OBJECT value, if you use an OBJECT key or a path that doesnt exist, a compile-time error occurs.\nIn contrast, when you use an index, key, or path that doesnt exist with a semi-structured OBJECT value, the function returns NULL.\nWhen you pass a structured OBJECT value to the GET or GET_IGNORE_CASE function, you must specify a constant for the key.\nYou dont need to specify a constant if you are passing a MAP or structured ARRAY value to the GET function.\nYou also dont need to specify a constant if you are passing a MAP value to the GET_IGNORE_CASE function.\nWhen you pass a structured OBJECT, structured ARRAY, or MAP value to the GET_PATH function, you must specify a constant for the path\nname.\nFor a structured OBJECT value, if you use an OBJECT key or a path that doesnt exist, a compile-time error occurs.\nIn contrast, when you use an index, key, or path that doesnt exist with a semi-structured OBJECT value, the function returns NULL.",
        "syntax": [
          "SELECT\n  SYSTEM$TYPEOF(\n    ARRAY_CONSTRUCT('San Mateo')[0]\n  ) AS semi_structured_array_element,\n  SYSTEM$TYPEOF(\n    CAST(\n      ARRAY_CONSTRUCT('San Mateo') AS ARRAY(VARCHAR)\n    )[0]\n  ) AS structured_array_element;",
          "+-------------------------------+--------------------------+\n| SEMI_STRUCTURED_ARRAY_ELEMENT | STRUCTURED_ARRAY_ELEMENT |\n|-------------------------------+--------------------------|\n| VARIANT[LOB]                  | VARCHAR[LOB]             |\n+-------------------------------+--------------------------+"
        ]
      },
      {
        "heading": "Determining the size of a structured ARRAY value",
        "description": "\nTo determine the size of a structured ARRAY value, pass the ARRAY value to the ARRAY_SIZE function:",
        "syntax": [
          "SELECT ARRAY_SIZE([1,2,3]::ARRAY(NUMBER));"
        ]
      },
      {
        "heading": "Determining the size of a MAP value",
        "description": "\nTo determine the size of a MAP value, pass the MAP value to MAP_SIZE function:",
        "syntax": [
          "SELECT MAP_SIZE({'my_key':'my_value'}::MAP(VARCHAR,VARCHAR));"
        ]
      },
      {
        "heading": "Looking up elements in a structured ARRAY value",
        "description": "\nTo determine if an element is present in a structured ARRAY value, call the ARRAY_CONTAINS function.\nFor example:\nTo determine the position of an element in a structured ARRAY value, call the ARRAY_POSITION function.\nFor example:\nNote\nFor both functions, use an element of a type that is comparable to the type of the\nARRAY value.\nDont cast the expression for the element to a VARIANT value.",
        "syntax": [
          "SELECT ARRAY_CONTAINS(10, [1, 10, 100]::ARRAY(NUMBER));",
          "SELECT ARRAY_POSITION(10, [1, 10, 100]::ARRAY(NUMBER));"
        ]
      },
      {
        "heading": "Determining if a MAP value contains a key",
        "description": "\nTo determine if a MAP value contains a key, call the MAP_CONTAINS_KEY function:\nFor example:",
        "syntax": [
          "SELECT MAP_CONTAINS_KEY('key_to_find', my_map);",
          "SELECT MAP_CONTAINS_KEY(10, my_map);"
        ]
      },
      {
        "heading": "Comparing values",
        "description": "\nThe following sections explain how to compare values:\nComparing structured values with semi-structured values\nComparing structured values with other structured values\nDetermining if two ARRAY values overlap\nComparing structured values with semi-structured values\nComparing structured values with other structured values\nDetermining if two ARRAY values overlap"
      },
      {
        "heading": "Comparing structured values with semi-structured values",
        "description": "\nYou cant compare a structured ARRAY, structured OBJECT, or MAP value with a semi-structured ARRAY, OBJECT, or VARIANT value."
      },
      {
        "heading": "Comparing structured values with other structured values",
        "description": "\nYou can compare two values of the same type (for example, two structured ARRAY values, two structured OBJECT values, or two MAP values).\nCurrently, the following comparison operators are supported for comparing values of structured types:\n=\n!=\n<\n<=\n>=\n>\n=\n!=\n<\n<=\n>=\n>\nWhen you compare two structured values for equality, note the following:\nIf one type cant be coerced to the other type, the comparison fails.\nWhen you compare MAP values that have numeric keys, the keys are compared as numbers (not as VARCHAR values).\nIf one type cant be coerced to the other type, the comparison fails.\nWhen you compare MAP values that have numeric keys, the keys are compared as numbers (not as VARCHAR values).\nWhen you compare two structured values using <, <=, >=, or >, the structured value fields are compared in\nalphabetical order. For example, the following value:\nis greater than:",
        "syntax": [
          "{'a':2,'b':1}::OBJECT(b INTEGER,a INTEGER)",
          "{'a':1,'b':2}::OBJECT(b INTEGER,a INTEGER)"
        ]
      },
      {
        "heading": "Determining if two ARRAY values overlap",
        "description": "\nTo determine if the elements of two structured ARRAY values overlap, call the\nARRAYS_OVERLAP function. For example:\nThe ARRAY values must be of comparable types.\nYou cant pass a semi-structured ARRAY value and a structured ARRAY value to this function. Both ARRAY values must either be structured\nor semi-structured.",
        "syntax": [
          "SELECT ARRAYS_OVERLAP(numeric_array, other_numeric_array);"
        ]
      },
      {
        "heading": "Transforming values of structured types",
        "description": "\nThe following sections explain how to transform structured ARRAY, structured OBJECT, and MAP values:\nTransforming structured ARRAY values\nTransforming structured OBJECT values\nTransforming MAP values\nTransforming structured ARRAY values\nTransforming structured OBJECT values\nTransforming MAP values"
      },
      {
        "heading": "Transforming structured ARRAY values",
        "description": "\nWhen you pass a structured ARRAY value to these functions, the functions return a structured ARRAY value of the same type:\nARRAY_APPEND\nARRAY_CAT\nARRAY_COMPACT\nARRAY_EXCEPT\nARRAY_INSERT\nARRAY_INTERSECTION\nARRAY_PREPEND\nARRAY_SLICE\nARRAY_UNION_AGG\nARRAY_APPEND\nARRAY_CAT\nARRAY_COMPACT\nARRAY_EXCEPT\nARRAY_INSERT\nARRAY_INTERSECTION\nARRAY_PREPEND\nARRAY_SLICE\nARRAY_UNION_AGG\nThe next sections explain how these functions work with structured ARRAY values.\nFunctions that add elements to ARRAY values\nFunctions that accept multiple ARRAY values as input\nFunctions that add elements to ARRAY values\nFunctions that accept multiple ARRAY values as input\nThe following functions add elements to an ARRAY values:\nARRAY_APPEND\nARRAY_INSERT\nARRAY_PREPEND\nARRAY_APPEND\nARRAY_INSERT\nARRAY_PREPEND\nFor these functions, the type of the element must be coercible to the type of\nthe ARRAY value.\nFor example, the following call succeeds because a NUMBER value can be coerced to a DOUBLE value (the type of the ARRAY value):\nThe following call succeeds because VARCHAR values can be coerced to DOUBLE values:\nThe following call fails because DATE values cant be coerced to NUMBER values:\nThe following functions accept multiple ARRAY values as input arguments:\nARRAY_CAT\nARRAY_EXCEPT\nARRAY_INTERSECTION\nARRAY_CAT\nARRAY_EXCEPT\nARRAY_INTERSECTION\nWhen you call these functions, both arguments must either be structured ARRAY values or semi-structured ARRAY values.\nFor example, the following calls fail because one argument is a structured ARRAY value and the other argument is a\nsemi-structured ARRAY value:\nThe ARRAY_EXCEPT function returns an ARRAY value of the same type as the ARRAY value in the first argument.\nThe ARRAY_CAT and ARRAY_INTERSECTION functions return an ARRAY value of a type that can accommodate the types of both input values.\nFor example, the following call to ARRAY_CAT passes in two structured ARRAY values:\nThe first structured ARRAY value doesnt allow NULLs and contains NUMBER values with the scale of 0 (NUMBER(38, 0)).\nThe second structured ARRAY value contains a NULL and a NUMBER value that has the scale of 1.\nThe first structured ARRAY value doesnt allow NULLs and contains NUMBER values with the scale of 0 (NUMBER(38, 0)).\nThe second structured ARRAY value contains a NULL and a NUMBER value that has the scale of 1.\nThe ARRAY value returned by ARRAY_CAT allows NULLs and contains NUMBER values with the scale of 1.\nFor the ARRAY_CAT function, the ARRAY value in the second argument must be coercible\nto the type in the first argument.\nFor the ARRAY_EXCEPT and ARRAY_INTERSECTION functions, the ARRAY value in the second argument must be\ncomparable to the ARRAY value in the first argument.\nFor example, the following call succeeds because an ARRAY(NUMBER) value is comparable to an ARRAY(DOUBLE) value:\nThe following call fails because an ARRAY(NUMBER) value isnt comparable to an ARRAY(VARCHAR) value:",
        "syntax": [
          "SELECT ARRAY_APPEND( [1,2]::ARRAY(DOUBLE), 3::NUMBER );",
          "SELECT ARRAY_APPEND( [1,2]::ARRAY(DOUBLE), '3' );",
          "SELECT ARRAY_APPEND( [1,2]::ARRAY(NUMBER), '2022-02-02'::DATE );",
          "SELECT ARRAY_CAT( [1,2]::ARRAY(NUMBER), ['3','4'] );",
          "SELECT ARRAY_CAT( [1,2], ['3','4']::ARRAY(VARCHAR) );",
          "SELECT\n  ARRAY_CAT(\n    [1, 2, 3]::ARRAY(NUMBER NOT NULL),\n    [5.5, NULL]::ARRAY(NUMBER(2, 1))\n  ) AS concatenated_array,\n  SYSTEM$TYPEOF(concatenated_array);",
          "+--------------------+-----------------------------------+\n| CONCATENATED_ARRAY | SYSTEM$TYPEOF(CONCATENATED_ARRAY) |\n|--------------------+-----------------------------------|\n| [                  | ARRAY(NUMBER(38,1))[LOB]          |\n|   1,               |                                   |\n|   2,               |                                   |\n|   3,               |                                   |\n|   5.5,             |                                   |\n|   undefined        |                                   |\n| ]                  |                                   |\n+--------------------+-----------------------------------+",
          "SELECT ARRAY_EXCEPT( [1,2]::ARRAY(NUMBER), [2,3]::ARRAY(DOUBLE) );",
          "SELECT ARRAY_EXCEPT( [1,2]::ARRAY(NUMBER), ['2','3']::ARRAY(VARCHAR) );"
        ]
      },
      {
        "heading": "Transforming structured OBJECT values",
        "description": "\nThe following sections explain how to return a structured OBJECT value that has been transformed from another OBJECT value:\nRemoving key-value pairs\nInserting key-value pairs and updating values\nSelecting key-value pairs from an existing OBJECT\nRemoving key-value pairs\nInserting key-value pairs and updating values\nSelecting key-value pairs from an existing OBJECT\nTo change the order of key-value pairs, rename keys, or add keys without specifying values, use the\nCAST function or :: operator. For details, see\nCasting from one structured type to another.\nTo return a new OBJECT value that contains the key-value pairs from an existing OBJECT value with specific key-value pairs removed,\ncall the OBJECT_DELETE function.\nWhen calling this function, note the following:\nFor the arguments that are keys, you must specify constants.\nIf the specified key isnt part of the OBJECT type definition, the call fails. For example, the following call fails because\nthe OBJECT value doesnt contain the specified key zip_code:\nSELECT OBJECT_DELETE( {'city':'San Mateo','state':'CA'}::OBJECT(city VARCHAR,state VARCHAR), 'zip_code' );\n\nCopy\n093201 (23001): Function OBJECT_DELETE: expected structured object to contain field zip_code but it did not.\nThe function returns a structured OBJECT value. The type of the OBJECT value excludes the deleted key. For example, suppose that you\nremove the city key:\nSELECT\n  OBJECT_DELETE(\n    {'city':'San Mateo','state':'CA'}::OBJECT(city VARCHAR,state VARCHAR),\n    'city'\n  ) AS new_object,\n  SYSTEM$TYPEOF(new_object);\n\nCopy\nThe function returns an OBJECT value of the type OBJECT(state VARCHAR), which doesnt include the city key.\n+-----------------+----------------------------+\n| NEW_OBJECT      | SYSTEM$TYPEOF(NEW_OBJECT)  |\n|-----------------+----------------------------|\n| {               | OBJECT(state VARCHAR)[LOB] |\n|   \"state\": \"CA\" |                            |\n| }               |                            |\n+-----------------+----------------------------+\nIf the function removes all keys from the OBJECT value, the function returns an empty structured OBJECT value of the type OBJECT().\nSELECT\n  OBJECT_DELETE(\n    {'state':'CA'}::OBJECT(state VARCHAR),\n    'state'\n  ) AS new_object,\n  SYSTEM$TYPEOF(new_object);\n\nCopy\n+------------+---------------------------+\n| NEW_OBJECT | SYSTEM$TYPEOF(NEW_OBJECT) |\n|------------+---------------------------|\n| {}         | OBJECT()[LOB]             |\n+------------+---------------------------+\n\n\nWhen the type of a structured OBJECT value includes key-value pairs, the names and types of those pairs are included in parentheses\nin the type (for example, OBJECT(city VARCHAR)). Because an empty structured OBJECT value contains no key-value pairs, the\nparentheses are empty.\nFor the arguments that are keys, you must specify constants.\nIf the specified key isnt part of the OBJECT type definition, the call fails. For example, the following call fails because\nthe OBJECT value doesnt contain the specified key zip_code:\nThe function returns a structured OBJECT value. The type of the OBJECT value excludes the deleted key. For example, suppose that you\nremove the city key:\nThe function returns an OBJECT value of the type OBJECT(state VARCHAR), which doesnt include the city key.\nIf the function removes all keys from the OBJECT value, the function returns an empty structured OBJECT value of the type OBJECT().\nWhen the type of a structured OBJECT value includes key-value pairs, the names and types of those pairs are included in parentheses\nin the type (for example, OBJECT(city VARCHAR)). Because an empty structured OBJECT value contains no key-value pairs, the\nparentheses are empty.\nTo return a new OBJECT value that contains the key-value pairs from an existing OBJECT value with additional key-value pairs or new values for\nkeys, call the OBJECT_INSERT function.\nWhen calling this function, note the following:\nFor the arguments that are keys, you must specify constants.\nWhen the updateFlag argument is FALSE (when you are inserting a new key-value pair):\n\nIf you specify a key that already exists in the OBJECT value, an error occurs.\nSELECT OBJECT_INSERT(\n  {'city':'San Mateo','state':'CA'}::OBJECT(city VARCHAR,state VARCHAR),\n  'city',\n  'San Jose',\n  false\n);\n\nCopy\n093202 (23001): Function OBJECT_INSERT:\n  expected structured object to not contain field city but it did.\n\n\n\nThe function returns a structured OBJECT value. The type of the OBJECT value includes the newly inserted key. For example, suppose that\nyou add the zipcode key with the FLOAT value 94402:\nSELECT\n  OBJECT_INSERT(\n    {'city':'San Mateo','state':'CA'}::OBJECT(city VARCHAR,state VARCHAR),\n    'zip_code',\n    94402::FLOAT,\n    false\n  ) AS new_object,\n  SYSTEM$TYPEOF(new_object) AS type;\n\nCopy\n+-------------------------------------+-------------------------------------------------------------------+\n| NEW_OBJECT                          | TYPE                                                              |\n|-------------------------------------+-------------------------------------------------------------------|\n| {                                   | OBJECT(city VARCHAR, state VARCHAR, zip_code FLOAT NOT NULL)[LOB] |\n|   \"city\": \"San Mateo\",              |                                                                   |\n|   \"state\": \"CA\",                    |                                                                   |\n|   \"zip_code\": 9.440200000000000e+04 |                                                                   |\n| }                                   |                                                                   |\n+-------------------------------------+-------------------------------------------------------------------+\n\n\nThe type of the inserted value determines the type added to the OBJECT type definition. In this case, the value for\nzipcode is a value cast to a FLOAT, so the type of zipcode is FLOAT.\nIf you specify a key that already exists in the OBJECT value, an error occurs.\nSELECT OBJECT_INSERT(\n  {'city':'San Mateo','state':'CA'}::OBJECT(city VARCHAR,state VARCHAR),\n  'city',\n  'San Jose',\n  false\n);\n\nCopy\n093202 (23001): Function OBJECT_INSERT:\n  expected structured object to not contain field city but it did.\nThe function returns a structured OBJECT value. The type of the OBJECT value includes the newly inserted key. For example, suppose that\nyou add the zipcode key with the FLOAT value 94402:\nSELECT\n  OBJECT_INSERT(\n    {'city':'San Mateo','state':'CA'}::OBJECT(city VARCHAR,state VARCHAR),\n    'zip_code',\n    94402::FLOAT,\n    false\n  ) AS new_object,\n  SYSTEM$TYPEOF(new_object) AS type;\n\nCopy\n+-------------------------------------+-------------------------------------------------------------------+\n| NEW_OBJECT                          | TYPE                                                              |\n|-------------------------------------+-------------------------------------------------------------------|\n| {                                   | OBJECT(city VARCHAR, state VARCHAR, zip_code FLOAT NOT NULL)[LOB] |\n|   \"city\": \"San Mateo\",              |                                                                   |\n|   \"state\": \"CA\",                    |                                                                   |\n|   \"zip_code\": 9.440200000000000e+04 |                                                                   |\n| }                                   |                                                                   |\n+-------------------------------------+-------------------------------------------------------------------+\n\n\nThe type of the inserted value determines the type added to the OBJECT type definition. In this case, the value for\nzipcode is a value cast to a FLOAT, so the type of zipcode is FLOAT.\nWhen the updateFlag argument is TRUE (when you are replacing an existing key-value pair):\n\nIf you specify a key that doesnt exist in the OBJECT value, an error occurs.\nThe function returns a structured OBJECT value of the same type.\nThe type of the inserted value is coerced to the type of the existing key.\nIf you specify a key that doesnt exist in the OBJECT value, an error occurs.\nThe function returns a structured OBJECT value of the same type.\nThe type of the inserted value is coerced to the type of the existing key.\nFor the arguments that are keys, you must specify constants.\nWhen the updateFlag argument is FALSE (when you are inserting a new key-value pair):\nIf you specify a key that already exists in the OBJECT value, an error occurs.\nSELECT OBJECT_INSERT(\n  {'city':'San Mateo','state':'CA'}::OBJECT(city VARCHAR,state VARCHAR),\n  'city',\n  'San Jose',\n  false\n);\n\nCopy\n093202 (23001): Function OBJECT_INSERT:\n  expected structured object to not contain field city but it did.\nThe function returns a structured OBJECT value. The type of the OBJECT value includes the newly inserted key. For example, suppose that\nyou add the zipcode key with the FLOAT value 94402:\nSELECT\n  OBJECT_INSERT(\n    {'city':'San Mateo','state':'CA'}::OBJECT(city VARCHAR,state VARCHAR),\n    'zip_code',\n    94402::FLOAT,\n    false\n  ) AS new_object,\n  SYSTEM$TYPEOF(new_object) AS type;\n\nCopy\n+-------------------------------------+-------------------------------------------------------------------+\n| NEW_OBJECT                          | TYPE                                                              |\n|-------------------------------------+-------------------------------------------------------------------|\n| {                                   | OBJECT(city VARCHAR, state VARCHAR, zip_code FLOAT NOT NULL)[LOB] |\n|   \"city\": \"San Mateo\",              |                                                                   |\n|   \"state\": \"CA\",                    |                                                                   |\n|   \"zip_code\": 9.440200000000000e+04 |                                                                   |\n| }                                   |                                                                   |\n+-------------------------------------+-------------------------------------------------------------------+\n\n\nThe type of the inserted value determines the type added to the OBJECT type definition. In this case, the value for\nzipcode is a value cast to a FLOAT, so the type of zipcode is FLOAT.\nIf you specify a key that already exists in the OBJECT value, an error occurs.\nThe function returns a structured OBJECT value. The type of the OBJECT value includes the newly inserted key. For example, suppose that\nyou add the zipcode key with the FLOAT value 94402:\nThe type of the inserted value determines the type added to the OBJECT type definition. In this case, the value for\nzipcode is a value cast to a FLOAT, so the type of zipcode is FLOAT.\nWhen the updateFlag argument is TRUE (when you are replacing an existing key-value pair):\nIf you specify a key that doesnt exist in the OBJECT value, an error occurs.\nThe function returns a structured OBJECT value of the same type.\nThe type of the inserted value is coerced to the type of the existing key.\nIf you specify a key that doesnt exist in the OBJECT value, an error occurs.\nThe function returns a structured OBJECT value of the same type.\nThe type of the inserted value is coerced to the type of the existing key.\nTo return a new OBJECT value that contains selected key-value pairs from an existing OBJECT value,\ncall the OBJECT_PICK function.\nWhen calling this function, note the following:\nFor the arguments that are keys, you must specify constants.\nYou cant pass in an ARRAY of keys as the second argument. You must specify each key as a separate argument.\nThe function returns a structured OBJECT value. The type of the OBJECT value includes the keys in the order in which they are specified.\nFor example, suppose that you select the state and city keys in that order:\nSELECT\n  OBJECT_PICK(\n    {'city':'San Mateo','state':'CA','zip_code':94402}::OBJECT(city VARCHAR,state VARCHAR,zip_code DOUBLE),\n    'state',\n    'city') AS new_object,\n  SYSTEM$TYPEOF(new_object);\n\nCopy\nThe function returns an OBJECT value of the type OBJECT(state VARCHAR, city VARCHAR).\n+-----------------------+------------------------------------------+\n| NEW_OBJECT            | SYSTEM$TYPEOF(NEW_OBJECT)                |\n|-----------------------+------------------------------------------|\n| {                     | OBJECT(state VARCHAR, city VARCHAR)[LOB] |\n|   \"state\": \"CA\",      |                                          |\n|   \"city\": \"San Mateo\" |                                          |\n| }                     |                                          |\n+-----------------------+------------------------------------------+\nFor the arguments that are keys, you must specify constants.\nYou cant pass in an ARRAY of keys as the second argument. You must specify each key as a separate argument.\nThe function returns a structured OBJECT value. The type of the OBJECT value includes the keys in the order in which they are specified.\nFor example, suppose that you select the state and city keys in that order:\nThe function returns an OBJECT value of the type OBJECT(state VARCHAR, city VARCHAR).",
        "syntax": [
          "SELECT OBJECT_DELETE( {'city':'San Mateo','state':'CA'}::OBJECT(city VARCHAR,state VARCHAR), 'zip_code' );",
          "093201 (23001): Function OBJECT_DELETE: expected structured object to contain field zip_code but it did not.",
          "SELECT\n  OBJECT_DELETE(\n    {'city':'San Mateo','state':'CA'}::OBJECT(city VARCHAR,state VARCHAR),\n    'city'\n  ) AS new_object,\n  SYSTEM$TYPEOF(new_object);",
          "+-----------------+----------------------------+\n| NEW_OBJECT      | SYSTEM$TYPEOF(NEW_OBJECT)  |\n|-----------------+----------------------------|\n| {               | OBJECT(state VARCHAR)[LOB] |\n|   \"state\": \"CA\" |                            |\n| }               |                            |\n+-----------------+----------------------------+",
          "SELECT\n  OBJECT_DELETE(\n    {'state':'CA'}::OBJECT(state VARCHAR),\n    'state'\n  ) AS new_object,\n  SYSTEM$TYPEOF(new_object);",
          "+------------+---------------------------+\n| NEW_OBJECT | SYSTEM$TYPEOF(NEW_OBJECT) |\n|------------+---------------------------|\n| {}         | OBJECT()[LOB]             |\n+------------+---------------------------+",
          "SELECT OBJECT_INSERT(\n  {'city':'San Mateo','state':'CA'}::OBJECT(city VARCHAR,state VARCHAR),\n  'city',\n  'San Jose',\n  false\n);",
          "093202 (23001): Function OBJECT_INSERT:\n  expected structured object to not contain field city but it did.",
          "SELECT\n  OBJECT_INSERT(\n    {'city':'San Mateo','state':'CA'}::OBJECT(city VARCHAR,state VARCHAR),\n    'zip_code',\n    94402::FLOAT,\n    false\n  ) AS new_object,\n  SYSTEM$TYPEOF(new_object) AS type;",
          "+-------------------------------------+-------------------------------------------------------------------+\n| NEW_OBJECT                          | TYPE                                                              |\n|-------------------------------------+-------------------------------------------------------------------|\n| {                                   | OBJECT(city VARCHAR, state VARCHAR, zip_code FLOAT NOT NULL)[LOB] |\n|   \"city\": \"San Mateo\",              |                                                                   |\n|   \"state\": \"CA\",                    |                                                                   |\n|   \"zip_code\": 9.440200000000000e+04 |                                                                   |\n| }                                   |                                                                   |\n+-------------------------------------+-------------------------------------------------------------------+",
          "SELECT\n  OBJECT_PICK(\n    {'city':'San Mateo','state':'CA','zip_code':94402}::OBJECT(city VARCHAR,state VARCHAR,zip_code DOUBLE),\n    'state',\n    'city') AS new_object,\n  SYSTEM$TYPEOF(new_object);",
          "+-----------------------+------------------------------------------+\n| NEW_OBJECT            | SYSTEM$TYPEOF(NEW_OBJECT)                |\n|-----------------------+------------------------------------------|\n| {                     | OBJECT(state VARCHAR, city VARCHAR)[LOB] |\n|   \"state\": \"CA\",      |                                          |\n|   \"city\": \"San Mateo\" |                                          |\n| }                     |                                          |\n+-----------------------+------------------------------------------+"
        ]
      },
      {
        "heading": "Transforming MAP values",
        "description": "\nTo transform MAP values, use the following functions:\nMAP_CAT\nMAP_DELETE\nMAP_INSERT\nMAP_PICK\nMAP_CAT\nMAP_DELETE\nMAP_INSERT\nMAP_PICK"
      },
      {
        "heading": "Working with structured types",
        "description": "\nThe following sections explain how to use different SQL functions and set operators with values of structured types:\nUsing the FLATTEN function with values of structured types\nUsing the PARSE_JSON function\nUsing structured types with set operators and CASE expressions\nWorking with other semi-structured functions\nUsing the FLATTEN function with values of structured types\nUsing the PARSE_JSON function\nUsing structured types with set operators and CASE expressions\nWorking with other semi-structured functions"
      },
      {
        "heading": "Using the FLATTEN function with values of structured types",
        "description": "\nYou can pass structured ARRAY, structured OBJECT, and MAP values to the FLATTEN function. As is the case with semi-structured data\ntypes, you can use the PATH argument to specify the value being flattened.\nIf the value being flattened is a structured ARRAY value and the RECURSIVE argument is FALSE, the value column contains a value of\nthe same type as the ARRAY value.\nFor example:\nSELECT value, SYSTEM$TYPEOF(value)\n  FROM TABLE(FLATTEN(INPUT => [1.08, 2.13, 3.14]::ARRAY(DOUBLE)));\n\nCopy\n+-------+----------------------+\n| VALUE | SYSTEM$TYPEOF(VALUE) |\n|-------+----------------------|\n|  1.08 | FLOAT[DOUBLE]        |\n|  2.13 | FLOAT[DOUBLE]        |\n|  3.14 | FLOAT[DOUBLE]        |\n+-------+----------------------+\nIf the value being flattened is a MAP value and the RECURSIVE argument is FALSE, the key column contains a key of the same type as\nthe MAP key, and the value column contains a value of the same type as the MAP value.\nFor example:\nSELECT key, SYSTEM$TYPEOF(key), value, SYSTEM$TYPEOF(value)\n  FROM TABLE(FLATTEN(INPUT => {'my_key': 'my_value'}::MAP(VARCHAR, VARCHAR)));\n\nCopy\n+--------+--------------------+----------+----------------------+\n| KEY    | SYSTEM$TYPEOF(KEY) | VALUE    | SYSTEM$TYPEOF(VALUE) |\n|--------+--------------------+----------+----------------------|\n| my_key | VARCHAR[LOB]       | my_value | VARCHAR[LOB]         |\n+--------+--------------------+----------+----------------------+\nOtherwise, the key and value columns have the type VARIANT.\nIf the value being flattened is a structured ARRAY value and the RECURSIVE argument is FALSE, the value column contains a value of\nthe same type as the ARRAY value.\nFor example:\nIf the value being flattened is a MAP value and the RECURSIVE argument is FALSE, the key column contains a key of the same type as\nthe MAP key, and the value column contains a value of the same type as the MAP value.\nFor example:\nOtherwise, the key and value columns have the type VARIANT.\nFor MAP values, the order of keys and values returned is indeterminate.",
        "syntax": [
          "SELECT value, SYSTEM$TYPEOF(value)\n  FROM TABLE(FLATTEN(INPUT => [1.08, 2.13, 3.14]::ARRAY(DOUBLE)));",
          "+-------+----------------------+\n| VALUE | SYSTEM$TYPEOF(VALUE) |\n|-------+----------------------|\n|  1.08 | FLOAT[DOUBLE]        |\n|  2.13 | FLOAT[DOUBLE]        |\n|  3.14 | FLOAT[DOUBLE]        |\n+-------+----------------------+",
          "SELECT key, SYSTEM$TYPEOF(key), value, SYSTEM$TYPEOF(value)\n  FROM TABLE(FLATTEN(INPUT => {'my_key': 'my_value'}::MAP(VARCHAR, VARCHAR)));",
          "+--------+--------------------+----------+----------------------+\n| KEY    | SYSTEM$TYPEOF(KEY) | VALUE    | SYSTEM$TYPEOF(VALUE) |\n|--------+--------------------+----------+----------------------|\n| my_key | VARCHAR[LOB]       | my_value | VARCHAR[LOB]         |\n+--------+--------------------+----------+----------------------+"
        ]
      },
      {
        "heading": "Using the PARSE_JSON function",
        "description": "\nThe PARSE_JSON function doesnt return structured types."
      },
      {
        "heading": "Using structured types with set operators and CASE expressions",
        "description": "\nYou can use structured ARRAY, structured OBJECT, and MAP values in:\nQuery expressions combined by set operators (e.g. UNION ALL).\nCASE expressions.\nQuery expressions combined by set operators (e.g. UNION ALL).\nCASE expressions.\nFor set operators, if different types are used in the different expressions  (for example, if one type is ARRAY(NUMBER) and the other is\nARRAY(DOUBLE)), one type is coerced to the other."
      },
      {
        "heading": "Working with other semi-structured functions",
        "description": "\nThe following functions dont accept a structured ARRAY, structured OBJECT, or MAP values as an input argument:\nAS_ARRAY\nAS_OBJECT\nIS_ARRAY\nIS_OBJECT\nTYPEOF\nAS_ARRAY\nAS_OBJECT\nIS_ARRAY\nIS_OBJECT\nTYPEOF\nPassing a structured type value as input results in an error."
      },
      {
        "heading": "Accessing structured types in applications using drivers",
        "description": "\nIn applications that use drivers (for example, the ODBC or JDBC driver, the Snowflake Connector for Python, etc.), structured type\nvalues are returned as semi-structured type values. For example:\nThe values in a structured ARRAY column are returned as semi-structured ARRAY values to the client application.\nThe values in a structured OBJECT or MAP column are returned as semi-structured OBJECT values to the client application.\nThe values in a structured ARRAY column are returned as semi-structured ARRAY values to the client application.\nThe values in a structured OBJECT or MAP column are returned as semi-structured OBJECT values to the client application.\nNote\nFor client applications that use the JDBC driver, the ResultSet.getArray() method returns an error\nif the query results you want to retrieve contain a structured ARRAY value with NULL values.\nTo retrieve a string representation instead, use the ResultSet.getString() method:",
        "syntax": [
          "String result = resultSet.getString(1);"
        ]
      },
      {
        "heading": "Using structured types with user-defined functions (UDFs) and stored procedures",
        "description": "\nWhen you create a user-defined function (UDF), user-defined table function (UDTF), or stored procedure in\nSQL,\nSnowflake Scripting,\nJava,\nPython, or\nScala, you can use structured\ntypes in the arguments and return values. For example:\nNote\nStructured types arent yet supported in UDFs, UDTFs, and stored procedures in JavaScript.",
        "syntax": [
          "CREATE OR REPLACE FUNCTION my_udf(\n    location OBJECT(city VARCHAR, zipcode NUMBER, val ARRAY(BOOLEAN)))\n  RETURNS VARCHAR\n  AS\n  $$\n    ...\n  $$;",
          "CREATE OR REPLACE FUNCTION my_udtf(check BOOLEAN)\n  RETURNS TABLE(col1 ARRAY(VARCHAR))\n  AS\n  $$\n  ...\n  $$;",
          "CREATE OR REPLACE PROCEDURE my_procedure(values ARRAY(INTEGER))\n  RETURNS ARRAY(INTEGER)\n  LANGUAGE SQL\n  AS\n  $$\n    ...\n  $$;",
          "CREATE OR REPLACE FUNCTION my_function(values ARRAY(INTEGER))\n  RETURNS ARRAY(INTEGER)\n  LANGUAGE PYTHON\n  RUNTIME_VERSION=3.10\n  AS\n  $$\n    ...\n  $$;"
        ]
      },
      {
        "heading": "Viewing information about structured types",
        "description": "\nThe following sections describe the views and commands that you can use to view information about structured types:\nUsing the SHOW COLUMNS command to view structured type information\nUsing the DESCRIBE and other SHOW commands to view structured type information\nViewing information about the structured types used in a database\nUsing the SHOW COLUMNS command to view structured type information\nUsing the DESCRIBE and other SHOW commands to view structured type information\nViewing information about the structured types used in a database"
      },
      {
        "heading": "Using the SHOW COLUMNS command to view structured type information",
        "description": "\nIn the output of the SHOW COLUMNS command, the data_type column includes information about the\ntypes of elements, keys, and values."
      },
      {
        "heading": "Using the DESCRIBE and other SHOW commands to view structured type information",
        "description": "\nThe output of the following commands includes information about structured types:\nDESCRIBE TABLE\nDESCRIBE RESULT\nDESCRIBE FUNCTION\nDESCRIBE PROCEDURE\nSHOW FUNCTIONS\nSHOW PROCEDURES\nDESCRIBE TABLE\nDESCRIBE RESULT\nDESCRIBE FUNCTION\nDESCRIBE PROCEDURE\nSHOW FUNCTIONS\nSHOW PROCEDURES\nFor example, in the DESCRIBE RESULT output, the row for a MAP(VARCHAR, VARCHAR) column contains the following value in the\ntype column:\nThe row for an ARRAY(NUMBER) column contains the following value in the type column:",
        "syntax": [
          "map(VARCHAR, VARCHAR)",
          "ARRAY(NUMBER(38,0))"
        ]
      },
      {
        "heading": "Viewing information about the structured types used in a database",
        "description": "\nFor columns of structured types, the INFORMATION_SCHEMA COLUMNS view only provides information about\nthe basic data type of the column (ARRAY, OBJECT, or MAP).\nFor example, the data_type column just contains ARRAY, OBJECT, or MAP. The column doesnt include the types of the\nelements, keys, or values.\nTo view information about the types of elements, keys, and values, use the following views:\nFor information about the types of elements in structured ARRAY types, query the\nELEMENT_TYPES view in INFORMATION_SCHEMA or the\nELEMENT_TYPES view in ACCOUNT_USAGE.\nFor information about the types of keys and values in structured OBJECT and MAP types, query the\nFIELDS view in INFORMATION_SCHEMA or the\nFIELDS view in ACCOUNT_USAGE.\nFor information about the types of elements in structured ARRAY types, query the\nELEMENT_TYPES view in INFORMATION_SCHEMA or the\nELEMENT_TYPES view in ACCOUNT_USAGE.\nFor information about the types of keys and values in structured OBJECT and MAP types, query the\nFIELDS view in INFORMATION_SCHEMA or the\nFIELDS view in ACCOUNT_USAGE.\nOn this page\nSpecifying a structured type\nCreating a table with a structured type column\nAdding a structured type column\nDropping and renaming structured type columns\nUsing structured types in semi-structured types\nConverting structured and semi-structured types\nConstructing structured ARRAY, structured OBJECT, and MAP values\nWorking with keys, values, and elements in values of structured types\nComparing values\nTransforming values of structured types\nWorking with structured types\nAccessing structured types in applications using drivers\nUsing structured types with user-defined functions (UDFs) and stored procedures\nViewing information about structured types\nWe use cookies to improve your experience on our site. By accepting, you agree to our privacy policy.\nEnglish\nFranais\nDeutsch\n\n\nPortugus\n"
      }
    ]
  },
  {
    "category": "Unstructured data types",
    "url": "https://docs.snowflake.com/en/sql-reference/data-types-unstructured",
    "details": [
      {
        "heading": "Unstructured data types",
        "description": "\nSnowflake supports three different kinds of data:\nStructured data (such as a CSV file) follows a strict tabular schema. Structured data can be easily loaded into SQL tables.\nSemi-structured data (such as a JSON or XML file) has a flexible schema. Snowflake can access fields in semi-structured data using\nspecial functions, but the data is not as easily queried as structured data. Semi-structured data can be loaded into SQL tables\nusing VARIANT columns.\nUnstructured data (such as a document, image, or audio file) has no inherent schema. Unstructured data might still\nhave an internal structure (for example, PNG image files must follow a documented format) but such technical details do not generally\nrelate to the information in the file.\nStructured data (such as a CSV file) follows a strict tabular schema. Structured data can be easily loaded into SQL tables.\nSemi-structured data (such as a JSON or XML file) has a flexible schema. Snowflake can access fields in semi-structured data using\nspecial functions, but the data is not as easily queried as structured data. Semi-structured data can be loaded into SQL tables\nusing VARIANT columns.\nUnstructured data (such as a document, image, or audio file) has no inherent schema. Unstructured data might still\nhave an internal structure (for example, PNG image files must follow a documented format) but such technical details do not generally\nrelate to the information in the file.\nSnowflake provides ways of working with data in unstructured files, such as\nthe AI COMPLETE function and\nDocument AI.\nTo use unstructured data in Snowflake, it must first be stored on an internal or external stage. The Snowflake function\nthat processes the unstructured data reads it from there. Depending on the function, you specify the file in\none or more of the following ways:\nBy passing a stage name and a relative path to the file as two separate arguments to the function that will use it.\nBy passing a staged or scoped URL as a string.\nBy passing a FILE object created using the TO_FILE or TRY_TO_FILE function.\nBy passing a stage name and a relative path to the file as two separate arguments to the function that will use it.\nBy passing a staged or scoped URL as a string.\nBy passing a FILE object created using the TO_FILE or TRY_TO_FILE function."
      },
      {
        "heading": "FILE data type",
        "description": "\nPreview Feature  Open\nAvailable to all accounts.\nSnowflake provides the FILE data type for unstructured data. A FILE value represents a file stored in an internal or\nexternal stage, but does not store the files data, only a reference to it. It includes the following metadata:\nSTAGE: The name of the stage on which the file resides.\nRELATIVE_PATH: The relative path of the file in its stage.\nSTAGE_FILE_URL: The stage file URL.\nSCOPED_FILE_URL: A scoped file URL.\nCONTENT_TYPE: The MIME type of the file.\nSIZE: The size, in bytes, of the file.\nETAG: A unique hash of the file contents.\nLAST_MODIFIED: The timestamp at which the file was last modified.\nSTAGE: The name of the stage on which the file resides.\nRELATIVE_PATH: The relative path of the file in its stage.\nSTAGE_FILE_URL: The stage file URL.\nSCOPED_FILE_URL: A scoped file URL.\nCONTENT_TYPE: The MIME type of the file.\nSIZE: The size, in bytes, of the file.\nETAG: A unique hash of the file contents.\nLAST_MODIFIED: The timestamp at which the file was last modified.\nNot all of these fields are required. A FILE must have CONTENT_TYPE, SIZE, ETAG, and LAST_MODIFIED fields, and also the\nfiles location specified by STAGE plus RELATIVE_PATH, STAGE_FILE_URL, or SCOPED_FILE_URL.\nYou can create a file by passing a scoped file URL, a stage and path, or a metadata object to the\nTO_FILE or TRY_TO_FILE function."
      },
      {
        "heading": "FILE functions",
        "tables": [
          {
            "headers": [
              "Sub-category",
              "Function"
            ],
            "rows": [
              [
                "Constructors",
                "TO_FILE"
              ],
              [
                "",
                "TRY_TO_FILE"
              ],
              [
                "Accessors",
                "FL_GET_CONTENT_TYPE"
              ],
              [
                "",
                "FL_GET_ETAG"
              ],
              [
                "",
                "FL_GET_FILE_TYPE"
              ],
              [
                "",
                "FL_GET_LAST_MODIFIED"
              ],
              [
                "",
                "FL_GET_RELATIVE_PATH"
              ],
              [
                "",
                "FL_GET_SCOPED_FILE_URL"
              ],
              [
                "",
                "FL_GET_SIZE"
              ],
              [
                "",
                "FL_GET_STAGE"
              ],
              [
                "",
                "FL_GET_STAGE_FILE_URL"
              ],
              [
                "Utility Functions",
                "FL_IS_AUDIO"
              ],
              [
                "",
                "FL_IS_COMPRESSED"
              ],
              [
                "",
                "FL_IS_DOCUMENT"
              ],
              [
                "",
                "FL_IS_IMAGE"
              ],
              [
                "",
                "FL_IS_VIDEO"
              ]
            ]
          }
        ]
      },
      {
        "heading": "Usage notes",
        "description": "\nFILE values may become inconsistent with the underlying staged files. FILE values are not updated when you modify or\ndelete the underlying file. Conversely, if a FILE value is deleted from a table, the underlying file is not affected.\nPermissions on the underlying files are governed by the type of URL that was specified when creating the FILE. Stage\nfile URLs and stage/path combinations give permanent permission to callers that have access to the associated stage.\nScoped URLs give temporary user-based access to the underlying file for a 24-hour period.\nFILE values may become inconsistent with the underlying staged files. FILE values are not updated when you modify or\ndelete the underlying file. Conversely, if a FILE value is deleted from a table, the underlying file is not affected.\nPermissions on the underlying files are governed by the type of URL that was specified when creating the FILE. Stage\nfile URLs and stage/path combinations give permanent permission to callers that have access to the associated stage.\nScoped URLs give temporary user-based access to the underlying file for a 24-hour period."
      },
      {
        "heading": "Using unstructured data in Snowflake via SQL",
        "description": "\nCreate a table with a FILE column.\nLoad data into the table from an external stage my_images that contains image files. mpy_images can be an internal or external\nstage.\nNote\nThis process requires directory table support on the stage. Enable it, if necessary, using the SQL below:\nLoad data into the Snowflake table.\nRun SQL statements against images_table. For example, the following query returns the relative path of each file in\nthe table that was last modified between January 1, 2021 and January 1, 2023.",
        "syntax": [
          "CREATE TABLE images_table(img FILE);",
          "ALTER STAGE my_images DIRECTORY=(ENABLE=true);",
          "INSERT INTO images_table\n    SELECT TO_FILE(file_url) FROM DIRECTORY(@my_images);",
          "SELECT FL_GET_RELATIVE_PATH(f)\n    FROM images_table\n    WHERE FL_GET_LAST_MODIFIED(f) BETWEEN '2021-01-01' and '2023-01-01';"
        ]
      },
      {
        "heading": "Known limitations",
        "description": "\nThe FILE data type currently cannot be used in:\nCLUSTER BY, GROUP BY, and ORDER BY clauses\nHybrid tables, Iceberg tables, and external tables\nSnowScript\nSecured views\nBinds\nSearch optimization\nClients and connectors except Snowpark Python\nCLUSTER BY, GROUP BY, and ORDER BY clauses\nHybrid tables, Iceberg tables, and external tables\nSnowScript\nSecured views\nBinds\nSearch optimization\nClients and connectors except Snowpark Python\nOn this page\nFILE data type\nUsage notes\nUsing unstructured data in Snowflake via SQL\nKnown limitations\nRelated content\nIntroduction to unstructured data\nData type conversion\nWe use cookies to improve your experience on our site. By accepting, you agree to our privacy policy.\nEnglish\nFranais\nDeutsch\n\n\nPortugus\n"
      }
    ]
  },
  {
    "category": "Introduction to unstructured data",
    "url": "https://docs.snowflake.com/en/user-guide/unstructured-intro",
    "details": [
      {
        "heading": "Introduction to unstructured data",
        "description": "\nUnstructured data is information that does not fit into a predefined data model or schema. Typically text-heavy, such as form responses and\nsocial media conversations, unstructured data also encompasses images, video, and audio. Industry-specific file types such as VCF\n(genomics), KDF (semiconductors), or HDF5 (aeronautics) are included in this category.\nSnowflake supports the following actions:\nSecurely access data files located in cloud storage.\nShare file access URLs with collaborators and partners.\nLoad file access URLs and other file metadata into Snowflake tables.\nProcess unstructured data.\nLoad unstructured data with Document AI\nSecurely access data files located in cloud storage.\nShare file access URLs with collaborators and partners.\nLoad file access URLs and other file metadata into Snowflake tables.\nProcess unstructured data.\nLoad unstructured data with Document AI\nThis topic introduces key concepts and provides instructions for accessing, sharing, and processing unstructured data files."
      },
      {
        "heading": "Cloud Storage service support",
        "description": "\nBoth external (external cloud storage) and internal (i.e. Snowflake) stages support unstructured data.",
        "definitions": [
          {
            "term": "External stages:",
            "definition": "Store files in external cloud storage: Amazon S3, Google Cloud Storage, or one of the supported Microsoft Azure cloud storage services: Blob storage Data Lake Storage Gen2 General-purpose v1 General-purpose v2"
          }
        ]
      },
      {
        "heading": "Types of URLs available to access files",
        "tables": [
          {
            "headers": [
              "",
              "Scoped URL",
              "File URL",
              "Pre-signed URL"
            ],
            "rows": [
              [
                "Use cases",
                "Recommended for file administrators to give scoped access to data files to specific roles in the same account. Provide access to the\nfiles with a view that retrieves scoped URLs. Only roles that have privileges on the view can access the files. Snowflake records\ninformation in the query history about who uses a scoped URL to access a file, and when. Ideal for use in\ncustom applications, for providing unstructured data to other accounts through a share, or for downloading and analysis of\nunstructured data in Snowsight.",
                "Permanent URL to a file on a stage. To download or access a file, users send the file URL in a GET request to the REST API endpoint\nalong with the authorization token. Ideal for custom applications that require access to unstructured data files.",
                "Used to download or access files without authenticating into Snowflake or passing an authorization token. Pre-signed URLs are open;\nany user or application can directly access or download the files. Ideal for business intelligence applications or reporting tools\nthat need to display the unstructured file contents."
              ],
              [
                "How to generate",
                "Query the BUILD_SCOPED_FILE_URL function.",
                "Either Query the directory table for the stage that references the staged files or call the\nBUILD_STAGE_FILE_URL function.",
                "Query the GET_PRESIGNED_URL function."
              ],
              [
                "Usage",
                "The following options are available:\n\nIn Snowsight, click on a scoped URL in the query results table. Snowsight retrieves the file only for the user who generated the\nscoped URL.\nSend a scoped URL in a GET request to the file support REST API endpoint. For information, see REST API for unstructured data support.",
                "The following options are available:\n\nIn Snowsight, click on a file URL in the query results table. Snowsight retrieves the file only if the active role has sufficient\nprivileges.\nSend a file URL in a GET request to the file support REST API endpoint. For information, see REST API for unstructured data support.",
                "The following options are available:\n\nIn Snowsight, click on a pre-signed URL in the query results table.\nNavigate to the pre-signed URL directly in a web browser."
              ],
              [
                "Snowflake Secure Data Sharing",
                "Unstructured data files can be accessed by data consumers via column values of this type in secure views shared by data providers.",
                "Unstructured data files cannot be accessed by data consumers via column values of this type in secure views shared by data providers.",
                "Unstructured data files can be accessed by data consumers via column values of this type in secure views shared by data providers."
              ],
              [
                "Authorization",
                "Only the user who generates a scoped URL can use the URL to access the referenced file.",
                "Role specified in the GET REST API call must have sufficient privileges on the stage: USAGE (external stage) or READ (internal stage).",
                "Any person who has the pre-signed URL can access the referenced file for the life of the token."
              ],
              [
                "Expiration",
                "Expiration period for the query results cache (currently 24 hours).",
                "Permanent.",
                "Length of time specified in the expiration_time argument."
              ]
            ]
          }
        ]
      },
      {
        "heading": "Server-side encryption for unstructured data access",
        "description": "\nTo enable unstructured data access on an internal stage, you can consider using server-side encryption when you create the stage.\nOtherwise, staged files will be client-side encrypted by default. The encryption keys are owned by Snowflake,\nand client-side encrypted files are unreadable by users and external tools using pre-signed, file, or scoped URLs.\nTo configure server-side encryption for an internal stage, specify the SNOWFLAKE_SSE encryption type in the CREATE STAGE command.\nSee Internal stage parameters (internalStageParams) for more information.\nThe following example creates an internal stage named my_int_stage with server-side encryption and a directory table.\nImportant\nIf you require Tri-Secret Secure for security compliance, use the SNOWFLAKE_FULL encryption type for internal stages.\nSNOWFLAKE_SSE does not support Tri-Secret Secure.\nNote\nYou cannot change the encryption type for an internal stage after you create the stage.\nCurrently, creating internal stages with server-side encryption is limited to the following Snowflake client versions: JDBC Driver v3.12.11 (or higher)\nYou cannot change the encryption type for an internal stage after you create the stage.\nCurrently, creating internal stages with server-side encryption is limited to the following Snowflake client versions: JDBC Driver v3.12.11 (or higher)",
        "syntax": [
          "CREATE STAGE my_int_stage\n  ENCRYPTION = (TYPE = 'SNOWFLAKE_SSE')\n  DIRECTORY = ( ENABLE = true );"
        ]
      },
      {
        "heading": "Directory tables",
        "description": "\nDirectory tables store a catalog of staged files in cloud storage. Roles with sufficient privileges can query a directory table to retrieve\nfile URLs to access the staged files.\nFor details, see Directory tables."
      },
      {
        "heading": "SQL functions",
        "tables": [
          {
            "headers": [
              "SQL Function",
              "Description"
            ],
            "rows": [
              [
                "GET_STAGE_LOCATION",
                "Returns the URL for an external or internal named stage using the stage name as the input."
              ],
              [
                "GET_RELATIVE_PATH",
                "Extracts the path of a staged file relative to its location in the stage using the stage name and absolute file path in cloud storage as inputs."
              ],
              [
                "GET_ABSOLUTE_PATH",
                "Returns the absolute path of a staged file using the stage name and path of the file relative to its location in the stage as inputs."
              ],
              [
                "GET_PRESIGNED_URL",
                "Generates the pre-signed URL to a staged file using the stage name and relative file path as inputs. Access files in an external stage using the function."
              ],
              [
                "BUILD_SCOPED_FILE_URL",
                "Generates a scoped Snowflake file URL to a staged file using the stage name and relative file path as inputs."
              ],
              [
                "BUILD_STAGE_FILE_URL",
                "Generates a Snowflake file URL to a staged file using the stage name and relative file path as inputs."
              ],
              [
                "TO_FILE",
                "Returns a FILE object that represents a file stored in an internal or external stage."
              ],
              [
                "TRY_TO_FILE",
                "Returns a FILE object as with TO_FILE, but returns NULL if the file does not exist or is not accessible."
              ]
            ]
          }
        ]
      },
      {
        "heading": "Downloading staged files in Snowsight"
      },
      {
        "heading": "Downloading a generated scoped, pre-signed, or file URL",
        "description": "\nUsers can select a generated scoped, pre-signed, or file URL in the results table of a Snowsight\nworksheet and download the referenced file.\nSign in to Snowsight.\nSelect Projects  Worksheets  My Worksheets, or open a local worksheet by navigating to Recent\nor Folders  <worksheet_name>.\nReturn a scoped, pre-signed, or file URL in a query using any one of the supported methods.\nSelect the URL in the results table. Snowsight downloads the file referenced by the URL.\nSign in to Snowsight.\nSelect Projects  Worksheets  My Worksheets, or open a local worksheet by navigating to Recent\nor Folders  <worksheet_name>.\nReturn a scoped, pre-signed, or file URL in a query using any one of the supported methods.\nSelect the URL in the results table. Snowsight downloads the file referenced by the URL."
      },
      {
        "heading": "Downloading from an internal stage",
        "description": "\nUsers can download a file from the internal stage directly from Snowsight.\nSign in to Snowsight.\nNavigate to your file on the internal stage. For more information about finding files, see Viewing staged files.\nSelect the  button, and select Download.\nSign in to Snowsight.\nNavigate to your file on the internal stage. For more information about finding files, see Viewing staged files.\nSelect the  button, and select Download."
      },
      {
        "heading": "Processing unstructured data",
        "description": "\nSnowflake supports the following features to help you process unstructured data.",
        "definitions": [
          {
            "term": "External Functions",
            "definition": "External functions are user-defined functions that you store and execute outside of Snowflake. With external functions, you can use libraries such as Amazon Textract, Document AI, or Azure Computer Vision that cannot be accessed from internal user-defined functions (UDFs). For more information, see Writing external functions."
          },
          {
            "term": "User-defined Functions and Stored Procedures",
            "definition": "Snowflake supports multiple ways to read a file within Java or Python code so that you can process unstructured data or use your own machine learning models in user-defined functions (UDFs), user-defined table functions (UDTFs), or stored procedures. You can extend the SQL that you use in Snowflake, or build an application using the Snowpark API. See the following topics for more information and examples. Processing unstructured data with UDF and procedure handlers Reading a File with a Python UDF Handler Reading files with a Python Stored Procedure Handler Reading Files with the Snowpark API for Java Reading Files with the Snowpark API for Python"
          }
        ]
      },
      {
        "heading": "FILE data type",
        "description": "\nThe FILE data type represents a file stored in an internal or external stage. Some built-in\nfunctions accept a FILE object in place of a stage name and file path. Use the TO_FILE\nor TRY_TO_FILE function to convert a files location in a stage to a FILE object.\nOn this page\nCloud Storage service support\nTypes of URLs available to access files\nServer-side encryption for unstructured data access\nDirectory tables\nSQL functions\nDownloading staged files in Snowsight\nProcessing unstructured data\nFILE data type\nRelated content\nUnstructured data types\nWe use cookies to improve your experience on our site. By accepting, you agree to our privacy policy.\nEnglish\nFranais\nDeutsch\n\n\nPortugus\n"
      }
    ]
  },
  {
    "category": "Geospatial data types",
    "url": "https://docs.snowflake.com/en/sql-reference/data-types-geospatial",
    "details": [
      {
        "heading": "Geospatial data types",
        "description": "\nSnowflake offers native support for geospatial features such as points, lines, and polygons on the Earths surface.\nTip\nYou can use the search optimization service to improve query performance.\nFor details, see Search Optimization Service."
      },
      {
        "heading": "Data types",
        "description": "\nSnowflake provides the following data types for geospatial data:\nThe GEOGRAPHY data type, which models Earth as though it were a perfect sphere.\nThe GEOMETRY data type, which represents features in a planar (Euclidean, Cartesian)\ncoordinate system.\nThe GEOGRAPHY data type, which models Earth as though it were a perfect sphere.\nThe GEOMETRY data type, which represents features in a planar (Euclidean, Cartesian)\ncoordinate system."
      },
      {
        "heading": "GEOGRAPHY data type",
        "description": "\nThe GEOGRAPHY data type follows the WGS 84 standard (spatial reference ID 4326; for details, see\nhttps://epsg.io/4326).\nPoints on the earth are represented as degrees of longitude (from -180 degrees to +180 degrees) and latitude\n(-90 to +90). Snowflake uses 14 decimal places to store GEOGRAPHY coordinates. When the data includes decimal\nplaces exceeding this limit, the coordinates are rounded to ensure compliance with the specified length constraint.\nAltitude currently isnt supported.\nLine segments are interpreted as great circle arcs on the Earths surface.\nSnowflake also provides\ngeospatial functions that\noperate on the GEOGRAPHY data type.\nIf you have geospatial data (for example, longitude and latitude data, WKT, WKB, GeoJSON, and so on), we suggest converting and\nstoring this data in GEOGRAPHY columns, rather than keeping the data in their original formats in VARCHAR, VARIANT or NUMBER columns.\nStoring your data in GEOGRAPHY columns can significantly improve the performance of queries that use geospatial functionality."
      },
      {
        "heading": "GEOMETRY data type",
        "description": "\nThe GEOMETRY data type represents features in a planar (Euclidean, Cartesian) coordinate system.\nThe coordinates are represented as pairs of real numbers (x, y). Currently, only 2D coordinates are supported.\nThe units of the X and Y are determined by the spatial reference system (SRS) associated with the GEOMETRY object.\nThe spatial reference system is identified by the spatial reference system identifier (SRID) number. Unless\nthe SRID is provided when creating the GEOMETRY object or by calling ST_SETSRID, the SRID is 0.\nSnowflake uses 14 decimal places to store GEOMETRY coordinates. When the data includes decimal\nplaces exceeding this limit, the coordinates are rounded to ensure compliance with the specified length constraint.\nSnowflake provides a set of\ngeospatial functions that operate on the GEOMETRY data type. For these functions:\nAll functions assume planar coordinates, even if the geometry uses a non-planar SRS.\nThe measurement functions (for example, ST_LENGTH) use the same units as the coordinate system.\nFor functions that accept multiple GEOMETRY expressions as arguments (for example, ST_DISTANCE),\nthe input expressions must be defined in the same SRS.\nAll functions assume planar coordinates, even if the geometry uses a non-planar SRS.\nThe measurement functions (for example, ST_LENGTH) use the same units as the coordinate system.\nFor functions that accept multiple GEOMETRY expressions as arguments (for example, ST_DISTANCE),\nthe input expressions must be defined in the same SRS."
      },
      {
        "heading": "Geospatial input and output",
        "description": "\nThe following sections cover the supported standard formats and object types when reading and writing geospatial data.\nSupported standard input and output formats\nSupported geospatial object types\nSpecifying the output format for result sets\nExamples of inserting and querying GEOGRAPHY data\nSupported standard input and output formats\nSupported geospatial object types\nSpecifying the output format for result sets\nExamples of inserting and querying GEOGRAPHY data"
      },
      {
        "heading": "Supported standard input and output formats",
        "description": "\nThe GEOGRAPHY and GEOMETRY data types support the following standard industry formats for input and output:\nWell-Known Text\n(WKT)\nWell-Known Binary\n(WKB)\nExtended WKT and WKB (EWKT and EWKB)\n(see the note on EWKT and EWKB handling)\nIETF GeoJSON\n(see the note on GeoJSON handling)\nWell-Known Text\n(WKT)\nWell-Known Binary\n(WKB)\nExtended WKT and WKB (EWKT and EWKB)\n(see the note on EWKT and EWKB handling)\nIETF GeoJSON\n(see the note on GeoJSON handling)\nYou might also find the following Open Geospatial Consortiums Simple Feature Access references helpful:\nCommon Architecture\nSQL Option\nCommon Architecture\nSQL Option\nAny departure from these standards is noted explicitly in the Snowflake documentation.\nThe WKT and WKB standards specify a format only. The semantics of WKT/WKB objects depend on the reference system (for\nexample, a plane or a sphere).\nThe GeoJSON standard, on the other hand, specifies both a format and its semantics: GeoJSON points are explicitly\nWGS 84 coordinates, and GeoJSON line segments are planar edges (straight lines).\nContrary to that, the Snowflake GEOGRAPHY data type interprets all line segments, including those input from or\noutput to GeoJSON format, as great circle arcs. In essence, Snowflake treats GeoJSON as JSON-formatted WKT with spherical\nsemantics.\nEWKT and EWKB are non-standard formats introduced by PostGIS.\nThey enhance the WKT and WKB formats by including a spatial reference system identifier (SRID), which specifies the\ncoordinate reference system to use with the data. Snowflake currently supports only WGS84, which maps to SRID=4326.\nBy default, Snowflake issues an error if an EWKB or EWKT input value contains an SRID other than 4326. Conversely, all EWKB and EWKT output values have SRID=4326."
      },
      {
        "heading": "Supported geospatial object types",
        "description": "\nThe GEOGRAPHY and GEOMETRY data types can store the following types of geospatial objects:\nWKT / WKB / EWKT / EWKB / GeoJSON geospatial objects:\n\nPoint\nMultiPoint\nLineString\nMultiLineString\nPolygon\nMultiPolygon\nGeometryCollection\nPoint\nMultiPoint\nLineString\nMultiLineString\nPolygon\nMultiPolygon\nGeometryCollection\nThese GeoJSON-specific geospatial objects:\n\nFeature\nFeatureCollection\nFeature\nFeatureCollection\nWKT / WKB / EWKT / EWKB / GeoJSON geospatial objects:\nPoint\nMultiPoint\nLineString\nMultiLineString\nPolygon\nMultiPolygon\nGeometryCollection\nPoint\nMultiPoint\nLineString\nMultiLineString\nPolygon\nMultiPolygon\nGeometryCollection\nThese GeoJSON-specific geospatial objects:\nFeature\nFeatureCollection\nFeature\nFeatureCollection"
      },
      {
        "heading": "Specifying the output format for result sets",
        "tables": [
          {
            "headers": [
              "Parameter value",
              "Description"
            ],
            "rows": [
              [
                "GeoJSON (default)",
                "The GEOGRAPHY / GEOMETRY result is rendered as an OBJECT in GeoJSON format."
              ],
              [
                "WKT",
                "The GEOGRAPHY / GEOMETRY result is rendered as a VARCHAR in WKT format."
              ],
              [
                "WKB",
                "The GEOGRAPHY / GEOMETRY result is rendered as a BINARY in WKB format."
              ],
              [
                "EWKT",
                "The GEOGRAPHY / GEOMETRY result is rendered as a VARCHAR in EWKT format."
              ],
              [
                "EWKB",
                "The GEOGRAPHY / GEOMETRY result is rendered as a BINARY in EWKB format."
              ]
            ]
          }
        ]
      },
      {
        "heading": "Examples of inserting and querying GEOGRAPHY data",
        "description": "\nThe code below shows sample input and output for the GEOGRAPHY data type. Note the following:\nFor the coordinates in WKT, EWKT, and GeoJSON, longitude appears before latitude (for example, POINT(lon lat)).\nFor the coordinates in WKT, EWKT, and GeoJSON, longitude appears before latitude (for example, POINT(lon lat)).\nFor the WKB and EWKB output, it is assumed that the BINARY_OUTPUT_FORMAT parameter\nis set to HEX (the default value for the parameter).\nFor the WKB and EWKB output, it is assumed that the BINARY_OUTPUT_FORMAT parameter\nis set to HEX (the default value for the parameter).\nThe following example creates a table with a GEOGRAPHY column, inserts data in WKT format, and returns\nthe data in different output formats.",
        "syntax": [
          "CREATE OR REPLACE TABLE geospatial_table (id INTEGER, g GEOGRAPHY);\nINSERT INTO geospatial_table VALUES\n  (1, 'POINT(-122.35 37.55)'),\n  (2, 'LINESTRING(-124.20 42.00, -120.01 41.99)');",
          "ALTER SESSION SET GEOGRAPHY_OUTPUT_FORMAT='GeoJSON';",
          "SELECt g\n  FROM geospatial_table\n  ORDER BY id;",
          "+------------------------+\n| G                      |\n|------------------------|\n| {                      |\n|   \"coordinates\": [     |\n|     -122.35,           |\n|     37.55              |\n|   ],                   |\n|   \"type\": \"Point\"      |\n| }                      |\n| {                      |\n|   \"coordinates\": [     |\n|     [                  |\n|       -124.2,          |\n|       42               |\n|     ],                 |\n|     [                  |\n|       -120.01,         |\n|       41.99            |\n|     ]                  |\n|   ],                   |\n|   \"type\": \"LineString\" |\n| }                      |\n+------------------------+",
          "ALTER SESSION SET GEOGRAPHY_OUTPUT_FORMAT='WKT';",
          "SELECt g\n  FROM geospatial_table\n  ORDER BY id;",
          "+-------------------------------------+\n| G                                   |\n|-------------------------------------|\n| POINT(-122.35 37.55)                |\n| LINESTRING(-124.2 42,-120.01 41.99) |\n+-------------------------------------+",
          "ALTER SESSION SET GEOGRAPHY_OUTPUT_FORMAT='WKB';",
          "SELECt g\n  FROM geospatial_table\n  ORDER BY id;",
          "+------------------------------------------------------------------------------------+\n| G                                                                                  |\n|------------------------------------------------------------------------------------|\n| 01010000006666666666965EC06666666666C64240                                         |\n| 010200000002000000CDCCCCCCCC0C5FC00000000000004540713D0AD7A3005EC01F85EB51B8FE4440 |\n+------------------------------------------------------------------------------------+",
          "ALTER SESSION SET GEOGRAPHY_OUTPUT_FORMAT='EWKT';",
          "SELECt g\n  FROM geospatial_table\n  ORDER BY id;",
          "+-----------------------------------------------+\n| G                                             |\n|-----------------------------------------------|\n| SRID=4326;POINT(-122.35 37.55)                |\n| SRID=4326;LINESTRING(-124.2 42,-120.01 41.99) |\n+-----------------------------------------------+",
          "ALTER SESSION SET GEOGRAPHY_OUTPUT_FORMAT='EWKB';",
          "SELECt g\n  FROM geospatial_table\n  ORDER BY id;",
          "+--------------------------------------------------------------------------------------------+\n| G                                                                                          |\n|--------------------------------------------------------------------------------------------|\n| 0101000020E61000006666666666965EC06666666666C64240                                         |\n| 0102000020E610000002000000CDCCCCCCCC0C5FC00000000000004540713D0AD7A3005EC01F85EB51B8FE4440 |\n+--------------------------------------------------------------------------------------------+"
        ]
      },
      {
        "heading": "Using geospatial data in Snowflake",
        "description": "\nThe following sections cover the supported standard formats and object types when reading and writing geospatial data.\nUnderstanding the effects of using different SRIDs with GEOMETRY\nChanging the spatial reference system (SRS) and SRID of a GEOMETRY object\nPerforming DML operations on GEOGRAPHY and GEOMETRY columns\nLoading geospatial data from stages\nUsing geospatial data with Java UDFs\nUsing geospatial data with JavaScript UDFs\nUsing geospatial data with Python UDFs\nUsing GEOGRAPHY objects with H3\nUnderstanding the effects of using different SRIDs with GEOMETRY\nChanging the spatial reference system (SRS) and SRID of a GEOMETRY object\nPerforming DML operations on GEOGRAPHY and GEOMETRY columns\nLoading geospatial data from stages\nUsing geospatial data with Java UDFs\nUsing geospatial data with JavaScript UDFs\nUsing geospatial data with Python UDFs\nUsing GEOGRAPHY objects with H3"
      },
      {
        "heading": "Understanding the effects of using different SRIDs with GEOMETRY",
        "description": "\nIn a GEOMETRY column, you can insert objects that have different SRIDs. If the column contains more than one SRID, some of the\nimportant performance optimizations arent applied. This can result in slower queries, in particular when joining on a geospatial\npredicate."
      },
      {
        "heading": "Changing the spatial reference system (SRS) and SRID of a GEOMETRY object",
        "description": "\nTo change the SRS and SRID of an existing GEOMETRY object, call the ST_TRANSFORM function,\npassing in the new SRID. The function returns a new GEOMETRY object with the new SRID and the coordinates converted to use the\nSRS. For example, to return a GEOMETRY object for geometry_expression that uses the SRS for SRID 32633, execute the following\nstatement:\nIf the original SRID isnt set correctly in the existing GEOMETRY object, specify the original SRID as an additional argument.\nFor example, if geometry_expression is a GEOMETRY object that uses the SRID 4326, and you want to transform this to use the\nSRID 28992, execute the following statement:\nIf a GEOMETRY object uses the correct coordinates for a SRS but has the wrong SRID, you can fix the SRID by calling the\nST_SETSRID function. For example, the following statement sets the SRID for\ngeometry_expression to 4326, while leaving the coordinates unchanged:",
        "syntax": [
          "SELECT ST_TRANSFORM(geometry_expression, 32633);",
          "SELECT ST_TRANSFORM(geometry_expression, 4326, 28992);",
          "SELECT ST_SETSRID(geometry_expression, 4326);"
        ]
      },
      {
        "heading": "Performing DML operations on GEOGRAPHY and GEOMETRY columns",
        "description": "\nWhen a GEOGRAPHY or GEOMETRY column is the target of a DML operation (INSERT, COPY, UPDATE, MERGE, or CREATE TABLE AS), the\ncolumns source expression can be any of the following types:\nGEOGRAPHY or GEOMETRY : An expression of type GEOGRAPHY or GEOMETRY is usually the result of a parsing function, a constructor\nfunction, or an existing GEOGRAPHY or GEOMETRY column. For a complete list of supported functions and categories of functions,\nsee Geospatial functions.\nVARCHAR: Interpreted as a WKT, WKB (in hex format), EWKT, EWKB (in hex format), or GeoJSON formatted string (see\nTO_GEOGRAPHY(VARCHAR)).\nBINARY: Interpreted as a WKB binary (see TO_GEOGRAPHY(BINARY) and\nTO_GEOMETRY(BINARY)).\nVARIANT: Interpreted as a GeoJSON object (see TO_GEOGRAPHY(VARIANT) and\nTO_GEOMETRY(VARIANT)).\nGEOGRAPHY or GEOMETRY : An expression of type GEOGRAPHY or GEOMETRY is usually the result of a parsing function, a constructor\nfunction, or an existing GEOGRAPHY or GEOMETRY column. For a complete list of supported functions and categories of functions,\nsee Geospatial functions.\nVARCHAR: Interpreted as a WKT, WKB (in hex format), EWKT, EWKB (in hex format), or GeoJSON formatted string (see\nTO_GEOGRAPHY(VARCHAR)).\nBINARY: Interpreted as a WKB binary (see TO_GEOGRAPHY(BINARY) and\nTO_GEOMETRY(BINARY)).\nVARIANT: Interpreted as a GeoJSON object (see TO_GEOGRAPHY(VARIANT) and\nTO_GEOMETRY(VARIANT))."
      },
      {
        "heading": "Loading geospatial data from stages",
        "description": "\nYou can load data from CSV or JSON/AVRO files in a stage directly (that is, without copy transforms) into a\nGEOGRAPHY column.\nCSV: String values from the corresponding CSV column are parsed as GeoJSON, WKT, EWKT, WKB, or EWKB (see\nTO_GEOGRAPHY(VARCHAR)).\nJSON/AVRO: The JSON values in the file are interpreted as GeoJSON (see\nTO_GEOGRAPHY(VARIANT)).\nSee also GeoJSON handling for GEOGRAPHY values.\nCSV: String values from the corresponding CSV column are parsed as GeoJSON, WKT, EWKT, WKB, or EWKB (see\nTO_GEOGRAPHY(VARCHAR)).\nJSON/AVRO: The JSON values in the file are interpreted as GeoJSON (see\nTO_GEOGRAPHY(VARIANT)).\nSee also GeoJSON handling for GEOGRAPHY values.\nLoading data from other file formats (Parquet, ORC, and so on) is\npossible through a COPY transform."
      },
      {
        "heading": "Using geospatial data with Java UDFs",
        "description": "\nJava UDFs allow the GEOGRAPHY type as an argument and as a return value. See SQL-Java Data Type Mappings and\nPassing a GEOGRAPHY value to an in-line Java UDF for details."
      },
      {
        "heading": "Using geospatial data with JavaScript UDFs",
        "description": "\nJavaScript UDFs allow the GEOGRAPHY or GEOMETRY type as an argument and as a return value.\nIf a JavaScript UDF has an argument of type GEOGRAPHY or GEOMETRY, that argument is visible as a JSON object in GeoJSON\nformat inside the UDF body.\nIf a JavaScript UDF returns GEOGRAPHY or GEOMETRY, the UDF body is expected to return a JSON object in GeoJSON format.\nFor example, these two JavaScript UDFs are roughly equivalent to the built-in functions ST_X and ST_MAKEPOINT:",
        "syntax": [
          "CREATE OR REPLACE FUNCTION my_st_x(g GEOGRAPHY) RETURNS REAL\nLANGUAGE JAVASCRIPT\nAS\n$$\n  if (G[\"type\"] != \"Point\")\n  {\n     throw \"Not a point\"\n  }\n  return G[\"coordinates\"][0]\n$$;\n\nCREATE OR REPLACE FUNCTION my_st_makepoint(lng REAL, lat REAL) RETURNS GEOGRAPHY\nLANGUAGE JAVASCRIPT\nAS\n$$\n  g = {}\n  g[\"type\"] = \"Point\"\n  g[\"coordinates\"] = [ LNG, LAT ]\n  return g\n$$;"
        ]
      },
      {
        "heading": "Using geospatial data with Python UDFs",
        "description": "\nPython UDFs allow the GEOGRAPHY and GEOMETRY type as an argument and as a return value.\nIf a Python UDF has an argument of type GEOGRAPHY or GEOMETRY, that argument is represented as a\nGeoJSON object, which is converted to a Python dict object inside the UDF body.\nIf a Python UDF returns GEOGRAPHY or GEOMETRY, the UDF body is expected to return a Python dict object\nthat complies with the structure of GeoJSON.\nFor example, this Python UDF returns the number of distinct geometries that constitute a composite GEOGRAPHY type:\nCheck Snowflake Labs for more samples\nof Python UDFs. Some of them enable complex spatial manipulations or simplify data ingestion. For example,\nthis UDF allows\nreading formats that arent supported natively, such as Shapefiles (.SHP), TAB, KML, GPKG, and others.\nNote\nThe code samples in Snowflake Labs are intended solely for reference and educational purposes. These code samples arent covered\nby any Service Level Agreement.",
        "syntax": [
          "CREATE OR REPLACE FUNCTION py_numgeographys(geo GEOGRAPHY)\nRETURNS INTEGER\nLANGUAGE PYTHON\nRUNTIME_VERSION = 3.10\nPACKAGES = ('shapely')\nHANDLER = 'udf'\nAS $$\nfrom shapely.geometry import shape, mapping\ndef udf(geo):\n    if geo['type'] not in ('MultiPoint', 'MultiLineString', 'MultiPolygon', 'GeometryCollection'):\n        raise ValueError('Must be a composite geometry type')\n    else:\n        g1 = shape(geo)\n        return len(g1.geoms)\n$$;"
        ]
      },
      {
        "heading": "Using GEOGRAPHY objects with H3",
        "description": "\nH3 is a hierarchical geospatial index that partitions\nthe world into hexagonal cells in a discrete global grid system.\nSnowflake provides SQL functions that enable you to use H3 with GEOGRAPHY objects. You can\nuse these functions to:\nGet the H3 cell ID (index) for a GEOGRAPHY object that represents a Point (and vice versa).\nGet the IDs of the minimal set of H3 cells that cover a GEOGRAPHY object.\nGet the IDs of the H3 cells that have centroids within a GEOGRAPHY object that represents a Polygon.\nGet the GEOGRAPHY object that represents the boundary of an H3 cell.\nGet the parents and children of a given H3 cell.\nGet the longitude and latitude of the centroid of an H3 cell (and vice versa).\nGet the resolution of an H3 cell.\nGet the hexadecimal representation of an H3 cell ID (and vice versa).\nGet the H3 cell ID (index) for a GEOGRAPHY object that represents a Point (and vice versa).\nGet the IDs of the minimal set of H3 cells that cover a GEOGRAPHY object.\nGet the IDs of the H3 cells that have centroids within a GEOGRAPHY object that represents a Polygon.\nGet the GEOGRAPHY object that represents the boundary of an H3 cell.\nGet the parents and children of a given H3 cell.\nGet the longitude and latitude of the centroid of an H3 cell (and vice versa).\nGet the resolution of an H3 cell.\nGet the hexadecimal representation of an H3 cell ID (and vice versa).\nFor more information about these functions, see Geospatial functions."
      },
      {
        "heading": "Choosing the geospatial data type to use (GEOGRAPHY or GEOMETRY)",
        "description": "\nThe next sections explain the differences between the GEOGRAPHY and GEOMETRY data types:\nUnderstanding the differences between GEOGRAPHY and GEOMETRY\nExamples comparing the GEOGRAPHY and GEOMETRY data types\nUnderstanding the differences in input data validation\nUnderstanding the differences between GEOGRAPHY and GEOMETRY\nExamples comparing the GEOGRAPHY and GEOMETRY data types\nUnderstanding the differences in input data validation"
      },
      {
        "heading": "Understanding the differences between GEOGRAPHY and GEOMETRY",
        "tables": [
          {
            "headers": [
              "GEOGRAPHY data type",
              "GEOMETRY data type"
            ],
            "rows": [
              [
                "Defines features on a sphere.\nOnly the WGS84 coordinate system. SRID is always 4326.\nCoordinates are latitude (-90 to 90) and longitude (-180 to 180) in degrees.\nResults of measurement operations (ST_LENGTH, ST_AREA, and so on) are in meters.\nSegments are interpreted as great circle arcs on the Earths surface.",
                "Defines features on a plane.\nAny coordinate system is supported.\nUnit of coordinate values are defined by the spatial reference system.\nResults of measurement operations (ST_LENGTH, ST_AREA, and so on) are in the same unit as coordinates. For example, if the\ninput coordinates are in degrees, the results are in degrees.\nSegments are interpreted as straight lines on the plane."
              ]
            ]
          }
        ]
      },
      {
        "heading": "Examples comparing the GEOGRAPHY and GEOMETRY data types",
        "tables": [
          {
            "headers": [
              "ST_DISTANCE using . GEOGRAPHY input",
              "ST_DISTANCE using . GEOMETRY input"
            ],
            "rows": [
              [
                "SELECT ST_DISTANCE(\n    ST_POINT(13.4814, 52.5015),\n    ST_POINT(-121.8212, 36.8252))\n  AS distance_in_meters;\n\nCopy\n+--------------------+\n| DISTANCE_IN_METERS |\n|--------------------|\n|9182410.99227821 |\n+--------------------+",
                "SELECT ST_DISTANCE(\n    ST_GEOMPOINT(13.4814, 52.5015),\n    ST_GEOMPOINT(-121.8212, 36.8252))\n  AS distance_in_degrees;\n\nCopy\n+---------------------+\n| DISTANCE_IN_DEGREES |\n|---------------------|\n|136.207708844 |\n+---------------------+"
              ]
            ]
          },
          {
            "headers": [
              "ST_AREA using . GEOGRAPHY input",
              "ST_AREA using . GEOMETRY input"
            ],
            "rows": [
              [
                "SELECT ST_AREA(border) AS area_in_sq_meters\n  FROM world_countries\n  WHERE name = 'Germany';\n\nCopy\n+-------------------+\n| AREA_IN_SQ_METERS |\n|-------------------|\n| 356379183635.591 |\n+-------------------+",
                "SELECT ST_AREA(border) as area_in_sq_degrees\n  FROM world_countries_geom\n  WHERE name = 'Germany';\n\nCopy\n+--------------------+\n| AREA_IN_SQ_DEGREES |\n|--------------------|\n| 45.930026848 |\n+--------------------+"
              ]
            ]
          },
          {
            "headers": [
              "ST_INTERSECTS using . GEOGRAPHY input",
              "ST_INTERSECTS using . GEOMETRY input"
            ],
            "rows": [
              [
                "SELECT name FROM world_countries WHERE\n  ST_INTERSECTS(border,\n    TO_GEOGRAPHY(\n      'LINESTRING(13.4814 52.5015, -121.8212 36.8252)'\n    ));\n\nCopy\n+--------------------------+\n| NAME|\n|--------------------------|\n| Germany |\n| Denmark |\n| Iceland |\n| Greenland |\n| Canada |\n| United States of America |\n+--------------------------+",
                "SELECT name FROM world_countries_geom WHERE\n  ST_INTERSECTS(border,\n    TO_GEOMETRY(\n      'LINESTRING(13.4814 52.5015, -121.8212 36.8252)'\n    ));\n\nCopy\n+--------------------------+\n| NAME |\n|--------------------------|\n| Germany |\n| Belgium |\n| Netherlands |\n| United Kingdom |\n| United States of America |\n+--------------------------+"
              ],
              [
                "",
                ""
              ]
            ]
          }
        ]
      },
      {
        "heading": "Understanding the differences in input data validation",
        "description": "\nTo create a GEOMETRY or GEOGRAPHY object for an input shape, you must use a shape that is well-formed and valid, according to the\nOGC rules for Simple Features. The next sections explain how the validity of input data differs between GEOMETRY and GEOGRAPHY.\nA given shape can be a valid GEOGRAPHY object but an invalid GEOMETRY object (and vice versa).\nFor example, self-intersecting polygons are disallowed by the OGC rules. A given set of points might define edges that intersect in\nCartesian domain but not on a sphere. Consider the following polygon:\nIn the Cartesian domain, this polygon degrades to a line and, as a result, is invalid.\nHowever, on a sphere, this same polygon doesnt intersect itself and is valid:\nWhen the input data is invalid, the GEOMETRY and GEOGRAPHY functions handle validation in different ways:\nSome of the functions for constructing and converting to GEOGRAPHY objects might attempt to repair the shape to handle problems\nsuch as unclosed loops, spikes, cuts, and self-intersecting loops in polygons. For example, when either the\nTO_GEOGRAPHY function or the\nST_MAKEPOLYGON function is used to\nconstruct a polygon, the function corrects the orientation of the loop to prevent the creation of polygons that span more than half of the\nglobe. However, the ST_MAKEPOLYGONORIENTED function doesnt attempt to correct the orientation of\nthe loop.\nIf the function is successful in repairing the shape, the function returns a GEOGRAPHY object.\nThe functions for constructing and converting to GEOMETRY objects (for example, TO_GEOMETRY) dont\nsupport the ability to repair the shape.\nSome of the functions for constructing and converting to GEOGRAPHY objects might attempt to repair the shape to handle problems\nsuch as unclosed loops, spikes, cuts, and self-intersecting loops in polygons. For example, when either the\nTO_GEOGRAPHY function or the\nST_MAKEPOLYGON function is used to\nconstruct a polygon, the function corrects the orientation of the loop to prevent the creation of polygons that span more than half of the\nglobe. However, the ST_MAKEPOLYGONORIENTED function doesnt attempt to correct the orientation of\nthe loop.\nIf the function is successful in repairing the shape, the function returns a GEOGRAPHY object.\nThe functions for constructing and converting to GEOMETRY objects (for example, TO_GEOMETRY) dont\nsupport the ability to repair the shape.",
        "syntax": [
          "POLYGON((0 50, 25 50, 50 50, 0 50))"
        ]
      },
      {
        "heading": "Converting between GEOGRAPHY and GEOMETRY",
        "description": "\nSnowflake supports converting from a GEOGRAPHY object to a GEOMETRY object (and vice versa). Snowflake also supports\ntransformations of objects that use different spatial reference systems (SRS).\nThe following example converts a GEOGRAPHY object that represents a point to a GEOMETRY object with the SRID 0:\nTo set the SRID of the new GEOMETRY object, pass the SRID as an argument to the constructor function. For example:\nIf you need to set the SRID of an existing GEOMETRY object, see Changing the spatial reference system (SRS) and SRID of a GEOMETRY object.",
        "syntax": [
          "SELECT TO_GEOMETRY(TO_GEOGRAPHY('POINT(-122.306100 37.554162)'));",
          "SELECT TO_GEOMETRY(TO_GEOGRAPHY('POINT(-122.306100 37.554162)', 4326));"
        ]
      },
      {
        "heading": "Specifying how invalid geospatial shapes are handled",
        "description": "\nBy default, when you use a geospatial conversion function to convert\ndata in a supported input format to a GEOGRAPHY or GEOMETRY object, the function\ndoes the following:\nThe function attempts to validate the shape in the input data.\nThe function determines if the shape is valid according to the\nOpen Geospatial Consortiums Simple Feature Access / Common Architecture standard.\nIf the shape is invalid, the function attempts to repair the data (for example, fixing polygons by closing the rings).\nIf the shape is still invalid after the repairs, the function reports an error and doesnt create the GEOGRAPHY or GEOMETRY\nobject. (For the TRY_* functions, the functions return NULL, rather than reporting an error.)\nThe function attempts to validate the shape in the input data.\nThe function determines if the shape is valid according to the\nOpen Geospatial Consortiums Simple Feature Access / Common Architecture standard.\nIf the shape is invalid, the function attempts to repair the data (for example, fixing polygons by closing the rings).\nIf the shape is still invalid after the repairs, the function reports an error and doesnt create the GEOGRAPHY or GEOMETRY\nobject. (For the TRY_* functions, the functions return NULL, rather than reporting an error.)\nWith this feature, you have more control over the validation and repair process. You can:\nAllow these conversion functions to create GEOGRAPHY and GEOMETRY objects for invalid shapes.\nDetermine if the shape for a GEOGRAPHY or GEOMETRY object is invalid.\nAllow these conversion functions to create GEOGRAPHY and GEOMETRY objects for invalid shapes.\nDetermine if the shape for a GEOGRAPHY or GEOMETRY object is invalid."
      },
      {
        "heading": "Understanding the effects of invalid shapes on geospatial functions",
        "description": "\nDifferent geospatial functions have different effects when you pass in a GEOGRAPHY\nor GEOMETRY object for an invalid shape.\nFor GEOMETRY objects:\nThe following functions return results based on the original invalid shape:\n\nST_AREA\nST_ASGEOJSON\nST_ASWKB\nST_ASWKT\nST_CENTROID\nST_CONTAINS\nST_DIMENSION\nST_DISTANCE\nST_ENVELOPE\nST_INTERSECTS\nST_LENGTH\nST_NPOINTS , ST_NUMPOINTS\nST_PERIMETER\nST_SETSRID\nST_SRID\nST_X\nST_XMAX\nST_XMIN\nST_Y\nST_YMAX\nST_YMIN\nST_AREA\nST_ASGEOJSON\nST_ASWKB\nST_ASWKT\nST_CENTROID\nST_CONTAINS\nST_DIMENSION\nST_DISTANCE\nST_ENVELOPE\nST_INTERSECTS\nST_LENGTH\nST_NPOINTS , ST_NUMPOINTS\nST_PERIMETER\nST_SETSRID\nST_SRID\nST_X\nST_XMAX\nST_XMIN\nST_Y\nST_YMAX\nST_YMIN\nThe following functions validate the shape and fail with an error if the shape is invalid:\n\nST_MAKELINE\nST_MAKEPOLYGON\nST_MAKELINE\nST_MAKEPOLYGON\nThe following functions return results based on the original invalid shape:\nST_AREA\nST_ASGEOJSON\nST_ASWKB\nST_ASWKT\nST_CENTROID\nST_CONTAINS\nST_DIMENSION\nST_DISTANCE\nST_ENVELOPE\nST_INTERSECTS\nST_LENGTH\nST_NPOINTS , ST_NUMPOINTS\nST_PERIMETER\nST_SETSRID\nST_SRID\nST_X\nST_XMAX\nST_XMIN\nST_Y\nST_YMAX\nST_YMIN\nST_AREA\nST_ASGEOJSON\nST_ASWKB\nST_ASWKT\nST_CENTROID\nST_CONTAINS\nST_DIMENSION\nST_DISTANCE\nST_ENVELOPE\nST_INTERSECTS\nST_LENGTH\nST_NPOINTS , ST_NUMPOINTS\nST_PERIMETER\nST_SETSRID\nST_SRID\nST_X\nST_XMAX\nST_XMIN\nST_Y\nST_YMAX\nST_YMIN\nThe following functions validate the shape and fail with an error if the shape is invalid:\nST_MAKELINE\nST_MAKEPOLYGON\nST_MAKELINE\nST_MAKEPOLYGON\nFor GEOGRAPHY objects:\nThe following functions return results based on the original invalid shape:\n\nST_ASWKB\nST_ASWKT\nST_ASGEOJSON\nST_AZIMUTH\nST_COLLECT\nST_DIMENSION\nST_GEOHASH\nST_HAUSDORFFDISTANCE\nST_MAKELINE\nST_NPOINTS , ST_NUMPOINTS\nST_POINTN\nST_SRID\nST_ENDPOINT\nST_STARTPOINT\nST_X\nST_Y\nST_ASWKB\nST_ASWKT\nST_ASGEOJSON\nST_AZIMUTH\nST_COLLECT\nST_DIMENSION\nST_GEOHASH\nST_HAUSDORFFDISTANCE\nST_MAKELINE\nST_NPOINTS , ST_NUMPOINTS\nST_POINTN\nST_SRID\nST_ENDPOINT\nST_STARTPOINT\nST_X\nST_Y\nThe following functions validate the shape and fail with an error if the shape is invalid:\n\nST_COLLECT\nST_MAKEPOLYGON\nST_MAKEPOLYGONORIENTED\nST_COLLECT\nST_MAKEPOLYGON\nST_MAKEPOLYGONORIENTED\nThe following functions return NULL if it isnt possible to compute the value:\n\nST_AREA\nST_CENTROID\nST_CONTAINS\nST_COVERS\nST_DIFFERENCE\nST_DISTANCE\nST_DWITHIN\nST_ENVELOPE\nST_INTERSECTION\nST_INTERSECTION_AGG\nST_INTERSECTS\nST_LENGTH\nST_PERIMETER\nST_SIMPLIFY\nST_SYMDIFFERENCE\nST_UNION\nST_UNION_AGG\nST_XMAX\nST_XMIN\nST_YMAX\nST_YMIN\nST_AREA\nST_CENTROID\nST_CONTAINS\nST_COVERS\nST_DIFFERENCE\nST_DISTANCE\nST_DWITHIN\nST_ENVELOPE\nST_INTERSECTION\nST_INTERSECTION_AGG\nST_INTERSECTS\nST_LENGTH\nST_PERIMETER\nST_SIMPLIFY\nST_SYMDIFFERENCE\nST_UNION\nST_UNION_AGG\nST_XMAX\nST_XMIN\nST_YMAX\nST_YMIN\nThe following functions return results based on the original invalid shape:\nST_ASWKB\nST_ASWKT\nST_ASGEOJSON\nST_AZIMUTH\nST_COLLECT\nST_DIMENSION\nST_GEOHASH\nST_HAUSDORFFDISTANCE\nST_MAKELINE\nST_NPOINTS , ST_NUMPOINTS\nST_POINTN\nST_SRID\nST_ENDPOINT\nST_STARTPOINT\nST_X\nST_Y\nST_ASWKB\nST_ASWKT\nST_ASGEOJSON\nST_AZIMUTH\nST_COLLECT\nST_DIMENSION\nST_GEOHASH\nST_HAUSDORFFDISTANCE\nST_MAKELINE\nST_NPOINTS , ST_NUMPOINTS\nST_POINTN\nST_SRID\nST_ENDPOINT\nST_STARTPOINT\nST_X\nST_Y\nThe following functions validate the shape and fail with an error if the shape is invalid:\nST_COLLECT\nST_MAKEPOLYGON\nST_MAKEPOLYGONORIENTED\nST_COLLECT\nST_MAKEPOLYGON\nST_MAKEPOLYGONORIENTED\nThe following functions return NULL if it isnt possible to compute the value:\nST_AREA\nST_CENTROID\nST_CONTAINS\nST_COVERS\nST_DIFFERENCE\nST_DISTANCE\nST_DWITHIN\nST_ENVELOPE\nST_INTERSECTION\nST_INTERSECTION_AGG\nST_INTERSECTS\nST_LENGTH\nST_PERIMETER\nST_SIMPLIFY\nST_SYMDIFFERENCE\nST_UNION\nST_UNION_AGG\nST_XMAX\nST_XMIN\nST_YMAX\nST_YMIN\nST_AREA\nST_CENTROID\nST_CONTAINS\nST_COVERS\nST_DIFFERENCE\nST_DISTANCE\nST_DWITHIN\nST_ENVELOPE\nST_INTERSECTION\nST_INTERSECTION_AGG\nST_INTERSECTS\nST_LENGTH\nST_PERIMETER\nST_SIMPLIFY\nST_SYMDIFFERENCE\nST_UNION\nST_UNION_AGG\nST_XMAX\nST_XMIN\nST_YMAX\nST_YMIN"
      },
      {
        "heading": "Working with invalid shapes",
        "description": "\nThe next sections explain how to allow functions to create invalid shapes and how to determine if a GEOGRAPHY or GEOMETRY object\nrepresents an invalid or repaired shape.\nTo allow the following conversion functions to create invalid geospatial objects, pass TRUE for the second argument\n(allowInvalid):\nBy default, the allowInvalid argument is FALSE.\nWhen you pass TRUE for the allowInvalid argument, the conversion function returns a GEOGRAPHY or GEOMETRY\nobject, even when the input shape is invalid and cant be repaired successfully.\nFor example, the following input shape is a LineString that consists of the same two Points. Passing TRUE for the\nallowInvalid argument returns a GEOMETRY object that represents an invalid shape:\nTo determine if a GEOGRAPHY or GEOMETRY object is invalid, call the ST_ISVALID function.\nThe following example checks if an object is valid:\nOn this page\nData types\nGeospatial input and output\nUsing geospatial data in Snowflake\nChoosing the geospatial data type to use (GEOGRAPHY or GEOMETRY)\nConverting between GEOGRAPHY and GEOMETRY\nSpecifying how invalid geospatial shapes are handled\nRelated content\nGeospatial functions\nData type conversion\nWe use cookies to improve your experience on our site. By accepting, you agree to our privacy policy.\nEnglish\nFranais\nDeutsch\n\n\nPortugus\n",
        "syntax": [
          "TO_GEOGRAPHY( <input> [, <allowInvalid> ] )",
          "ST_GEOGFROMWKB( <input> [, <allowInvalid> ] )",
          "ST_GEOGFROMWKT( <input> [, <allowInvalid> ] )",
          "TO_GEOMETRY( <input> [, <allowInvalid> ] )",
          "ST_GEOMFROMWKB( <input> [, <allowInvalid> ] )",
          "ST_GEOMFROMWKT( <input> [, <allowInvalid> ] )",
          "SELECT TO_GEOMETRY('LINESTRING(100 102,100 102)', TRUE);",
          "SELECT TO_GEOMETRY('LINESTRING(100 102,100 102)', TRUE) AS g, ST_ISVALID(g);"
        ]
      }
    ]
  },
  {
    "category": "Vector data types",
    "url": "https://docs.snowflake.com/en/sql-reference/data-types-vector",
    "details": [
      {
        "heading": "Vector data types",
        "description": "\nThis topic describes the vector data types."
      },
      {
        "heading": "Data types",
        "description": "\nSnowflake supports a single vector data type, VECTOR.\nNote\nThe VECTOR data type is only supported in SQL, the Python connector, and\nthe Snowpark Python library. No other languages are supported."
      },
      {
        "heading": "VECTOR",
        "description": "\nWith the VECTOR data type, Snowflake encodes and processes vectors efficiently. This data type supports semantic vector\nsearch and retrieval applications, such as RAG-based applications, and common operations on vectors in vector-processing applications.\nTo specify a VECTOR type, use the following syntax:\nWhere:\ntype  is the Snowflake data type of the elements, which can be 32-bit integers or 32-bit floating-point numbers.\nYou can specify one of the following types:\n\n\nINT\nFLOAT\nINT\nFLOAT\ndimension is the dimension (length) of the vector. This must be a positive integer value with a maximum value of 4096.\ntype  is the Snowflake data type of the elements, which can be 32-bit integers or 32-bit floating-point numbers.\nYou can specify one of the following types:\nINT\nFLOAT\nINT\nFLOAT\ndimension is the dimension (length) of the vector. This must be a positive integer value with a maximum value of 4096.\nNote\nDirect vector comparisons (for example, v1 < v2) are byte-wise lexicographic and, although deterministic, wont produce the results\nthat you might expect from number comparisons. So although you can use VECTOR columns in ORDER BY clauses, for vector comparisons, use the\nvector similarity functions provided.\nThe following definitions are examples of valid vector definitions:\nDefine a vector of 256 32-bit floating-point values:\nVECTOR(FLOAT, 256)\n\nCopy\nDefine a vector of 16 32-bit integer values:\nVECTOR(INT, 16)\n\nCopy\nDefine a vector of 256 32-bit floating-point values:\nDefine a vector of 16 32-bit integer values:\nThe following definitions are examples of invalid vector definitions:\nA vector definition using an invalid value type:\nVECTOR(STRING, 256)\n\nCopy\nA vector definition using an invalid vector size:\nVECTOR(INT, -1)\n\nCopy\nA vector definition using an invalid value type:\nA vector definition using an invalid vector size:",
        "syntax": [
          "VECTOR( <type>, <dimension> )",
          "VECTOR(FLOAT, 256)",
          "VECTOR(INT, 16)",
          "VECTOR(STRING, 256)",
          "VECTOR(INT, -1)"
        ]
      },
      {
        "heading": "Vector conversion",
        "description": "\nThis section describes how to convert to and from a VECTOR value. For details about casting, see Data type conversion."
      },
      {
        "heading": "Converting a value to a VECTOR value",
        "description": "\nVECTOR values can be explicitly cast from the following types:\nARRAY\nStructured ARRAY\nVariant containing an ARRAY\nARRAY\nStructured ARRAY\nVariant containing an ARRAY"
      },
      {
        "heading": "Converting a value from a VECTOR value",
        "description": "\nVECTOR values can be explicitly cast to the following types:\nARRAY\nStructured ARRAY\nARRAY\nStructured ARRAY"
      },
      {
        "heading": "Loading and unloading vector data",
        "description": "\nDirectly loading and unloading a VECTOR column isnt supported. For VECTOR columns, you must load and unload\ndata as an ARRAY and then cast it to a VECTOR when you use it. To learn how to load and unload ARRAY data types, see\nIntroduction to Loading Semi-structured Data. A common use case for vectors is to generate a\nvector embedding.\nThe following example shows how to unload a table with a VECTOR column to an internal stage named mystage:\nThe following example shows how to load a table from a stage and then cast the ARRAY columns as VECTOR columns:",
        "syntax": [
          "CREATE OR REPLACE TABLE myvectortable (a VECTOR(float, 3), b VECTOR(float, 3));\nINSERT INTO myvectortable SELECT [1.1,2.2,3]::VECTOR(FLOAT,3), [1,1,1]::VECTOR(FLOAT,3);\nINSERT INTO myvectortable SELECT [1,2.2,3]::VECTOR(FLOAT,3), [4,6,8]::VECTOR(FLOAT,3);\n\nCOPY INTO @mystage/unload/\n  FROM (SELECT TO_ARRAY(a), TO_ARRAY(b) FROM myvectortable);",
          "CREATE OR REPLACE TABLE arraytable (a ARRAY, b ARRAY);\n\nCOPY INTO arraytable\n  FROM @mystage/unload/mydata.csv.gz;\n\nSELECT a::VECTOR(FLOAT, 3), b::VECTOR(FLOAT, 3)\n  FROM arraytable;"
        ]
      },
      {
        "heading": "Examples",
        "description": "\nConstruct a VECTOR by casting a constant ARRAY:\nAdd a column with the VECTOR data type:",
        "syntax": [
          "SELECT [1, 2, 3]::VECTOR(FLOAT, 3) AS vec;",
          "ALTER TABLE myissues ADD COLUMN issue_vec VECTOR(FLOAT, 768);\n\nUPDATE TABLE myissues\n  SET issue_vec = SNOWFLAKE.CORTEX.EMBED_TEXT_768('e5-base-v2', issue_text);"
        ]
      },
      {
        "heading": "Limitations",
        "tables": [
          {
            "headers": [
              "Snowflake\nfeature",
              "Python",
              "SQL"
            ],
            "rows": [
              [
                "UDFs",
                "",
                ""
              ],
              [
                "UDTFs",
                "",
                ""
              ],
              [
                "Drivers/Connectors",
                "",
                ""
              ],
              [
                "Snowpark API",
                "",
                ""
              ]
            ]
          }
        ]
      }
    ]
  }
]